<h1 id="0">0 目录</h1>

* [5 内核同步](#5)
    - [5.1 如何请求内核服务](#5.1)
        + [5.1.1 内核抢占](#5.1.1)
        + [5.1.2 什么时候需要同步？](#5.1.2)
    - [5.2 同步原语](#5.2)
        + [5.2.1 Per-CPU变量](#5.2.1)
        + [5.2.2 原子操作](#5.2.2)
        + [5.2.3 优化和内存屏障](#5.2.3)
        + [5.2.4 自旋锁](#5.2.4)
        + [5.2.5 读写自旋锁](#5.2.5)
        + [5.2.6 Seqlock](#5.2.6)
        + [5.2.7 读-拷贝-更新（RCU）](#5.2.7)
        + [5.2.8 信号量](#5.2.8)
        + [5.2.9 读写信号量](#5.2.9)
        + [5.2.10 Completion机制](#5.2.10)
        + [5.2.11 中断禁止](#5.2.11)
        + [5.2.12 软中断禁止](#5.2.12)
    - [5.3 内核数据结构的同步访问](#5.3)
        + [5.3.1 如何选择自旋锁、信号量和关闭中断](#5.3.1)
    - [5.4 防止竞态条件的示例](#5.4)
        + [5.4.1 引用计数器](#5.4.1)
        + [5.4.2 大内核锁](#5.4.2)
        + [5.4.3 内存描述符读写信号量](#5.4.3)
        + [5.4.4 Slab Cache列表信号量](#5.4.4)
        + [5.4.5 INode节点信号量](#5.4.5)


<h1 id="5">5 内核同步</h1>

我们可以把内核想象成一个服务器，专门响应各种请求。这些请求可以是CPU上正在运行的进程发起的请求，也可以是外部的设备发起的中断请求。所以说，内核并不是串行运行，而是交错执行。既然是交错执行，就会产生`竞态条件`，我们可以采用同步技术消除这种竞态条件。

我们首先了解一下如何向内核请求服务。然后，看一下这些请求如何实现同步。Linux内核又是采用了哪些同步技术。

<h2 id="5.1">5.1 如何请求内核服务</h2>

为了更好地理解内核是如何工作的，我们把内核比喻成一个酒吧服务员，他响应两种请求服务：一种是来自顾客，另外一种来自多个老板。这个服务员采用的策略是：

1. 如果老板呼叫服务员，而服务员恰巧空闲，则立即服务老板；

2. 如果老板呼叫服务员，而服务员恰巧正在服务一名顾客。则服务员停止为顾客服务，而是去服务老板。

3. 如果老板呼叫服务员，而服务员恰巧在服务另一个老板，则服务员停止服务第一个老板，转而服务第二个。当他服务完第二个老板，再回去服务第一个老板。

4. 老板让服务员停止为顾客服务转而为自己服务。在处理完老板的最后一个请求后，服务员也可能会决定是临时性地放弃之前的顾客，而迎接新顾客。

上面的服务员就非常类似于处于内核态的代码执行。如果CPU被用户态程序占用，服务员被认为是空闲的。老板的请求就类似于中断请求，而顾客请求就对应于用户进程发出的系统调用或异常。后面描述中，异常处理程序指的是系统调用和常规异常的处理程序。

仔细研究，就会发现，前3条规则其实与内核中的异常和中断嵌套执行的规则是一样的。第4条规则就对应于内核抢占。

<h3 id="5.1.1">5.1.1 内核抢占</h3>

给内核抢占下一个完美定义很难。在这儿，我们只是尝试着给其下一个定义：如果一个进程正运行在内核态，此时，发生了进程切换我们就称其为抢占式内核。当然了，Linux内核不可能这么简单：

* 不论是抢占式内核还是非抢占式内核，进程都有可能放弃CPU的使用权而休眠等待某些资源。我们称这类进程切换是有计划的进程切换。但是抢占式内核和非抢占式的区别就在于对于异步事件的响应方式不同-比如，抢占式内核的中断处理程序可以唤醒更高优先级的进程，而非抢占式内核不会。我们称这类进程切换为强迫性的进程切换。

* 我们已经知道所有的进程切换动作都由`switch_to`宏完成。不论是抢占式还是非抢占式，当进程完成内核活动的某个线程并调用调度器时就会发生进程切换。但是，在非抢占式内核中，除非即将切换到用户态时，否则不会发生进程替换。

因此，抢占式内核主要的特性就是运行在内核态的进程可以被其它进程打断而发生替换。让我们举例说明抢占式内核和非抢占式内核的区别：

假设进程A正在执行异常处理程序（内核态），这时候中断请求IRQ发生，相应的处理程序唤醒高优先级的进程B。如果内核是可抢占式的，就会发生进程A到进程B的替换。异常处理程序还没有执行完，只有当调度器再一次选择进程A执行的时候才会继续。相反，如果内核是非抢占式的，除非进程A完成异常处理或者自愿放弃CPU的使用权，否则不会发生进程切换。

再比如，考虑正在执行异常处理程序的进程，它的CPU使用时间已经超时。如果内核是抢占式的，进程被立即切换；但是，如果内核是非抢占式的，进程会继续执行，知道进程完成异常处理或自动放弃CPU的使用权。

实施内核抢占的动机就是减少用户态进程的调度延时，也就是减少`可运行状态`到`真正运行时`的延时。需要实时调度的任务（比如外部的硬件控制器等）需要内核具有抢占性，因为减少了被其它进程延时的风险。

Linux内核是从2.6版本开始的，相比那些旧版本的非抢占性内核而言，没有什么显著的变化。当`thread_info`描述符中的`preempt_count`成员的值大于0，内核抢占就被禁止。这个值分为3部分，也就是说可能有3种情况导致该值大于0：

1. 内核正在执行中断服务例程（ISR）；
2. 延时函数被禁止（当内核执行软中断或tasklet时总是使能状态）；
3. 内核抢占被禁止。

通过上面的规则可以看出，内核只有在执行异常处理程序（尤其是系统调用）的时候才能够被抢占，而且内核抢占也没有被禁止。所以，CPU必须使能中断，内核抢占才能被执行。

下表是操作`prempt_count`数据成员的一些宏：

| Macro | 描述 |
| ----- | ----------- |
| preempt_count() | 选择`preempt_count` |
| preempt_disable() | 抢占计数加1 |
| preempt_enable_no_resched() | 抢占计数减1 |
| preempt_enable() | 抢占计数减1，如果需要调度，调用`preempt_schedule()` |
| get_cpu() | 与`preempt_disable()`相似，但是返回CPU的数量 |
| put_cpu() | 与`preempt_enable()`相似 |
| put_cpu_no_resched() | 与`preempt_enable_no_resched()`相似 |

`preempt_enable()`使能抢占，还会检查`TIF_NEED_RESCHED`标志是否设置。如果设置，说明需要进行进程切换，就会调用函数`preempt_schedule()`，其代码片段如下所示：

    if (!current_thread_info->preempt_count && !irqs_disabled()) {
        current_thread_info->preempt_count = PREEMPT_ACTIVE;
        schedule();
        current_thread_info->preempt_count = 0;
    }

可以看出，这个函数首先检查中断是否使能，以及抢占计数是否为0。如果条件为真，调用`schedule()`切换到其它进程运行。因此，内核抢占既可以发生在中断处理程序结束时，也可以发生在异常处理程序重新使能内核抢占时（调用`preempt_enable()`。<font color="red">也就是说，对于抢占式内核来说，进程切换发生的时机有，中断、系统调用、异常处理，还有一种特殊情况就是内核线程，它们直接调用schedule()进行主动进程切换。</font>

内核抢占不可避免地引入了更多的开销。基于这个原因，Linux2.6内核允许用户在编译内核代码的时候，通过配置，可以使能和禁止内核抢占。

<h3 id="5.1.2">5.1.2 什么时候需要同步技术？</h3>

我们先了解一下内核进程的竞态条件和临界区的概念。当计算结果依赖于两个嵌套的内核控制路径时就会发生竞态条件。而临界区就是每次只能一个内核控制路径可以进入的代码段。

内核控制路径的交错执行给内核开发者带来很大的麻烦：必须小心地在异常处理程序、中断处理程序、可延时处理函数和内核线程中确定临界区。一旦确定了哪些代码是临界区，就需要为这个临界区代码提供合适的保护，确保至多有一个内核控制路径可以访问它。

假设两个不同的中断处理程序需要访问相同的数据结构。所有影响数据结构的语句都必须放到一个临界区中。如果是单核处理系统，临界区的保护只需要关闭中断即可，因为内核控制路径的嵌套只有在中断使能的情况下会发生。

另一方面，如果不同的系统调用服务程序访问相同的数据，系统也是单核处理系统，临界区的保护只需要禁止内核抢占即可。

但是，在多核系统中事情就比较复杂了。**因为除了内核抢占，中断、异常或软中断之外，多个CPU也可能会同时访问某个相同的数据**。

后面我们会看一下内核提供了哪些内核同步手段？每种同步手段最合适的使用场景是什么？通过这些问题，我们掌握内核同步技术，为自己的内核程序设计最好的同步方法。

<h2 id="5.2">5.2 同步原语</h2>

表5-2，列举了Linux内核使用的一些同步技术。范围一栏表明同步技术应用到所有的CPU还是单个CPU。比如局部中断禁止就是针对一个CPU（系统中的其它CPU不受影响）；相反，原子操作影响所有的CPU。

表5-2 Linux内核使用的一些同步技术

| 技术 | 描述 | 范围 |
| --------- | ----------- | ----- |
| Per-CPU变量 | 用于在CPU之间拷贝数据 | 所有CPU |
| 原子操作 | 针对计数器的原子RMW指令 | 所有CPU |
| 内存屏障 | 避免指令乱序 | 本地CPU或所有CPU |
| 自旋锁 | 忙等待 | 所有CPU |
| 信号量 | 阻塞等待（休眠） | 所有CPU |
| Seqlock |   | 所有CPU |
| 中断禁止 | 禁止响应中断 | 本地CPU |
| 软中断禁止 | 禁止处理可延时函数 | 本地CPU |
| 读-拷贝-更新（RCU） | 通过指针实现无锁访问共享资源 | 所有CPU |

接下来，我们介绍各个同步技术。

<h3 id="5.2.1">5.2.1 Per-CPU变量</h3>

其实，最好的同步手段在于设计阶段就要尽量避免同步的需求。因为，毕竟同步的实现都是需要牺牲系统性能的。

既然多核系统中，CPU之间访问共享数据需要同步，那么最简单和有效的同步技术就是为每个CPU声明自己的变量，这样就减少了它们的耦合性，降低了同步的可能性。

**使用场景：**

一个CPU访问自己专属的变量，而无需担心其它CPU访问而导致的竞态条件。这意味着，`per-CPU`变量只能在特定情况下使用，比如把数据进行逻辑划分，然后分派给各个CPU的时候。

因为这些`per-CPU`变量全部元素都存储在内存上，所有的数据结构都会落在Cache的不同行上。所以，访问这些`per-CPU`变量不会导致对Cache行进行窥视（snoop）和失效（invalidate）操作，它们都对系统性能有很大的牺牲。

**缺点：**

1. 尽管，`per-CPU`变量保护了来自多个CPU的并发访问，但是无法阻止异步访问（比如，中断处理程序和可延时函数）。这时候，就需要其它同步技术了。

2. 此外，不管是单核系统还是多核系统，`per-CPU`变量都易于受到内核抢占所导致的竞态条件的影响。一般来说，内核控制路径访问每个CPU变量的时候，应该禁用内核抢占。假设，内核控制路径获得一个`per-CPU`变量的拷贝的地址，然后被转移到其它CPU上运行，这个值就可能会被其它CPU修改。

表5-3 列出了操作`per-CPU`变量的函数和宏

| 函数 | 描述 |
| ---- | ---- |
| DEFINE_PER_CPU(type, name)| 静态分配一个`per-CPU`数组 |
| per_cpu(name, cpu)        | 选择元素 |
| __get_cpu_var(name)       | 选择元素 |
| get_cpu_var(name)         | 禁止内核抢占，选择元素 |
| put_cpu_var(name)         | 使能内核抢占 |
| alloc_percpu(type)        | 动态分配一个`per-CPU`数组 |
| free_percpu(pointer)      | 释放动态分配的数组 |
| per_cpu_ptr(pointer, cpu) | 返回某个元素的地址 |

<h3 id="5.2.2">5.2.2 原子操作</h3>

汇编指令读写内存变量的过程我们称为`read-modify-write`，简称为RMW操作。也就是说，它们读写一个内存区域两次，第一次读取旧值，第二次写入新值。

假设有两个不同的内核控制路径运行在两个CPU上，同时尝试RMW操作相同的内存区域且执行的是非原子操作。起初，两个CPU尝试读取相同位置，但是内存仲裁器（促使串行访问RAM的电路）确定一个可以访问，让另一个等待。但是，当第一个读操作完成，延时的CPU也会读取相同的旧值。但是等到两个CPU都往这个内存区域写入新值的时候，还是由内存仲裁器决定谁先访问，然后写操作都会成功。但是，最终的结果却是最后写入的值，先写入的值会被覆盖掉。

防止RMW操作造成的竞态条件最简单的方式就是保证这样的指令操作是原子的，也就是这个指令的执行过程不能被打断。这就是原子操作的由来。

让我们看一下X86的汇编指令有哪些是原子的：

* 进行零或一对齐内存访问的汇编指令是原子的。

* RMW操作汇编指令（比如`inc`或`dec`），如果在read之后，write之前内存总线没有被其它CPU抢占，那么这些指令就是原子的。

* 所以，基于上一点，RMW操作汇编指令前缀`lock（0xf0）`就称为原子操作指令。当控制单元检测到这个前缀，它会锁住内存总线，直到指令完成。

* 带有前缀`rep`（0xf2、0xf3，强迫控制单元重复指令多次）的汇编指令就不是原子的。

但是，我们在编写完C代码后，编译器不能保证给你使用原子指令进行替代。因此，Linux内核提供了`atomic_t`类型变量并提供了相关的操作函数和宏（如表5-4所示）。多核系统中，会在每个指令的前面前缀`lock`。

表5-4 Linux中的原子操作

| 函数 | 描述 |
| ---- | ---- |
| atomic_read(v)            | 返回`*v` |
| atomic_set(v,i)           | *v=i |
| atomic_add(i,v)           | *v+i |
| atomic_sub(i,v)           | *v-i |
| atomic_sub_and_test(i, v) | 如果`*v-i = 0`，<br> 返回1；否则0 |
| atomic_inc(v)             | *v+1 |
| atomic_dec(v)             | *v-1 |
| atomic_dec_and_test(v)    | 如果`*v-1 = 0`，<br> 返回1；否则0 |
| atomic_inc_and_test(v)    | 如果`*v+1 = 0`，<br> 返回1；否则0 |
| atomic_add_negative(i, v) | 如果`*v+i < 0`，<br> 返回1；否则0  |
| atomic_inc_return(v)      | 返回`*v-1` |
| atomic_dec_return(v)      | 返回`*v+i` |
| atomic_add_return(i, v)   | 返回`*v-i` |


<h3 id="5.2.3">5.2.3 优化和内存屏障</h3>

带有优化的编译器，会尝试重新排序汇编指令，以提高程序的执行速度。但是，当在处理同步问题的时候，重新排序的指令应该被避免。因为重新排序可能会打乱我们之前想要的同步效果。因此，所有的同步原语都充当优化和内存屏障。

优化屏障保证屏障原语前后的C语言转换成汇编语言之后，指令序列不会发生变化。比如说，对于Linux内核的`barrier()`宏，展开后就是`asm volatile("":::"memory")`，就是一个优化屏障。`asm`告知编译器插入一条汇编指令，`volatile`关键字禁止编译器用程序的其它指令重新洗牌`asm`指令。`memory`关键字强迫编译器假设RAM中所有的位置都被汇编指令更改了；因此，编译器不会使用CPU寄存器中的值优化`asm`指令之前的代码。我们需要注意的是优化屏障不能保证汇编指令的执行不会乱序，这是由内存屏障保障的。

内存屏障确保屏障原语前的指令完成后，才会启动原语之后的指令操作。

X86系统中，下面这些汇编指令都是串行的，可以充当内存屏障：

* 所有操作I/O端口的指令；
* 前缀`lock`的指令；
* 所有写控制寄存器，系统寄存器或debug寄存器的指令（比如，`cli`和`sti`指令，可以改变`eflags`寄存器的IF标志）；
* `lfence`、`sfence`和`mfence`汇编指令，分别用来实现读内存屏障、写内存屏障和读/写内存屏障；
* 特殊的汇编指令，比如`iret`指令，可以终止中断或异常处理程序。

> ARM系统中，使用`ldrex`和`strex`汇编指令实现内存屏障。

Linux内核中使用的内存屏障原语如下，如表5-6所示。当然了，这些原语完全可以作为优化屏障，阻止编译器优化该屏障前后的汇编指令。读内存屏障只对内存的读操作指令有效；写内存屏障只对内存的写操作指令有效。`smp_xxx()`之类的内存屏障只对发生在多核系统里的竞态条件有效，单核系统中，什么也没有做。其它的内存屏障对多核系统和单核系统都有效。

表5-6 Linux内存屏障

| macro | 描述 |
| ----- | ---- |
| mb()      | MP和UP的内存屏障 |
| rmb()     | MP和UP的读内存屏障 |
| wmb()     | MP和UP的写内存屏障 |
| smp_mb()  | MP内存屏障 |
| smp_rmb() | MP读内存屏障 |
| smp_wmb() | MP写内存屏障 |

内存屏障的实现跟系统架构息息相关。在X86系统上，如果支持`lfence`汇编指令，则`rmb()`实现为：

    asm volatile("lfence":::"memory")

如不支持`lfence`汇编指令，则`rmb()`实现为：

    asm volatile("lock;addl $0,0(%%esp)":::"memory")

`asm volatile`的作用之前的文章已经介绍过，不再赘述。`lock;addl $0,0(%%esp)":::"memory"`的意思是，对栈顶保存的内存地址内的内容加上0，所以这条命令本身没有意义，主要还是`lock`前缀，对数据总线加锁，从而使该条指令对CPU而言，称为内存屏障。

而`wmb()`的实现事实上非常简单，就是`barrier()`的宏声明。这是因为，现有的Intel处理器不会对写内存访问进行重新排序，所以无法插入特定的内存屏障指令。但是，该宏还是会禁止编译器打乱指令。

值得注意的是多核处理器中，所有的原子操作指令都会前缀`lock`，所以都可以充当内存屏障。

总结：

内存屏障主要解决的还是硬件数据总线上对于指令的读取可能会发生乱序问题。

<h3 id="5.2.4">5.2.4 自旋锁</h3>

使用最广泛的同步技术就是`加锁`。对于锁概念，我相信大家已经不陌生了，不论是实时嵌入式系统还是服务器上的操作系统，都使用了这个概念。所以对于锁的理解就不再赘述了。

自旋锁是设计用来在多核系统中工作的一种特殊锁。如果内核控制路径发现自旋锁空闲，则申请加锁然后执行。相反，如果发现锁已经被其它CPU上的内核控制路径占用，它就会一直`自旋`，就是在循环查看锁是否已经释放，直到该锁被释放。

自旋锁的自旋过程就是一个忙等待的过程。也就是说，正在等待的内核控制路径正在浪费时间，因为什么也不干。但是，大部分的内核资源加锁的时间可能仅为毫秒的几分之一，因此，释放CPU使用权再获取可能比一直等待更消耗时间。所以，自旋锁使用的场合就是，**内核资源的占用时间一般比较短，且是多核系统的时候**。

<h3 id="5.2.4.1">5.2.4.1 自旋锁结构实现</h3>

Linux内核系统中，自旋锁`spinlock_t`的实现主要使用了`raw_spinlock_t`结构，这个结构的实现，参考下面的代码：

    typedef struct raw_spinlock {
        arch_spinlock_t raw_lock;
    #ifdef CONFIG_GENERIC_LOCKBREAK
        unsigned int break_lock;
    #endif
        ...
    } raw_spinlock_t;
    typedef struct spinlock {
        union {
            struct raw_spinlock rlock;
            ...
        };
    } spinlock_t;

上面的代码中，核心的数据成员是`raw_lock`和`break_lock`。对于`raw_lock`来说，其类型为`arch_spinlock_t`，从名称上也能看出，这个结构是跟体系结构相关的。

* raw_lock

    表示自旋锁的状态，依赖于具体的架构实现。

* break_lock

    标志着进程正在忙等待锁（仅当内核同时支持SMP和内核抢占时才会出现）。

接下来，我们分析加锁的流程。

<h4 id="5.2.4.1">5.2.4.1 spin_lock()函数</h4>

本章我们直接看源代码，用函数出现的顺序表示函数调用的顺序。首先，看加锁的函数为:

    static __always_inline void spin_lock(spinlock_t *lock)
    {
        raw_spin_lock(&lock->rlock);
    }

`raw_spin_lock`函数的代码如下：

    #define raw_spin_lock(lock) _raw_spin_lock(lock)

`_raw_spin_lock`函数分为2个版本：SMP版本和UP版本。

1. UP版本的代码如下：

    `_raw_spin_lock`函数：

        #define _raw_spin_lock(lock)            __LOCK(lock)

    `__LOCK`函数代码如下：

        #define __LOCK(lock) \
                do { preempt_disable(); ___LOCK(lock); } while (0)

    可以看出，首先禁止内核抢占。然后调用

        #define ___LOCK(lock) \
                do { __acquire(lock); (void)(lock); } while (0)

    从上面的代码可以看出，单核系统没有处于debug状态时，没有真正的锁在运行。因此，就是禁止了内核抢占。至于`void`是避免编译器对未使用的锁变量发出警告。`__acquire(lock)`就是给检查器（CHECKER）添加适当的注释。真正的定义就是`# define __acquire(x) (void)0`。

2. SMP版本的代码如下：

    `_raw_spin_lock`函数：
    
    ```c
    static inline void __raw_spin_lock(raw_spinlock_t *lock)
    {
        // 禁止内核抢占
        preempt_disable();
        // debug用
        spin_acquire(&lock->dep_map, 0, 0, _RET_IP_);
        // 真正申请锁的地方
        LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
    }
    ```

    `LOCK_CONTENDED`是一个通用的加锁流程。`do_raw_spin_trylock`和`do_raw_spin_lock`的实现依赖于具体的体系结构，以`x86`为例，`do_raw_spin_trylock`最终调用的是：

        static inline int do_raw_spin_trylock(raw_spinlock_t *lock)
        {
            return arch_spin_trylock(&(lock)->raw_lock);
        }

    `arch_spin_trylock`函数的实现依赖于具体的体系架构，以X86为例，代码如下：

        typedef struct arch_spinlock {
            union {
                __ticketpair_t head_tail;
                struct __raw_tickets {
                    __ticket_t head, tail; // 注意，x86使用的是小端模式，存在高地址空间的是tail
                } tickets;
            };
        } arch_spinlock_t;

        static __always_inline int arch_spin_trylock(arch_spinlock_t *lock)
        {
            arch_spinlock_t old, new;

            // 获取旧的ticket信息
            old.tickets = READ_ONCE(lock->tickets);
            // head和tail不一致，说明锁正在被占用，加锁不成功
            if (!__tickets_equal(old.tickets.head, old.tickets.tail))
                return 0;

            // 将tail + 1
            new.head_tail = old.head_tail + (TICKET_LOCK_INC << TICKET_SHIFT);
            new.head_tail &= ~TICKET_SLOWPATH_FLAG;

            /* cmpxchg是一个完整的内存屏障 */
            return cmpxchg(&lock->head_tail, old.head_tail, new.head_tail) == old.head_tail;
        }

    从上述代码中可知，`arch_spin_trylock`的核心功能，就是判断自旋锁是否被占用，如果没被占用，尝试原子性地更新lock中的`head_tail`的值，将tail+1，返回是否加锁成功。

    不考虑CONFIG_DEBUG_SPINLOCK宏的话，` do_raw_spin_lock`的源代码如下：

        static inline void do_raw_spin_lock(raw_spinlock_t *lock) __acquires(lock)
        {
            __acquire(lock);
            arch_spin_lock(&lock->raw_lock);
        }

    `arch_spin_lock`函数的源代码：

        static __always_inline void arch_spin_lock(arch_spinlock_t *lock)
        {
            register struct __raw_tickets inc = { .tail = TICKET_LOCK_INC };

            // 原子性地把ticket中的tail+1，返回的inc是+1之前的原始值
            inc = xadd(&lock->tickets, inc);
            if (likely(inc.head == inc.tail))
                goto out;

            for (;;) {
                unsigned count = SPIN_THRESHOLD;

                do {
                    // 读取新的head值
                    inc.head = READ_ONCE(lock->tickets.head);
                    if (__tickets_equal(inc.head, inc.tail))
                        goto clear_slowpath;
                    cpu_relax();
                } while (--count);
                __ticket_lock_spinning(lock, inc.tail);
            }
        // 循环直到head和tail相等
        clear_slowpath:
            __ticket_check_and_clear_slowpath(lock, inc.head);
        out:
            barrier();  /* make sure nothing creeps before the lock is taken */
        }

    `__ticket_check_and_clear_slowpath`函数执行的操作是把tail加1，并把之前的值记录下来，完成加锁操作。

        static inline void __ticket_check_and_clear_slowpath(arch_spinlock_t *lock,
                                    __ticket_t head)
        {
            if (head & TICKET_SLOWPATH_FLAG) {
                arch_spinlock_t old, new;

                old.tickets.head = head;
                new.tickets.head = head & ~TICKET_SLOWPATH_FLAG;
                old.tickets.tail = new.tickets.head + TICKET_LOCK_INC;
                new.tickets.tail = old.tickets.tail;

                /* try to clear slowpath flag when there are no contenders */
                cmpxchg(&lock->head_tail, old.head_tail, new.head_tail);
            }
        }

    至此，就完成了申请锁的操作。接下来我们再来研究一下，解锁流程。

<h4 id="5.2.4.3">5.2.4.3 spin_unlock函数</h4>

对于SMP架构来说，`spin_unlock`最终调用的是`__raw_spin_unlock`，其源代码如下：

    static inline void __raw_spin_unlock(raw_spinlock_t *lock)
    {
        spin_release(&lock->dep_map, 1, _RET_IP_);
        do_raw_spin_unlock(lock);   // 完成主要的解锁工作
        preempt_enable();           // 启动抢占
    }

    static inline void do_raw_spin_unlock(raw_spinlock_t *lock) __releases(lock)
    {
        arch_spin_unlock(&lock->raw_lock);
        __release(lock);
    }

`arch_spin_unlock`函数的代码如下：

    static __always_inline void arch_spin_unlock(arch_spinlock_t *lock)
    {
        if (TICKET_SLOWPATH_FLAG &&
            static_key_false(&paravirt_ticketlocks_enabled)) {
            __ticket_t head;

            BUILD_BUG_ON(((__ticket_t)NR_CPUS) != NR_CPUS);

            // 主要内容：将head+1；所以现在head>tail表示锁又空闲了。
            head = xadd(&lock->tickets.head, TICKET_LOCK_INC);

            if (unlikely(head & TICKET_SLOWPATH_FLAG)) {
                head &= ~TICKET_SLOWPATH_FLAG;
                __ticket_unlock_kick(lock, (head + TICKET_LOCK_INC));
            }
        } else
            __add(&lock->tickets.head, TICKET_LOCK_INC, UNLOCK_LOCK_PREFIX);
    }

所以，解锁的过程就是将head和tail不相等，且重新使能内核抢占的过程。

<h3 id="5.2.5">5.2.5 `读/写自旋锁`</h3>

自旋锁解决了多核系统在内核抢占模式下的数据共享问题。但是，这样的自旋锁一次只能一个内核控制路径使用，这严重影响了系统的并发性能。根据我们以往的开发经验，大部分的程序都是读取共享的数据，并不更改；只有少数时候会修改数据。为此，Linux内核提出了`读/写自旋锁`的概念。也就是说，没有内核控制路径修改共享数据的时候，多个内核控制路径可以同时读取它。如果有内核控制路径想要修改这个数据结构，它就申请`读/写自旋锁`的写自旋锁，独占访问这个资源。这大大提高了系统的并发性能。

`读/写自旋锁`的数据结构是`rwlock_t`，其定义如下：

    typedef struct {
        arch_rwlock_t raw_lock;
    #ifdef CONFIG_GENERIC_LOCKBREAK
        unsigned int break_lock;
    #endif
        ......
    } rwlock_t;

从上面的代码可以看出，`读/写自旋锁`的实现还是依赖于具体的架构体系。下面我们先以ARM体系解析一遍：

1. `arch_rwlock_t`的定义：

        typedef struct { 
            u32 lock; 
        } arch_rwlock_t;

2. 申请写自旋锁`arch_write_lock`的实现：

        static inline void arch_write_lock(arch_rwlock_t *rw)
        {
            unsigned long tmp;

            prefetchw(&rw->lock);   // ----------（0）
            __asm__ __volatile__(
        "1: ldrex   %0, [%1]\n"     // ----------（1）
        "   teq %0, #0\n"           // ----------（2）
            WFE("ne")               // ----------（3）
        "   strexeq %0, %2, [%1]\n" // ----------（4）
        "   teq %0, #0\n"           // ----------（5）
        "   bne 1b"                 // ----------（6）
            : "=&r" (tmp)
            : "r" (&rw->lock), "r" (0x80000000)
            : "cc");

            smp_mb();               // ----------（7）
        }

    * （0）通知硬件提前将`rw->lock`的值加载到cache中，缩短等待预取指令的时延。
    * （1）使用独占指令`ldrex`标记相应的内存位置已经被独占，并将其值存储到tmp变量中。
    * （2）判断tmp是否等于0。
    * （3）如果tmp不等于0，则说明rw->lock正在被占用，所以进入低功耗待机模式。
    * （4）如果tmp等于0，则向rw->lock的内存地址处写入`0x80000000`，然后清除独占标记。
    * （5）测试tmp是否等于0，相当于验证第4步是否成功。
    * （6）如果加锁失败，则重新（0）->（5）的过程。
    * （7）现在只是把指令写入到数据总线上，还没有完全成功。所以`smp_mb()`内存屏障保证加锁成功。

3. 写自旋锁的释放过程，`arch_write_unlock`函数实现，代码如下：

        static inline void arch_write_unlock(arch_rwlock_t *rw)
        {
            smp_mb();           // ----------（0）

            __asm__ __volatile__(
            "str    %1, [%0]\n" // ----------（1）
            :
            : "r" (&rw->lock), "r" (0)
            : "cc");

            dsb_sev();          // ----------（2）
        }

    * （0）保证释放锁之前的操作都完成。
    * （1）将`rw->lock`的值赋值为0。
    * （2）调用sev指令，唤醒正在执行WFE指令的内核控制路径。

4. 读自旋锁的申请过程（低功耗版）由`arch_read_lock`函数实现，代码如下：

        static inline void arch_read_lock(arch_rwlock_t *rw)
        {
            unsigned long tmp, tmp2;

            prefetchw(&rw->lock);
            __asm__ __volatile__(
        "1: ldrex   %0, [%2]\n"     // ----------（0）
        "   adds    %0, %0, #1\n"   // ----------（1）
        "   strexpl %1, %0, [%2]\n" // ----------（2）
            WFE("mi")               // ----------（3）
        "   rsbpls  %0, %1, #0\n"   // ----------（4）
        "   bmi 1b"                 // ----------（5）
            : "=&r" (tmp), "=&r" (tmp2)
            : "r" (&rw->lock)
            : "cc");

            smp_mb();
        }

    * （0）读取`rw->lock`地址处的内容，然后标记为独占。
    * （1）tmp=tmp+1。
    * （2）将这条指令的执行结果写入到tmp2变量中，将tmp的值写入到`rw->lock`地址处。
    * （3）如果tmp是负值，说明锁已经被占有，则执行wfe指令，进入低功耗待机模式。
    * （4）执行0减去tmp2，将结果写入tmp。因为tmp2的值有2个：0-更新成功；1-更新失败。所以正常情况，此时tmp的结果应该为0，也就是申请加锁成功。
    * （5）如果加锁失败，则重新进行（0）->（4）的操作。失败的可能就是，独占标记被其它加锁操作破会。

5. 读自旋锁的申请过程（不断尝试版）由`arch_read_trylock`函数实现，代码如下：

        static inline int arch_read_trylock(arch_rwlock_t *rw)
        {
            unsigned long contended, res;

            prefetchw(&rw->lock);
            do {
                __asm__ __volatile__(
                "   ldrex   %0, [%2]\n"     // ----------（0）
                "   mov %1, #0\n"           // ----------（1）
                "   adds    %0, %0, #1\n"   // ----------（2）
                "   strexpl %1, %0, [%2]"   // ----------（3）
                : "=&r" (contended), "=&r" (res)
                : "r" (&rw->lock)
                : "cc");
            } while (res);                  // ----------（4）

            /* 如果lock为负，则已经处于write状态 */
            if (contended < 0x80000000) {   // ----------（5）
                smp_mb();
                return 1;
            } else {
                return 0;
            }
        }

    * （0）读取`rw->lock`地址处的内容，然后标记为独占。
    * （1）res = 0。
    * （2）contended = contended + 1。
    * （3）将contended的值写入`rw->lock`地址处，操作结果写入res。
    * （4）如果res等于0，操作成功；否则重新前面的操作。
    * （5）如果此时处于write状态，则申请锁失败，返回1；否则，成功返回0。

    根据4和5两个申请锁的过程分析，可以看出除了是否根据需要进入低功耗状态之外，其它没有区别。

6. 读自旋锁的释放过程由`arch_read_unlock`函数实现，代码如下：

        static inline void arch_read_unlock(arch_rwlock_t *rw)
        {
            unsigned long tmp, tmp2;

            smp_mb();

            prefetchw(&rw->lock);
            __asm__ __volatile__(
        "1: ldrex   %0, [%2]\n"     // ----------（0）
        "   sub %0, %0, #1\n"       // ----------（1）
        "   strex   %1, %0, [%2]\n" // ----------（2）
        "   teq %1, #0\n"           // ----------（3）
        "   bne 1b"                 // ----------（4）
            : "=&r" (tmp), "=&r" (tmp2)
            : "r" (&rw->lock)
            : "cc");

            if (tmp == 0)
                dsb_sev();
        }

    * （0）读取`rw->lock`地址处的内容，然后标记为独占。
    * （1）要退出临界区，所以，tmp = tmp - 1。
    * （2）tmp写入到`rw->lock`地址处，操作结果写入tmp2。
    * （3）判断tmp2是否等于0。
    * （4）等于0成功，不等于0，则跳转到标签1处继续执行。

通过上面的分析可以看出，读写自旋锁使用bit31表示写自旋锁，bit30-0表示读自旋锁，对于读自旋锁而言，绰绰有余了。

对于另一个成员`break_lock`来说，同自旋锁数据结构中的成员一样，标志锁的状态。

`rwlock_init`宏初始化读写锁的lock成员。

对于X86系统来说，处理的流程差不多。但是，因为与ARM架构体系不同，所以具体的加锁和释放锁的实现是不一样的。在此，就不一一细分析了。

<h3 id="5.2.6">5.2.6 Seqlock</h3>

1. 什么是seqlock锁？

上一篇文章中，我们已经学习了读/写自旋锁的工作原理和实现方式（基于ARM架构体系）。但是，有一个问题我们不得不考虑，那就是read锁和write锁的优先级问题：它们具有相同的优先级，所以，读操作必须等到写操作完成后才能执行，同样，写操作必须等到读操作完成后才能执行。

Linux2.6内核版本引入了`Seqlock`锁，与读写自旋锁基本一样，只是对于写操作来说，具有更高的优先级；也就是说，即使现在读操作正在执行，写操作也会被立即执行。这个策略的优点就是，写操作绝不会等待（除非是有其它写操作在占用锁）；缺点就是，读操作可能需要读取多次，才能获取正确的备份。

2. seqlock锁实现

`seqlock`锁的数据结构如下所示，包含两个数据成员`lock`和`seqcount`。查看代码可知，`seqlock`锁就是一个自旋锁加上一个序列计数器。

        typedef struct {
            struct seqcount seqcount;       // 序列计数器
            spinlock_t lock;
        } seqlock_t;

`seqlock`锁的工作原理是，对于读操作而言，每次读取数据前后，都要读取序列计数器2次，检查这前后两次的值是否一致，一致则认为可以使用锁。相反，如果一个新的写操作开始工作，增加序列计数器的值，隐含地告知读操作刚刚读到的数据不合法，需要重新读取数据。

`seqlock_t`类型变量初始化的方法有两种：一种是直接赋值`SEQLOCK_UNLOCKED`，另外一种是调用`seqlock_init`宏。写操作分别申请锁和释放锁，分别调用`write_seqlock()`和`write_sequnlock()`。申请锁的过程是，申请`seqlock_t`数据结构中的自旋锁，并对序列计数器进行加一操作。释放锁的过程是，再一次对序列计数器进行加一操作，并释放掉自旋锁。这样操作的结果就是，写操作过程中，计数器的计数是奇数；没有写操作的时候，计数器是偶数。

3. seqlock锁使用范例

对于读操作来说，大概的代码实现如下所示：

        unsigned int seq;
        do {
            seq = read_seqbegin(&seqlock);
            /* ... 临界代码段 ... */
        } while (read_seqretry(&seqlock, seq));

`read_seqbegin()`获取锁的当前序列号。`read_seqretry()`判断序列号是否一致，如果seq的值是奇数，则会返回1，也就是条件为真（也就是说，`read_seqbegin()`函数被调用之后，有写操作更新了数据）。因此，需要重新读取数据。如果seq的值是偶数，则读取数据成功。

值得注意的是，当读操作进入临界代码段时，无需禁止内核抢占。因为，我们允许写操作打断读操作的执行，这也是Seqlock锁写操作优先级高的设计初衷。但是，写操作进入临界代码段时，会自动禁止内核抢占。

4. seqlock锁使用场合

并不是所有的数据结构都能使用seqlock锁保护。因为seqlock锁有自身的缺点：因为写操作的优先级高于读操作，所以，对于写操作负荷比较的重的场合来说就不合适。如果写操作过于频繁，那么对读操作来说极为不公平，可能需要多次读取数据才能成功。所以，使用seqlock锁的场合应该满足下面的条件：

* 要保护的数据结构不能包含指针，而且这些指针写操作修改，读操作进行引用。因为可能写操作修改了指针，而读操作还会引用之前的指针。

* 要保护的数据结构必须是特别短小的代码，而且读操作比较频繁，写操作很少且非常快。（这也是读写自旋锁的使用原则）

* 读操作的临界代码段中的代码不能有副作用（否则，多次读操作可能与单次读取有不同的效果）。

典型应用可以参考linux内核关于系统时间处理的部分。

<h3 id="5.2.7">5.2.7 读-拷贝-更新（RCU）</h3>

每一种技术的出现必然是因为某种需求。正因为人的本性是贪婪的，所以科技的创新才能日新月异。

1. 引言

seqlock锁只能允许一个写操作，但是有些时候我们可能需要多个写操作可以并发执行。所以，Linux内核引入了读-拷贝-更新技术（英文是`Read-copy update`，简称RCU），它是另外一种同步技术，主要用来保护被多个CPU读取的数据结构。RCU允许多个读操作和多个写操作并发执行。更重要的是，RCU是一种免锁算法，也就是说，它没有使用共享的锁或计数器保护数据结构（但是，这儿还是主要指的读操作是无锁算法。而对于多个写操作来说，需要使用lock保护避免多个CPU的并发访问。所以，其使用场合也是比较严格的，多个写操作中的锁开销不能大于读操作采用无锁算法省下的开销）。这相对于读写自旋锁和seqlock来说，具有很大的优势，毕竟锁的申请和释放对Cache行的"窥视"和失效也是一个很大的负担。

> 1. Cache行的"窥视"，指的是因为每个CPU具有局部Cache，所以硬件snoop单元必须时时刻刻在"窥视"所有的Cache行，并对其不合法的数据进行失效处理，重新从内存获取数据替换到相应的Cache行中。而在这里，如果使用了共享的lock或者计数器，那么每次对其进行写操作，必然导致相应Cache行的失效。然后重新把使用这个lock的CPU的局部Cache进行更新。

2. RCU实现

既然RCU没有使用共享数据结构，那么它是如何神奇地实现同步技术的呢？其核心思想就是限制RCU的使用范围：

* 1. 只有动态分配的、通过指针进行访问的数据结构。
* 2. 进入RCU保护的临界代码段的内核控制路径不能休眠。

3. 基本操作

* 对于reader，RCU的基本操作为：
    
    * （1）调用`rcu_read_lock()`，进入RCU保护的临界代码段。等价于调用`preempt_disable()`。
    * （2）调用`rcu_dereference`，获取RCU保护的数据指针。然后通过该指针读取数据。当然了，在此期间读操作不能发生休眠。
    * （3）调用`rcu_read_unlock()`，离开RCU保护的临界代码段。等价于调用` preempt_enable()`。 

* 对于writer，RCU的基本操作为：

    * （1）拷贝一份旧数据到新数据，修改新数据。

    * （2）调用`rcu_assign_pointer()`，将RCU保护的指针修改为新数据的指针。
    
        因为指针的修改是一个原子操作，所以不会发生读写不一致的问题。但是，需要插入一个内存屏障保证只有在数据被修改完成后，其它CPU才能看见更新的指针。尤其是当使用了自旋锁保护RCU禁止多个写操作的并发访问的时候。

    * （3）调用`synchronize_rcu`，等待所有的读操作都离开临界代码段，完成同步。

        RCU技术的真正问题是当写操作更新了指针后，旧数据的存储空间不能立马释放。因为，这时候读操作可能还在读取旧数据，所以，必须等到所有的可能的读操作执行`rcu_read_unlock()`离开临界代码段后，旧数据的存储空间才能被释放。

    * （4）调用`call_rcu()`，完成旧数据存储空间的回收工作。

        该函数的参数是类型为`rcu_head`的描述符的地址。该描述符嵌入在要回收的数据结构的内部。该函数还有一个参数就是一个回调函数，当所有的CPU处于空闲状态的时候执行这个回调函数。这个函数通常是负责旧数据存储空间的释放工作。

        有一个问题需要注意的是，这个回调函数的执行是在另一个内核线程中执行。`call_rcu()`函数吧回调函数的地址和其参数存储在`rcu_head`描述符中，然后将这个描述符插入到每个CPU的回调函数列表中（这儿又体现了`per-CPU变量`的重要性）。每个系统时间滴答，内核都会检查局部CPU是否处于空闲状态。当所有的CPU处于空闲状态的时候，一个特殊的tasklet就会执行所有的回调函数，这个tasklet描述符存储在每个CPU的rcu_tasklet变量中。

4. 使用场合

    RCU是从Linux2.6版本引入的，主要使用在网络层和虚拟文件系统层。

<h3 id="5.2.8">5.2.8 信号量</h3>

对于信号量我们并不陌生。信号量在计算机科学中是一个很容易理解的概念。本质上，信号量就是一个简单的整数，对其进行的操作称为PV操作。进入某段临界代码段就会调用相关信号量的P操作；如果信号量的值大于0，该值会减1，进程继续执行。相反，如果信号量的值等于0，该进程就会等待，直到有其它程序释放该信号量。释放信号量的过程就称为V操作，通过增加信号量的值，唤醒正在等待的进程。

> <font color="blue">注：</font>
>
> 信号量，这一同步机制为什么称为PV操作。原来，这些术语都是来源于狄克斯特拉使用荷兰文定义的。因为在荷兰文中，通过叫`passeren`，释放叫`vrijgeven`，PV操作因此得名。这是在计算机术语中不是用英语表达的极少数的例子之一。

事实上，Linux提供了两类信号量：

* 内核使用的信号量
* 用户态使用的信号量（遵循`System V IPC`信号量要求）

在本文中，我们集中研究内核信号量，至于进程间通信使用的信号量以后再分析。所以，后面再提及的信号量指的是内核信号量。

信号量与自旋锁及其类型，不同之处是使用自旋锁的话，获取锁失败的时候，进入忙等待状态，也就是一直在自旋。而使用信号量的话，如果获取信号量失败，则相应的进程会被挂起，知道资源被释放，相应的进程就会继续运行。因此，信号量只能由那些允许休眠的程序可以使用，像中断处理程序和可延时函数等不能使用。

信号量的结构体是`semaphore`，包含下面的成员：

* count

    是一个`atomic_t`类型原子变量。该值如果大于0，则信号量处于释放状态，也就是可以被使用。如果等于0，说明信号量已经被占用，但是没有其它进程在等待信号量保护的资源。如果是负值，说明被保护的资源不可用且至少有一个进程在等待这个资源。

* wait

    休眠进程等待队列列表的地址，这些进程都是要访问该信号保护的资源。当然了，如果count大于0，这个等待队列是空的。

* sleepers

    标志是否有进程正在等待该信号。

虽然信号量可以支持很大的count，但是在linux内核中，大部分情况下还是使用信号量的一种特殊形式，也就是`互斥信号量（MUTEX）`。所以，在早期的内核版本（`2.6.37`之前），专门提供了一组函数：

    init_MUTEX()            // 将count设为1
    init_MUTEX_LOCKED()     // 将count设为0

用它们来初始化信号量，实现独占访问。init_MUTEX()函数将互斥信号设为1，允许进程使用这个互斥信号量加锁访问资源。init_MUTEX_LOCKED()函数将互斥信号量设为0，说明资源已经被锁住，进程想要访问资源需要先等待别的地方解锁，然后再请求锁独占访问该资源。这种初始化方式一般是在该资源需要其它地方准备好后才允许访问，所以初始状态先被锁住。等准备后，再释放锁允许等待进程访问资源。

另外，还分别有两个静态初始化方法：

    DECLARE_MUTEX
    DECLARE_MUTEX_LOCKED

这两个宏的作用和上面的初始化函数一致，但是静态分配信号量变量。当然了，count还可以被初始化为一个整数值n（n大于1），这样的话，可以允许多达n个进程并发访问资源。

但是，从Linux内核2.6.37版本之后，上面的函数和宏已经不存在。这是为什么呢？因为大家发现在Linux内核的设计实现中通常使用互斥信号量，而不会使用信号量。那既然如此，为什么不直接使用自旋锁和一个int型整数设计信号量呢？这样的话，因为自旋锁本身就有互斥性，代码岂不更为简洁？这样设计，还有一个原因就是之前使用atomic原子变量表示count，但是等待该信号量的进程队列还是需要自旋锁进行保护，有点重复。于是，2.6.37版本内核开始，就使用自旋锁和count设计信号量了。代码如下：

    struct semaphore {
        raw_spinlock_t      lock;
        unsigned int        count;
        struct list_head    wait_list;
    };

这样的设计使用起来更为方便简单。当然了，结构体的变化必然导致操作信号量的函数发生设计上的改变。

<h4 id="5.2.8.1">5.2.8.1 获取和释放信号量</h4>

前面我们已经知道，信号量实现在内核发展的过程中发生了更变。所以，其获取和释放信号量的过程必然也有了改变。为了更好的理解信号量，也为了尝试理解内核在设计上的一些思想和机制。我们还是先了解一下早期版本内核获取和释放信号量的过程。

因为信号量的释放过程比获取更为简单，所以我们先以释放信号量的过程为例进行分析。如果一个进程想要释放内核信号量，会调用up()函数。这个函数，本质上等价于下面的代码：

        movl $sem->count,%ecx
        lock; incl (%ecx)
        jg 1f               // 标号1后面的f字符表示向前跳转，如果是b表示向后跳转
        lea %ecx,%eax
        pushl %edx
        pushl %ecx
        call __up
        popl %ecx
        popl %edx
    1:

上面的代码实现的过程大概是，先把信号量的count拷贝到寄存器ecx中，然后使用lock指令原子地将ecx寄存器中的值加1。如果eax寄存器中的值大于0，说明没有进程在等待这个信号，则跳转到标号1处开始执行。使用加载有效地址指令`lea`将寄存器ecx中的值的地址加载到eax寄存器中，也就是说把变量sem->count的地址（因为count是第一个成员，所以其地址就是sem变量的地址）加载到eax寄存器中。至于两个pushl指令把edx和ecx压栈，是为了保存当前值。因为后面调用`__up()`函数的时候约定使用3个寄存器（eax，edx和ecx）传递参数，虽然此处只有一个参数。为此调用C函数的内核栈准备好了，可以调用`__up()`函数了。该函数的代码如下：
    
    __attribute__((regparm(3))) void __up(struct semaphore *sem)
    {
        wake_up(&sem->wait);
    }

反过来，如果一个进程想要请求一个内核信号量，调用`down()`函数，也就是实施p操作。该函数的实现比较复杂，但是大概内容如下：

        down:
        movl $sem->count,%ecx
        lock; decl (%ecx);
        jns 1f
        lea %ecx, %eax
        pushl %edx
        pushl %ecx
        call __down
        popl %ecx
        popl %edx
    1:

上面代码实现过程：移动sem->count到ecx寄存器中，然后对ecx寄存器进行原子操作，减1。然后检查它的值是否为负值。如果该值大于等于0，则说明当前进程请求信号量成功，可以执行信号量保护的代码区域；否则，说明信号量已经被占用，进程需要挂起休眠。因而，把sem->count的地址加载到eax寄存器中，并将edx和ecx寄存器压栈，为调用C语言函数做好准备。接下来，就可以调用`__down()`函数了。

`__down()`函数是一个C语言函数，内容如下：

    __attribute__((regparm(3))) void __down(struct semaphore * sem)
    {
        DECLARE_WAITQUEUE(wait, current);
        unsigned long flags;
        current->state = TASK_UNINTERRUPTIBLE;
        spin_lock_irqsave(&sem->wait.lock, flags);
        add_wait_queue_exclusive_locked(&sem->wait, &wait);
        sem->sleepers++;
        for (;;) {
            if (!atomic_add_negative(sem->sleepers-1, &sem->count)) {
                sem->sleepers = 0;
                break;
            }
            sem->sleepers = 1;
            spin_unlock_irqrestore(&sem->wait.lock, flags);
            schedule();
            spin_lock_irqsave(&sem->wait.lock, flags);
            current->state = TASK_UNINTERRUPTIBLE;
        }
        remove_wait_queue_locked(&sem->wait, &wait);
        wake_up_locked(&sem->wait);
        spin_unlock_irqrestore(&sem->wait.lock, flags);
        current->state = TASK_RUNNING;
    }

`__down()`函数改变进程的运行状态，从TASK_RUNNING到TASK_UNINTERRUPTIBLE，然后把它添加到该信号量的等待队列中。其中sem->wait中包含一个自旋锁spin_lock，使用它保护wait等待队列这个数据结构。同时，还要关闭本地中断。通常，queue操作函数从队列中插入或者删除一个元素，都是需要lock保护的，也就是说，有一个请求、释放锁的过程。但是，__down()函数还使用这个queue的自旋锁保护其它成员，所以扩大了锁的保护范围。所以调用的queue操作函数都是带有`_locked`后缀的函数，表示锁已经在函数外被请求成功了。

`__down()`函数的主要任务就是对信号量结构体中的count计数进行减1操作。sleepers如果等于0，则说明没有进行在等待队列中休眠；如果等于1，则相反。

以MUTEX信号量为例进行说明。

* 第1种情况：count等于1，sleepers等于0。

    也就是说，信号量现在没有进程使用，也没有等待该信号量的进程在休眠。`down()`直接通过自减指令设置count为0，满足跳转指令的条件是一个非负数，直接调转到标签1处开始执行，也就是请求信号量成功。那当然也就不会再调用`__down()`函数了。

* 第2种情况：count等于0，sleepers也等于0。

    这种情况下，会调用`__down()`函数进行处理（count等于-1），设置sleepers等于1。然后判断`atomic_add_negative()`函数的执行结果：因为在进入for循环之前，sleepers先进行了自加，所以，`sem->sleepers-1`等于0。所以，if条件不符合，不跳出循环。那么此时count等于-1，sleepers等于0。也就是说明请求信号量失败，因为已经有进程占用信号量，但是没有进程在等待这个信号量。然后，循环继续往下执行，设置sleepers等于1，表示当前进程将会被挂起，等待该信号量。然后执行schedule()，切换到那个持有信号量的进程执行，执行完之后释放信号量。也就是将count设为1，sleepers设为0。而当前被挂起的进程再次被唤醒后，继续检查if条件是否符合，因为此时count等于1，sleepers等于0。所以if条件为真，将sleepers设为0之后，跳出循环。请求锁失败。

* 第3种情况：count等于0，sleepers等于1。

    进入`__down()`函数之后（count等于-1），设置sleepers等于2。if条件为真，所以设置sleepers等于0，跳出循环。说明已经有一个持有信号量的进程在等待队列中。所以，跳出循环后，尝试唤醒等待队列中的进程执行。

* 第4种情况：count是-1，sleepers等于0。

    这种情况下，进入`__down()`函数之后，count等于-2，sleepers临时被设为1。那么`atomic_add_negative()`函数的计算结果小于0，返回1。if条件为假，继续往下执行，设置sleepers等于1，表明当前进程将被挂起。然后，执行schedule()，切换到持有该信号的进程运行。运行完后，释放信号量，唤醒当前的进程继续执行。而当前被挂起的进程再次被唤醒后，继续检查if条件是否符合，因为此时count等于1，sleepers等于0。所以if条件为真，将sleepers设为0之后，跳出循环。请求锁失败。

* 第5种情况：count是-1，sleepers等于1。

    这种情况下，进入`__down()`函数之后，count等于-2，sleepers临时被设为2。if条件为真，所以设置sleepers等于0，跳出循环。说明已经有一个持有信号量的进程在等待队列中。所以，跳出循环后，尝试唤醒等待队列中的进程执行。

通过上面几种情况的分析，我们可知不管哪种情况都能正常工作。wake_up()每次最多可以唤醒一个进程，因为在等待队列中的进程是互斥的，不可能同时有两个休眠进程被激活。

在上面的分析过程中，我们知道down()函数的实现过程，需要关闭中断，而且这个函数会挂起进程，而中断服务例程中是不能挂起进程的。所以，只有异常处理程序，尤其是系统调用服务例程可以调用down()函数。基于这个原因，Linux还提供了其它版本的请求信号量的函数：

1. down_trylock() 

    可以被中断和延时函数调用。基本上与down()函数的实现一致，除了当信号量不可用时立即返回，而不是将进程休眠外。

2.  down_interruptible()

    广泛的应用在驱动程序中，因为它允许当信号量忙时，允许进程可以接受信号，从而中止请求信号量的操作。如果正在休眠的进程在取得信号量之前被其它信号唤醒，这个函数将信号量的count值加1，并且返回`-EINTR`。正常返回0。驱动程序通常判断返回`-EINTR`后，终止I/O操作。

其实，通过上面的分析，很容易看出down()函数有点鸡肋。它能实现的功能，down_interruptible()函数都能实现。而且down_interruptible()还能满足中断处理程序和延时函数的调用。所以，在2.6.37版本以后的内核中，这个函数已经被废弃。

<h3 id="5.2.9">5.2.9 读写信号量</h3>

#### 读/写信号量的工作原理

读/写信号量和读/写自旋锁类似，不同的地方是进程在等待读/写信号量的时候处于挂起状态，而在等待读/写自旋锁的时候是处于忙等待，也就是自旋的状态中。

那也就是说，读/写信号量同读/写自旋锁一样，对于读操作，多个内核控制路径可以并发请求一个读写信号量；而对于写操作，每个内核控制路径必须独占访问受保护的资源。因此，对于读/写信号量来说，写操作的时候，既不可以进行读操作，也不可以进行写操作。读/写信号量提高了内核中的并发数量，也同时提高了系统的整体性能。

内核严格按照先进先出（FIFO）的原则处理等待读/写信号量的进程。读进程或者写进程一旦请求信号量失败，就被写到信号量等待队列的队尾。当信号量被释放后，队列中的第一个进程先被执行，因为它先被唤醒。如果唤醒的是一个写进程，那么队列中其它进程继续休眠。如果唤醒的是一个读进程，写进程之前的所有读进程都会被唤醒获得信号量；但是写进程之后的读进程继续休眠。

#### 读/写信号量的数据结构

读/写信号量使用数据结构`rw_semaphore`表示，其成员为：

* count

    一个32位的整形数，被分割成两个16位的计数器。高16位的计数器以2的补码形式表示非等待写进程和等待内核控制路径的数量，低16位表示非等待读进程和非等待写进程的总数。

* wait_list

    等待进程的列表。每个元素是一个`rwsem_waiter`数据结构，包含指向休眠进程描述符的指针和一个标志，这个标志表明进程申请信号量是要读取还是写入。

* wait_lock

    自旋锁，用来保护等待队列和`rw_semaphore`数据结构。

#### 读/写信号量的有关API

初始化函数为 `init_rwsem()`，用其可以初始化一个`rw_semaphore`数据结构，将count设为0，wait_lock自旋锁设为未使用，wait_list设为空列表。

`down_read()` 和 `down_write()`函数分别用来请求读信号量和写信号量。同理，`up_read()`和 `up_write()`函数分别用来释放读信号量和写信号量。`down_read_trylock()`和`down_write_trylock()`函数分别与`down_read()` 和 `down_write()`函数类似，只是当信号量忙的时候不会阻塞进程。最后，还有一个重要的函数，`downgrade_write()`，用于写进程使用完写信号量之后，自动将其转换成一个读信号量。这些函数的实现与普通信号量的实现极其类似，所以，在此，我们就不再详细描述其实现过程了。

<h3 id="5.2.10">5.2.10 Completion机制</h3>

内核编程中的一个常见模式就是在当前进程中，再去启动另外一个活动，比如创建新的内核线程或用户进程、向已存在的进程发起请求、再或者操作某些硬件。针对这些情况，内核当然可以尝试使用信号量同步两个任务，代码如下所示：

    struct semaphore sem;

    init_MUTEX_LOCKED(&sem);
    start_external_task(&sem);
    down(&sem);

把信号量初始化为一个关闭的互斥信号量，也就是count=0，然后启动外部任务并挂起等待信号量的释放。当外部的任务完成操作后，调用up(&sem)释放信号量，上面的代码继续往下执行。

正常逻辑下，上面的代码一点毛病没有。但世上的事就没有完美的。我们假设两种异常情况：第一种情况是，如果上面的代码是一个通信任务的话（我们都知道，通信任务一般对信号量的竞争都比较激烈），性能往往会变得非常糟糕，因为调用down()函数的进程几乎总是处于等待之中。第二种情况是，在多核系统中，假设定义的信号量只是一个临时变量，按照上面的调用关系，上面的代码一旦被唤醒就要销毁临时信号量的话，这个进程启动的外部任务很可能还处于执行up()函数的过程中。而此时，信号量已经被销毁，up()函数可能会尝试访问一个不存在的信号量数据结构。当然了，第二种情况可以使用其它指令，禁止down()和up()函数的并发执行。但是，这样的话，又增加了新的负荷。所以，并不是一个特别好的选择。

针对上面的情况，Linux内核从2.4.7版本开始，引入了另外一种同步技术：completion机制。

completion同步原语的数据结构如下代码所示：

    struct completion {
        unsigned int done;
        wait_queue_head_t wait;
    };

可以看出，其由一个整形数done和队列head组成。

与信号量的up()函数对应的函数称为complete()函数。它的参数是一个completion数据结构。这个函数会调用spin_lock_irqsave()函数，请求completion等待队列的保护自旋锁，增加done的值，唤醒等待队列中的休眠进程中的一个，最后调用spin_unlock_irqrestore()释放自旋锁。

与信号量的down()函数对应的称为wait_for_completion()函数。它的参数也是completion数据结构。这个函数会检查done的值：如果大于0，函数执行终止，因为另一个CPU上已经执行了complete()函数；否则，这个函数添加当前进程到等待队列的队尾，并使进程进入休眠，将其进程状态设为TASK_UNINTERRUPTIBLE（如果代码调用了该函数，而且被等待的任务没有完成，结果就是，等待的任务就是一个不可杀的进程）。一旦进程被唤醒，这个函数就会把当前进程从等待队列中删除。然后，再次检查done的值，如果等于0，则函数执行终止；否则，当前进程会再次被挂起。同complete()函数一样，这个函数也使用自旋锁保护等待队列。

completion和信号量的真正区别是等待队列中的自旋锁如何使用。在completion中，自旋锁被用来保证complete()和wait_for_completion()不会并发执行。在信号量中，自旋锁被用来保证并发执行的两个调用down()的函数不会弄乱信号量数据结构。

关于completion机制如何使用，请参考complete的模块示例。该模块定义了一个这样的模块：任何尝试读取设备的进程都会进入等待状态（通过调用wait_for_completion()函数实现），直到有其它进行尝试写该设备。代码类似于下面的代码：

    DECLARE_COMPLETION(comp);
    ssize_t complete_read (struct file *filp, char __user *buf, size_t count, loff_t
            *pos)
    {
        printk(KERN_DEBUG "process %i (%s) going to sleep\n",
                current->pid, current->comm);
        wait_for_completion(&comp);
        printk(KERN_DEBUG "awoken %i (%s)\n", current->pid, current->comm);
        return 0;
    }
    ssize_t complete_write (struct file *filp, const char __user *buf, size_t count,
            loff_t *pos)
    {
        printk(KERN_DEBUG "process %i (%s) awakening the readers...\n",
                current->pid, current->comm);
        complete(&comp);
        return count; /* 成功，避免重试 */
    }

在上面的示例中，可能存在多个进程同时读取设备。对设备的一次写操作只能试一个读操作完成，而无法通知其它正在读操作的进程。

completion机制的一个典型应用就是，在模块exit的时候，终止内核线程。在一些典型的例子中，驱动程序的内部工作是在内核线程中使用while(1)循环中实现的。当模块准备好清理时，exit函数就会告诉线程需要退出，然后等待线程的completion事件。基于这个目的，内核提供了一个特殊的函数供线程调用：

    void complete_and_exit(struct completion *c, long retval);

<h3 id="5.2.11">5.2.11 中断禁止</h3>

作为嵌入式软件开发人员，对于禁止中断肯定不陌生。尤其是基于MCU的嵌入式软件，因为就一个微处理器核，所以禁止中断是实现临界代码段的有效手段。笔者比较熟悉的μC/OS-II或III，就是使用禁止中断保护临界代码段。当然了，这样的临界代码段一般较短，就几行代码而已。如果太长，会影响整个系统任务的调度，也有可能导致中断信号的丢失。

同样，Linux也不会放弃禁止中断这么好的同步机制。它保证内核控制路径可以继续执行，其访问的数据结构不会被中断处理程序破坏。但是，多核系统中，中断禁止是一个局部概念，也就是说，只是某一个CPU核中断被禁止，不能阻止运行在其它CPU上的中断处理程序访问要保护的数据结构。所以，在多核系统中，内核数据结构的保护一般是禁止中断搭配自旋锁一起使用。

local_irq_disable()利用cli汇编指令，禁止局部CPU的中断；local_irq_enable()利用sti汇编指令使能中断。正如在讲解"IRQ和中断"时所说的那样，cli和sti汇编指令，分别用来清除和设置eflags寄存器中的IF标志。

当内核代码进入临界代码段时，通过清除eflags寄存器中的IF标志实现禁止中断，从而保护临界代码段。但是，当内核离开临界代码段的时候，内核是否该恢复之前的IF标志呢？还是不做任何处理？显然，不做任何处理是不可以的，因为那样的话，就会丢失某些中断信号，这对于一个安全可靠的系统而言，是非常荒谬的。我们知道中断是以嵌套的方式被执行的，所以内核无需知道之前是什么具体的IF标志。只需要记录之前的标志值，在退出临界代码段的时候恢复之前的IF标志即可。

保存和恢复eflags内容，可以分别通过local_irq_save()和local_irq_restore()实现。local_irq_save拷贝eflags内容到一个局部变量中，然后调用cli指令清除IF标志。退出临界代码段的时候，local_irq_restore再把局部变量中的内容拷贝到eflags寄存器中。

<h3 id="5.2.12">5.2.12 软中断禁止</h3>

在讲软中断的时候，我们知晓可延时函数的执行时间是不可预测的（基本上都是在硬件中断处理程序终止的时候，因为软中断的实现大部分时候都是给tasklet服务的，而tasklet的用处就是协助硬件处理程序处理那些耗时长，又不是那么紧急的任务的）。因此，可延时函数要访问的数据结构必须被保护起来，防止竞态条件的产生。

可能很多人都想到了一个简单粗暴的方法，直接禁止那个CPU的中断不就可以了吗。没有中断处理程序被激活，软中断的行为也就不会发生混乱。

但是，事情不会那么简单，有时候，内核需要只禁止可延时函数，而不禁止中断。那怎么实现呢？

回忆do_softirq()函数，如果软中断计数器（存储在当前线程thread_info描述符的preempt_count成员中）是正数，它就不会处理软中断。所以，将这个计数器设为正数，软中断不会执行，在其上的所有可延时函数也不会执行。

local_bh_disable()给局部CPU的软中断计数器加1，local_bh_enable()则是将其减1。local_bh_disable()可以嵌套多调用几次，如果调用local_bh_enable()的次数匹配，可延时函数就会被使能。

为了确保及时执行长时间等待的线程，local_bh_enable()对软中断计数器执行减1操作之后，还有执行两个重要的操作：

1. 检查preempt_count中的硬中断计数器和软中断计数器。如果都是0，且有挂起的软中断要执行，直接调用do_softirq()激活它们。

2. 检查局部CPU的 TIF_NEED_RESCHED标志是否被设置；如果被设置，说明此时有进程正在请求调度，然后调用preempt_schedule()执行抢占调度。

<h2 id="5.3">5.3 内核数据结构的同步访问</h2>

前面，我们学习了这么多内核同步技术。那我们该怎么选择呢？选择不同的内核同步技术，可能对系统的性能影响很大。根据经验，基本可以遵守这么一条准则：**尽可能高地保证系统的并发性**。

而系统的并发水平又依赖于两个关键的因素：

* 可以并发访问的I/O设备数量；
* 能够执行有效工作的CPU数量。

为了最大化I/O的吞吐量，中断禁止的时间应该尽可能短。我们知道，如果中断被禁止，I/O设备发出的IRQ信号会被PIC中断控制器临时性地忽略，也就不会相应I/O设备的请求。

为了使CPU的效率最大化，基于自旋锁的内核同步原语尽可能不用。因为，当CPU忙等待自旋锁被释放的时候，其实浪费了珍贵的机器执行周期。甚至更糟糕的是，自旋锁还会影响硬件Cache，强迫Cache失效，从而从内存中重新读取数据，刷新Cache，这大大降低了系统的整体性能。这就是为什么多核系统不能达到1+1=2的效果的原因。

让我们举几个例子来说明如何在保持高并发水平的同时还能实现同步：

* 如果共享的数据结构是一个简单的整数，那么可以使用atomic_t类型的原子变量声明它。原子操作比自旋锁和禁止中断都快，它只是降低了并发访问数据的内核控制路径的执行速度。

* 但是，往链表中插入元素就不是原子的，因为至少包含两个指针赋值操作。然而，内核有时候可以在不使用锁或禁止中断的前提下执行这种插入操作。比如，系统调用服务例程中，系统调用插入新元素到一个单链表中，而中断处理程序或可延时函数异步遍历这个列表，就无须锁的保护。

另外，在内核的实现代码中，我们经常需要对列表进行插入操作，通常使用指针赋值的方式实现，如下所示：

    new->next = list_element->next;
    list_element->next = new;

将上面的代码转换成汇编语言之后，就成为2条连续的原子指令操作。第1条指令建立新元素的next指针，但是不会修改列表。第2条指令将其存入对应的内存位置。假设，在这2条指令执行之间来一个中断信号，则中断处理程序看到的列表没有新元素；如果中断信号在第2条指令执行之后到来，则中断处理程序看到是的已经插入新元素的列表。任何一种情况，列表的数据都是正确的，没有被破坏的。但是，必须保证中断处理程序不会修改这个列表。如果其修改了列表，next指针很可能就会变成非法值。

更重要的是，这两条指令是由时序关系的。只有先创建了next指针，才能给其赋值；否则，操作不合法。所以，对于上面的代码，内核开发者应该保证它们的执行顺序，不会被编译器或者CPU控制单元破坏。否则，在两条赋值语句之间插入进来执行的中断服务程序，会发现一个被破坏了的列表。这时候，往往需要一个写内存屏障原语，如下所示：
        
        new->next = list_element->next;
        wmb();
        list_element->next = new;

到这儿，很多人可能会纳闷：为什么我在编写内核代码或者驱动程序的时候，怎么机会不使用wmb()之类的内存屏障呢？那是因为，Linux内核提供的操作函数API已经封装了内存屏障原语。所以，大部分时候我们不需要关心它。

通过上面的分析，我们可以得出的结论就是：尽可能提高系统的并发性，也就是压榨CPU能够有效工作的时间。为此，在保护要访问的数据的同时，尽可能不要选择自旋锁、信号量和关闭中断之类的加锁机制。因为它们往往让CPU处于无效工作时间中，降低系统的性能。

但是，许多时候我们别无选择，只能使用这些降低系统性能的加锁机制。当我们不得不面对的时候，我们又该如何抉择呢？

<h3 id="5.3.1">5.3.1 如何选择自旋锁、信号量和关闭中断</h3>

不幸的是，访问内核数据结构的形式远远比上面的示例复杂多了，迫使内核开发者不得不启动信号量、自旋锁和中断禁止这些锁原语。通常来讲，具体选择哪种加锁机制，取决于访问数据的是哪种内核控制路径，如下表所示。但需要注意的一点是，无论何时，内核控制路径请求一个自旋锁（包括读写锁，seqlock和RCU）时，都会禁止局部中断或者软中断，从而禁止内核抢占。

表5-8 不同内核控制路径访问的数据结构需要的锁

| 内核控制路径 | 单核系统 | 多核系统 |
| ------------ | -------- | -------- |
| 异常处理程序 | 信号量   | 信号量 |
| 中断处理程序 | 禁止中断 | 自旋锁 |
| 可延时函数   | 无       | 无/自旋锁 |
| 异常处理程序+ <br> 中断处理程序| 禁止中断 | 自旋锁 |
| 异常处理程序+ <br> 可延时函数  | 禁止软中断 | 自旋锁 |
| 中断处理程序+ <br> 可延时函数  | 禁止中断 | 自旋锁 |
| 中断处理程序+ <br> 可延时函数+ <br> 异常处理程序 | 禁止中断 | 自旋锁 |

在了解这些不同的内核控制路径访问的数据结构应该如何保护之前，我们先来复习几个概念：

1. 硬中断和软中断的区别

    严格意义上来说，中断可以分为同步中断和异步中断。而所谓的同步中断肯定就是CPU自身产生的中断，也就是所谓的异常。比如，除零操作就会产生硬件错误，在嵌入式内核中很常见这之类的错误。对于这类错误，首先应该能避免就避免，这是我们嵌入式开发者或者内核开发者必须要考虑的工作；实在无法避免（有时候可能还要故意产生硬件异常，比如Linux就利用页错误做特殊处理），就要编写异常处理程序进行必要处理，比如发送信号给当前进程等。

    对于异常，在此不做过多描述。所以，在此，所说的中断特指异步中断，主要用来服务I/O设备还有CPU之间的中断。为了及时响应外部I/O设备和其它CPU，中断直接打断CPU的执行，让其执行对应的中断处理程序。所以，中断处理程序必须占用CPU的时间极短，且不能发生阻塞操作，但允许嵌套中断执行。

    但是，有时候，中断信号所引发的操作比较复杂，但是可以分为需要及时处理和可以延时处理的部分。对于需要及时处理的部分就交给中断处理程序直接处理就好了，也就是我们常说的概念-顶半部。而对于可延时处理的部分，Linux提出了其它的概念来处理，比如说软中断、tasklet和工作队列。

2. 软中断

    那软中断的工作原理又是什么呢？软中断是内核在编译阶段就预先定义好的，这是一个数组，数组元素个数正好是内核支持的软中断数量（Linux目前是32个，但实际只用了6个），而恰恰，内核为每个CPU都维护着一个表示软中断挂起标志位的32位变量，正好对应上面的数组元素个数。也就是说，哪个CPU将相应的bit位设置为1，这个CPU就需要处理这个软中断，至于软中断处理程序在预编译的时候已经写好了。这样的处理行为与硬中断完全一样，对于同一个软中断，每个CPU都有可能执行处理（所以，软中断要访问的数据结构必须使用自旋锁进行保护）。唯一不同的是，软中断的触发时机与硬中断不同：硬中断直接由硬件打断CPU的执行，调用相应的处理程序；而软中断的触发时机完全由内核设计者定义（也就是说，你可以让它任何时候触发）。但是，这样的机制也就固化了其处理行为，因为是预先定义好的。也就是说，用户无法根据自己的需要，设计自定义的软中断处理程序了。这怎么能行呢？于是，Linux在此基础上又提出了另一个概念，tasklet。

3. tasklet

    Linux拿出其中的2个软中断，专门处理tasklet（一个高优先级，一个低优先级）。但是，tasklet的处理流程又大不一样。怎么不一样呢？就是哪个CPU激活的tasklet，一般就由哪个CPU执行，效率优先嘛。但是，不排除，在一个CPU上激活，在另一个CPU上执行的使用情况。但是，无论哪种情况，它们的执行都是与CPU绑定在一起的，也就是一一对应，也就是不存在并发访问同一个tasklet的时候。

4. 工作队列

    其实工作队列与tasklet的行为极其类似，只是软中断和tasklet都是在中断上下文中调用的，也就是不允许阻塞；而工作队列是运行在进程上下文中，也就是说，这是为内核线程处理延时任务提供的一种机制。故暂时不在本文的讨论范畴之内。

#### 异常程序访问的数据结构

只有异常处理程序访问的数据结构，可能产生的竞态条件简单易懂，也很容易保护。最常见的异常处理程序就是系统调用，因为它可能被多个进程并发调用，从而为用户态的程序提供内核服务。所以说，异常处理程序访问的数据结构就是可以分配给一个或多个进程的一种资源。

避免这种资源可能产生的竞态条件，可以选择信号量，因为大部分情况下，想要访问这个资源的进程如果没有得到资源的使用权的话会选择休眠等待。而恰好，信号量就是这样的一种加锁机制。如果请求信号量失败，进程挂起，让出CPU的使用权给其它进程。这种情况下，自旋锁是不合适的，因为它是忙等待，一直占用CPU。值得一提的是，不论是单核系统还是多核系统，信号量都能工作的很好。

即使是开启内核抢占，也不会产生问题。如果持有信号量的进程被抢占，新进程会尝试申请信号量。但是，这时候申请信号量肯定失败，从而新进程进入休眠，等待旧进程释放信号量。

#### 中断程序访问的数据结构

我们这儿要讨论的数据结构只是被中断程序的顶半部访问，不涉及底半部访问的数据结构，这类数据结构属于可延时函数访问的数据结构的范畴，后面再讨论。我们在学习中断的时候，已经知道，中断处理程序中的处理是串行化的，也就是说不会发生并发访问。所以，也就不需要同步。

但是，当数据结构被多个中断程序访问的时候，就会发生并发访问产生的竞态问题。尤其是在多核系统中，一个数据结构可能被多个不同的中断程序并发访问。这时候就需要同步了。

单核系统，竞态条件很好避免，只要关闭中断即可。其它同步技术也不合适。信号量阻塞进程，而中断万万不能被阻塞。另一方面，自旋锁会冻结系统：如果中断中正在访问的数据结构被中断，它不会释放锁；而新的中断程序一直在忙等待这个锁。其实就是发生了死锁。

多核系统处理更为复杂一些。因为中断都是局部中断，也就是每个CPU独享的。所以，只是简单的关闭中断无法有效避免竞态条件。因为，即使中断被禁止，其它CPU上的中断处理程序还会继续执行。所以，这时候需要关闭中断的同时，再申请一个自旋锁或者读写自旋锁保护数据结构。值得注意的是，这类自旋锁不会冻结系统。首先，因为关闭局部中断，所以同一CPU上的中断程序不会执行，也就不会发生上面所说的死锁。其次，因为是多核系统，中断程序发现锁被占用了，也不会阻止其它CPU上的中断程序释放这个锁。所以，无论哪种情况都不会发生死锁的情况。

为了方便处理多核系统中这种局部中断禁止和自旋锁结合在一起使用的情况，Linux提供了一些宏，如下表所示。单核系统中，这些宏只能禁止中断或者禁止内核抢占。

表5-9 与中断有关的自旋锁宏

| 宏    | 描述        |
| ----- | ----------- |
| spin_lock_irq(l)                  | local_irq_disable();  <br> spin_lock(l) |
| unlock_irq(l)                     | spin_unlock(l);       <br> local_irq_enable() |
| spin_lock_bh(l)                   | local_bh_disable();   <br> spin_lock(l) |
| spin_unlock_bh(l)                 | spin_unlock(l);       <br> local_bh_enable() |
| spin_lock_irqsave(l,f)            | local_irq_save(f);    <br> spin_lock(l) |
| spin_unlock_irqrestore(l,f)       | spin_unlock(l);       <br> local_irq_restore(f) |
| read_lock_irq(l)                  | local_irq_disable( ); <br> read_lock(l) |
| read_unlock_irq(l)                | read_unlock(l);       <br> local_irq_enable( ) |
| read_lock_bh(l)                   | local_bh_disable( );  <br> read_lock(l) |
| read_unlock_bh(l)                 | read_unlock(l);       <br> local_bh_enable( ) |
| write_lock_irq(l)                 | local_irq_disable();  <br> write_lock(l) |
| write_unlock_irq(l)               | write_unlock(l);      <br> local_irq_enable( ) |
| write_lock_bh(l)                  | local_bh_disable();   <br> write_lock(l) |
| write_unlock_bh(l)                | write_unlock(l);      <br> local_bh_enable( ) |
| read_lock_irqsave(l,f)            | local_irq_save(f);    <br> read_lock(l) |
| read_unlock_irqrestore(l,f)       | read_unlock(l);       <br> local_irq_restore(f) |
| write_lock_irqsave(l,f)           | local_irq_save(f);    <br> write_lock(l) |
| write_unlock_irqrestore(l,f)      | write_unlock(l);      <br> local_irq_restore(f) |
| read_seqbegin_irqsave(l,f)        | local_irq_save(f);    <br> read_seqbegin(l) |
| read_seqretry_irqrestore(l,v,f)   | read_seqretry(l,v);   <br> local_irq_restore(f) |
| write_seqlock_irqsave(l,f)        | local_irq_save(f);    <br> write_seqlock(l) |
| write_sequnlock_irqrestore(l,f)   | write_sequnlock(l);   <br> local_irq_restore(f) |
| write_seqlock_irq(l)              | local_irq_disable();  <br> write_seqlock(l) |
| write_sequnlock_irq(l)            | write_sequnlock(l);   <br> local_irq_enable() |
| write_seqlock_bh(l)               | local_bh_disable();   <br> write_seqlock(l) |
| write_sequnlock_bh(l)             | write_sequnlock(l);   <br> local_bh_enable() |

#### 可延时函数访问的数据结构

通过前面软中断、tasklet等概念的梳理，想必你对它们要访问的数据需要的保护方式有了一些初步的理解：采用哪种同步技术保护数据结构，完全取决于是属于哪类可延时函数。接下来，我们详细一一分析。

单核系统，通过上面的分析，不论是哪种机制访问数据结构，都不会产生竞态条件。因为它不会被其它可延时函数中断。也就无需使用同步了。

相反，多核系统就可能发生并发访问所带来的竞态问题。如下表所示，根据可延时函数的类型进行了列举：

| 延时函数类型 | 保护机制 |
| ------------ | -------- |
| 软中断       | 自旋锁   |
| 一个tasklet  | 无需锁   |
| 多个tasklet  | 自旋锁   |

如前所述，软中断总是需要自旋锁进行保护，因为即使是同一个软中断也有可能被多个CPU并发访问。相反，一个tasklet不需要锁的保护，因为同一个tasklet不会发生并发访问。但是，如果数据被多个tasklet访问，就需要加锁保护了。

#### 异常和中断同时访问的数据结构

如果数据结构既被异常处理程序（如系统调用）访问，又被中断处理程序访问，那该怎么保护数据呢？

对于这种情况，单核系统的处理非常简单，关闭中断即可。因为中断程序不可重入，也不能被异常处理程序中断。所以只要关闭中断，内核访问数据就不会被中断。

多核系统，我们就不得不考虑多个CPU的并发访问了。所以与中断访问数据一样，采用关闭中断与自旋锁相结合的方式。

但是，有时候使用信号量代替上面的自旋锁可能更好。由其是异常处理程序等不到锁需要挂起的时候。举例来说，系统调用和中断同时访问某个数据：中断处理程序尝试申请信号量（调用down_trylock()），失败就不断尝试，还是相当于自旋锁的忙等待；另一方面，系统调用如果申请信号量失败，就挂起，让CPU执行其它操作，这完全符合系统调用时的预期行为。这种情况，信号量优于自旋锁，因为它让系统有一个更高的并发性能。

#### 异常和可延时函数同时访问的数据结构

异常和可延时函数同时访问数据时，处理方式与异常和中断同时访问数据时类似。因为可延时函数本质上都是中断激活的，也是运行在中断上下文中的，在运行期间不会被异常中断。也就是说，使用关闭中断和自旋锁相结合的方式就足够了。

实际上，不用关闭硬中断即可，也就是调用local_bh_disable宏，只关闭可延时函数的执行。因为中断处理程序并没有访问数据，所以，只禁止可延时函数比禁止中断更有效率，因为中断可以继续被CPU响应。而在单个CPU上执行可延时函数是串行执行的，没有竞态条件产生。（这儿，禁止可延时函数指的是禁止再激活软中断，tasklet之类的，但是之前已经激活的还是要执行的。）

正如多数情况一样，多核系统中，自旋锁保证任何时候只有一个内核控制路径访问数据。

#### 中断和可延时函数同时访问的数据结构

这种情况与中断和异常同时访问数据相似。单核系统，禁止中断即可。多核系统需要再加上自旋锁。

#### 中断、异常和可延时函数同时访问的数据结构

与上一种情况一样，故不再累述。

<h2 id="5.4">5.4 防止竞态条件的例子</h2>

要想一个系统不崩溃，性能还得好，同步技术是非常关键的。但是，完全避免竞态条件几乎是难于上青天。因为它要求对内核各个功能模块之间的交互得有一个清晰深刻的理解。下面我们看一下Linux内核中一些具体保护数据访问的示例，加深对其理解，甚至可以在自己的内核设计上借鉴一下。

<h3 id="5.4.1">5.4.1 引用计数器</h3>

引用计数器是内核中保护某个资源或者模块的一种有效手段，比如分配内存，使用某个内核模块，或者打开某个文件的时候。它是一个atomic_t类型的原子变量。当内核中某个程序访问该资源的时候，计数器加1，当内核程序释放资源，计数器减1。当计数器的值为0时，它就可以被释放了。

<h3 id="5.4.2">5.4.2 大内核锁</h3>

关于这部分请参阅网友universus写的这篇文章-[大内核锁将何去何从](https://blog.csdn.net/universus/article/details/5623971)。我觉得写得还是非常详细的。

In earlier Linux kernel versions, a big kernel lock (also known as global kernel lock, or BKL) was widely used. In Linux 2.0, this lock was a relatively crude spin lock, ensuring that only one processor at a time could run in Kernel Mode. The 2.2 and 2.4 kernels were considerably more flexible and no longer relied on a single spin lock; rather, a large number of kernel data structures were protected by many different spin locks. In Linux kernel version 2.6, the big kernel lock is used to protect old code (mostly functions related to the VFS and to several filesystems).

Starting from kernel version 2.6.11, the big kernel lock is implemented by a semaphore named kernel_sem (in earlier 2.6 versions, the big kernel lock was implemented by means of a spin lock). The big kernel lock is slightly more sophisticated than a simple semaphore, however.

Every process descriptor includes a lock_depth field, which allows the same process to acquire the big kernel lock several times. Therefore, two consecutive requests for it will not hang the processor (as for normal locks). If the process has not acquired the lock, the field has the value –1; otherwise, the field value plus 1 specifies how many times the lock has been taken. The lock_depth field is crucial for allowing interrupt handlers, exception handlers, and deferrable functions to take the big kernel lock: without it, every asynchronous function that tries to get the big kernel lock could generate a deadlock if the current process already owns the lock.

The lock_kernel() and unlock_kernel() functions are used to get and release the big kernel lock. The former function is equivalent to:

    depth = current->lock_depth + 1;
    if (depth == 0)
        down(&kernel_sem);
    current->lock_depth = depth;

while the latter is equivalent to:

    if (--current->lock_depth < 0)
        up(&kernel_sem);

Notice that the if statements of the lock_kernel( ) and unlock_kernel( ) functions need not be executed atomically because lock_depth is not a global variable—each CPU addresses a field of its own current process descriptor. Local interrupts inside the if statements do not induce race conditions either. Even if the new kernel control path invokes lock_kernel( ), it must release the big kernel lock before terminating.

Surprisingly enough, a process holding the big kernel lock is allowed to invoke schedule(), thus relinquishing the CPU. The schedule() function, however, checks the lock_depth field of the process being replaced and, if its value is zero or positive, automatically releases the kernel_sem semaphore (see the section “The schedule( ) Function” in Chapter 7). Thus, no process that explicitly invokes schedule() can keep the big kernel lock across the process switch. The schedule() function, however, will reacquire the big kernel lock for the process when it will be selected again for execution.

Things are different, however, if a process that holds the big kernel lock is preempted by another process. Up to kernel version 2.6.10 this case could not occur, because acquiring a spin lock automatically disables kernel preemption. The current implementation of the big kernel lock, however, is based on a semaphore, and acquiring it does not automatically disable kernel preemption. Actually, allowing kernel preemption inside critical regions protected by the big kernel lock has been the main reason for changing its implementation. This, in turn, has beneficial effects on the response time of the system.

When a process holding the big kernel lock is preempted, schedule() must not release the semaphore because the process executing the code in the critical region has not voluntarily triggered a process switch, thus if the big kernel lock would be released, another process might take it and corrupt the data structures accessed by the preempted process.

To avoid the preempted process losing the big kernel lock, the preempt_schedule_irq() function temporarily sets the lock_depth field of the process to -1 (see the section “Returning from Interrupts and Exceptions” in Chapter 4). Looking at the value of this field, schedule() assumes that the process being replaced does not hold the kernel_sem semaphore and thus does not release it. As a result, the kernel_sem semaphore continues to be owned by the preempted process. Once this process is selected again by the scheduler, the preempt_schedule_irq() function restores the original value of the lock_depth field and lets the process resume execution in the critical section protected by the big kernel lock.


<h3 id="5.4.3">5.4.3 内存描述符读写信号量</h3>

每个内存描述符都可以使用数据结构mm_struct进行表达，它有一个成员mmap_sem，专门用来保护该描述符避免竞态条件的发生。因为每个内存描述符可以被几个轻量级进程共享。这是用户态多线程共享内存的硬件基础。

假设内核需要为某个进程创建或扩展一段内存区域。为此，调用do_mmap()函数，分配一个新的类型为vm_area_struct虚拟内存给进程。在这个过程中，如果已经没有内存可用，且每段内存都有一个信号量保护，所以，当前进程挂起，其它进程还可以正常访问他们的共享内存继续运行。但是，如果没有信号量保护，当前进程申请内存就会成功（其实可能占用了其它进程的内存）。而与当前进程共享内存的进程就会请求访问内存描述符（比如，写时复制（Copy on Write）导致的页错误），从而导致严重的数据损坏。

此处一般使用的是读/写信号量，因为大部分的内核函数，比如页错误异常处理程序只需要查看内存描述符，不会修改它。这样可以提高系统的并发性能。

<h3 id="5.4.4">5.4.4 Slab Cache列表信号量</h3>

slab是一种Linux内核内存分配算法，slab分配算法采用cache存储内核对象。这些对象的描述符使用一个列表进行管理。这个列表使用一个称为cache_chain_sem的信号量进行保护，从而对列表进行独占访问。

因为往这个列表中插入新对象的同时，kmem_cache_shrink()和kmem_cache_reap()会扫描这个列表，这就带来了竞态条件的发生。当然了，中断不会调用这些函数，所以不需要信号量。所以，主要是在支持内核抢占的多核和单核系统中起作用。所以选择信号量而不是自旋锁。

<h3 id="5.4.5">5.4.5 INode节点信号量</h3>

As we’ll see in “Inode Objects” in Chapter 12, Linux stores the information on a disk file in a memory object called an inode. The corresponding data structure includes its own semaphore in the i_sem field.

A huge number of race conditions can occur during filesystem handling. Indeed, each file on disk is a resource held in common for all users, because all processes may (potentially) access the file content, change its name or location, destroy or duplicate it, and so on. For example, let’s suppose that a process lists the files contained in some directory. Each disk operation is potentially blocking, and therefore even in uniprocessor systems, other processes could access the same directory and modify its content while the first process is in the middle of the listing operation. Or, again, two different processes could modify the same directory at the same time. All these race conditions are avoided by protecting the directory file with the inode semaphore.

Whenever a program uses two or more semaphores, the potential for deadlock is present, because two different paths could end up waiting for each other to release a semaphore. Generally speaking, Linux has few problems with deadlocks on semaphore requests, because each kernel control path usually needs to acquire just one semaphore at a time. However, in some cases, the kernel must get two or more locks. Inode semaphores are prone to this scenario; for instance, this occurs in the service routine in the rename( ) system call. In this case, two different inodes are involved in the operation, so both semaphores must be taken. To avoid such deadlocks, semaphore requests are performed in predefined address order.
