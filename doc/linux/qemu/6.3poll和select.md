* [6.3 poll和select](#6.3)
    * [6.3.1 与read和write的交互](#6.3.1)
    * [6.3.2 底层数据结构](#6.3.2)

***

<h2 id="6.3">poll和select</h2>

使用非阻塞IO的应用程序可以调用 *`poll`*, *`select`*, 和 *`epoll`*系统函数。  *`poll`*, *`select`*, 和 *`epoll`*本质上具有相同的功能：都是允许一个进程是否能通过非阻塞的方式读写一个或者多个文件。当给定的文件描述符集中没有文件可以读取，就会阻塞进程。因此，往往用于具有多个输入输出流的应用程序中，避免程序被某个输入输出流阻塞住。为什么相同的功能要实现多个函数呢？因为它们分别由不同的组实现，*`select`*是`BSD Unix`引入的概念，而 *`poll`*是由`System V`引入的。为了增加文件描述符的个数，从Linux内核2.5.45开始，又引入了 *`epoll`*。

当然了，这肯定需要驱动程序的支持。这三种调用都是通过驱动程序的 *`poll`* 方法提供的，原型如下：

    unsigned int (*poll) (struct file *filp, poll_table *wait);

当用户空间程序调用 *`poll`*, *`select`*, 或 *`epoll`*时，它们处理的文件描述符与驱动程序相关联，然后，驱动程序的 *`poll`* 方法就会执行。

1. 对于一个或多个 *`wait`* 队列调用 *`poll_wait`*,就能指示出轮询的状态。如果没有可用于I/O的文件描述符，内核就会让进程继续等待传递给系统调用的所有文件描述符
2. 返回一个能够立即非阻塞执行的文件描述符掩码

这些操作简单明了，各个驱动程序的这类操作看起来很相似。然而，它们非常依赖驱动程序提供的信息，因此每个驱动程序必须单独实现。

结构体 *`poll_table`* 是 *`poll`* 方法的第`2`个参数，用来在内核中实现*`poll`*, *`select`*, 和 *`epoll`*系统调用，其声明在 *`<linux/poll.h>`*文件中。 所以，在驱动程序的源代码中一定要包含这个文件。 驱动程序的作者不需要关心其内部细节， 把其当做一个 **黑盒子**使用即可。 它被传递给驱动程序的方法， 以至于驱动可以把等待队列载入，然后唤醒进程并改变 *`poll`* 的状态。  驱动程序通过调用函数 *`poll_wait`*添加一个等待队列到结构体 *`poll_table`*中。

    void poll_wait (struct file *, wait_queue_head_t *, poll_table *);

*`poll`*执行的第2个任务就是返回描述那些操作可以立即完成的位掩码，这也很简单。 例如， 如果设备有数据可用， *`read`*就会立即无阻塞的执行； *`poll`*就应该指出这种情况。 下面的标志用来指明这些可能的操作，其定义位于文件 *`<linux/poll.h>`*中。

>**POLLIN**
>
>       要想设备能够非阻塞的可读，必须设置。
>
>**POLLRDNORM**
>
>       “正常”数据可读取，必须设置。 可读设备应该返回 (POLLIN | POLLRDNORM)。
>
>**POLLRDBAND**
>
>       通常只用于linux内核某一处(DECnet码)且通常不会用于设备驱动程序。
>
>**POLLPRI**
>
>       无阻塞读取高优先级的数据（out-of-band）。select方法会报异常（带外数据）。
>
>**POLLHUP**
>
>       看到文件结束时，必须设置此位。
>
>**POLLERR**
>
>       设备发生错误，设置此位。调用 `poll`，会返回设备可读写，因为read和write都会返回错误代码而不会阻塞。
>
>**POLLOUT**
>
>       设备可以非阻塞地写入时，设置此位。
>
>**POLLWRNORM**
>
>        与POLLOUT相同，甚至有时候都是相同的数字。可写设备应该返回(POLLOUT | POLLWRNORM)。
>
>**POLLWRBAND**
>
>       像POLLRDBAND，表示可以将非0优先级的数据写入设备。只有poll数据报实现中使用。

It’s worth repeating that POLLRDBAND and POLLWRBAND are meaningful only with file descriptors associated with sockets: device drivers won’t normally use these flags.
The description of *`poll`* takes up a lot of space for something that is relatively simple to use in practice. Consider the scullpipe implementation of the *`poll`* method:

    static unsigned int scull_p_poll(struct file *filp, poll_table *wait)
    {
        struct scull_pipe *dev = filp->private_data;
        unsigned int mask = 0;

        /*
        * The buffer is circular; it is considered full
        * if "wp" is right behind "rp" and empty if the
        * two are equal.
        */
        down(&dev->sem);
        poll_wait(filp, &dev->inq, wait);
        poll_wait(filp, &dev->outq, wait);
        if (dev->rp != dev->wp)
            mask |= POLLIN | POLLRDNORM;            /* readable */
        if (spacefree(dev))
            mask |= POLLOUT | POLLWRNORM;           /* writable */
        up(&dev->sem);
        return mask;
    }

This code simply adds the two *`scullpipe`* wait queues to the poll_table, then sets the appropriate mask bits depending on whether data can be read or written.

The *`poll`* code as shown is missing end-of-file support, because *`scullpipe`* does not support an end-of-file condition. For most real devices, the *`poll`* method should return *`POLLHUP`* if no more data is (or will become) available. If the caller used the *`select`* system call, the file is reported as readable. Regardless of whether *`poll`* or *`select`* is used, the application knows that it can call read without waiting forever, and the *`read`* method returns, 0 to signal end-of-file.

With real FIFOs, for example, the reader sees an end-of-file when all the writers close the file, whereas in *`scullpipe`* the reader never sees end-of-file. The behavior is different because a FIFO is intended to be a communication channel between two processes, while *`scullpipe`* is a trash can where everyone can put data as long as there’s at least one reader. Moreover, it makes no sense to reimplement what is already available in the kernel, so we chose to implement a different behavior in our example.

Implementing end-of-file in the same way as FIFOs do would mean checking *`dev->nwriters`*, both in *`read`* and in *`poll`*, and reporting end-of-file (as just described) if no process has the device opened for writing. Unfortunately, though, with this implementation, if a reader opened the *`scullpipe`* device before the writer, it would see end-of-file without having a chance to wait for data. The best way to fix this problem would be to implement blocking within open like real FIFOs do; this task is left as an exercise for the reader.

***

<h3 id="6.3.1">6.3.1 与read和write的交互</h3>

The purpose of the *`poll`* and *`select`* calls is to determine in advance if an I/O operation will block. In that respect, they complement *`read`* and *`write`*. More important, *`poll`* and *`select`* are useful, because they let the application wait simultaneously for several data streams, although we are not exploiting this feature in the *`scull`* examples.

A correct implementation of the three calls is essential to make applications work correctly: although the following rules have more or less already been stated, we summarize them here.

####Reading data from the device

* If there is data in the input buffer, the *`read`* call should return immediately, with no noticeable delay, even if less data is available than the application requested, and the driver is sure the remaining data will arrive soon. You can always return less data than you’re asked for if this is convenient for any reason (we did it in *`scull`*), provided you return at least one byte. In this case, *`poll`* should return POLLIN|POLLRDNORM.
* If there is no data in the input buffer, by default *`read`* must block until at least one byte is there. If ***O_NONBLOCK*** is set, on the other hand, *`read`* returns immediately with a return value of -***EAGAIN*** (although some old versions of System V return 0 in this case). In these cases, *`poll`* must report that the device is unreadable until at least one byte arrives. As soon as there is some data in the buffer, we fall back to the previous case.
* If we are at end-of-file, read should return immediately with a return value of 0, independent of ***O_NONBLOCK***. *`poll`* should report ***POLLHUP*** in this case.

####Writing to the device

* If there is space in the output buffer, *`write`* should return without delay. It can accept less data than the call requested, but it must accept at least one byte. In this case, *`poll`* reports that the device is writable by returning ***POLLOUT|POLLWRNORM***.
* If the output buffer is full, by default *`write`* blocks until some space is freed. If ***O_NONBLOCK*** is set, *`write`* returns immediately with a return value of **-EAGAIN** (older System V Unices returned 0). In these cases, *`poll`* should report that the file is not writable. If, on the other hand, the device is not able to accept any more data, *`write`* returns **-ENOSPC** (“No space left on device”), independently of the setting of ***O_NONBLOCK***.
* Never make a *`write`* call wait for data transmission before returning, even if ***O_NONBLOCK*** is clear. This is because many applications use *`select`* to find out whether a *`write`* will block. If the device is reported as writable, the call must not block. If the program using the device wants to ensure that the data it enqueues in the output buffer is actually transmitted, the driver must provide an *`fsync`* method. For instance, a removable device should have an *`fsync`* entry point.

Although this is a good set of general rules, one should also recognize that each device is unique and that sometimes the rules must be bent slightly. For example, record-oriented devices (such as tape drives) cannot execute partial writes.

####Flushing pending output

We’ve seen how the *`write`* method by itself doesn’t account for all data output needs. The *`fsync`* function, invoked by the system call of the same name, fills the gap. This method’s prototype is

    int (*fsync) (struct file *file, struct dentry *dentry, int datasync);

If some application ever needs to be assured that data has been sent to the device, the *`fsync`* method must be implemented regardless of whether ***O_NONBLOCK*** is set. A call to *`fsync`* should return only when the device has been completely flushed (i.e., the output buffer is empty), even if that takes some time. The `datasync` argument is used to distinguish between the *`fsync`* and *`fdatasync`* system calls; as such, it is only of interest to filesystem code and can be ignored by drivers.
The *`fsync`* method has no unusual features. The call isn’t time critical, so every device driver can implement it to the author’s taste. Most of the time, char drivers just have a `NULL` pointer in their `fops`. Block devices, on the other hand, always implement the method with the general-purpose *`block_fsync`*, which, in turn, flushes all the blocks of the device, waiting for I/O to complete.

***

<h3 id="6.3.2">6.3.2 底层数据结构</h3>

The actual implementation of the *`poll`* and *`select`* system calls is reasonably simple, for those who are interested in how it works; *`epoll`* is a bit more complex but is built on the same mechanism. Whenever a user application calls *`poll`*, *`select`*, or *`epoll_ctl`*,* the kernel invokes the *`poll`* method of all files referenced by the system call, passing the same *`poll_table`* to each of them. The *`poll_table`* structure is just a wrapper around a function that builds the actual data structure. That structure, for *`poll`* and *`select`*, is a linked list of memory pages containing *`poll_table_entry`* structures. Each *`poll_table_entry`* holds the struct *`file`* and *`wait_queue_head_t`* pointers passed to *`poll_wait`*, along with an associated wait queue entry. The call to *`poll_wait`* sometimes also adds the process to the given wait queue. The whole structure must be maintained by the kernel so that the process can be removed from all of those queues before *`poll`* or *`select`* returns.

If none of the drivers being polled indicates that I/O can occur without blocking, the *`poll`* call simply sleeps until one of the (perhaps many) wait queues it is on wakes it up. What’s interesting in the implementation of *`poll`* is that the driver’s *`poll`* method may be called with a `NULL` pointer as a *`poll_table`* argument. This situation can come about for a couple of reasons. If the application calling *`poll`* has provided a timeout value of 0 (indicating that no wait should be done), there is no reason to accumulate wait queues, and the system simply does not do it. The *`poll_table`* pointer is also set to `NULL` immediately after any driver being polled indicates that I/O is possible. Since the kernel knows at that point that no wait will occur, it does not build up a list of wait queues.

When the *`poll`* call completes, the *`poll_table`* structure is deallocated, and all wait queue entries previously added to the poll table (if any) are removed from the table and their wait queues.

We tried to show the data structures involved in polling in Figure 6-1; the figure is a simplified representation of the real data structures, because it ignores the multipage nature of a poll table and disregards the file pointer that is part of each poll_table_entry. The reader interested in the actual implementation is urged to look in <linux/poll.h> and fs/select.c.

At this point, it is possible to understand the motivation behind the new epoll system call. In a typical case, a call to poll or select involves only a handful of file descriptors, so the cost of setting up the data structure is small. There are applications out there, however, that work with thousands of file descriptors. At that point, setting up and tearing down this data structure between every I/O operation becomes prohibitively expensive. The epoll system call family allows this sort of application to set up the internal kernel data structure exactly once and to use it many times.