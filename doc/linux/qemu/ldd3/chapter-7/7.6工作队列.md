* [7.6 工作队列](#7.6)
    * [7.6.1 共享队列](#7.6.1)

***
<h3 id="7.6">7.6 工作队列</h3>
***

从表面上看，工作队列类似于`tasklet`;它们允许内核代码请求在将来的某个时间调用一个函数。但是，两者还是存在着显著的差异，如下所示：

* `tasklet`运行在软件中断上下文中，所以其代码必须是原子操作。相反，工作队列运行在内核进程上下文中；结果就是它们具有更大的灵活性。特别是，工作队列可以休眠。
* `tasklet`始终运行在最初提交它们的处理器上。默认情况下，工作队列以相同方式工作。
* 内核代码可以请求，将工作队列中的函数延迟一段时间后再执行

所以，工作队列和`tasklet`最大的不同就是`tasklet`执行的更快，因为其是原子的；但是，因为不必是原子的，所以工作队列具有更高的延迟。

工作队列使用的一种数据结构是`struct workqueue_struct`，定义在`<linux/workqueue.h>`中。工作队列在使用之前，必须使用下面的函数显式地创建：

    struct workqueue_struct *create_workqueue(const char *name);
    struct workqueue_struct *create_singlethread_workqueue(const char *name);

每个工作队列都有一个或多个专用进程（“内核线程”），在其中运行提交给队列的函数。如果使用`create_workqueue`，则可以得到一个工作队列，该队列具有系统上每个处理器的专用线程。在许多情况下，这么多线程有点浪费；如果只要单个工作线程就够了，那么可以使用`create_singlethread_workqueue`。

为了提交任务给工作队列，需要填充结构体`work_struct`。下面的宏就是在编译的时候完成数据结构的填充。

    DECLARE_WORK(name, void (*function)(void *), void *data);

在这里，`name`是被声明的结构体的名称， `function`是要从工作队列中调用的函数，`data`是传递给函数的参数。如果需要在运行时建立结构体`work_struct`z，则使用下面两个宏：

    INIT_WORK(struct work_struct *work, void (*function)(void *), void *data);
    PREPARE_WORK(struct work_struct *work, void (*function)(void *), void *data);

INIT_WORK does a more thorough job of initializing the structure; you should use it the first time that structure is set up. PREPARE_WORK does almost the same job, but it does not initialize the pointers used to link the work_struct structure into the workqueue. If there is any possibility that the structure may currently be submitted to a workqueue, and you need to change that structure, use PREPARE_WORK rather than INIT_WORK.

There are two functions for submitting work to a workqueue:

    int queue_work(struct workqueue_struct *queue, struct work_struct *work);
    int queue_delayed_work(struct workqueue_struct *queue,
        struct work_struct *work, unsigned long delay);

Either one adds work to the given queue. If queue_delayed_work is used, however, the actual work is not performed until at least delay jiffies have passed. The return value from these functions is 0 if the work was successfully added to the queue; a nonzero result means that this work_struct structure was already waiting in the queue, and
was not added a second time.

At some time in the future, the work function will be called with the given data value. The function will be running in the context of the worker thread, so it can sleep if need be—although you should be aware of how that sleep might affect any other tasks submitted to the same workqueue. What the function cannot do, however, is access user space. Since it is running inside a kernel thread, there simply is no user space to access.

Should you need to cancel a pending workqueue entry, you may call:

    int cancel_delayed_work(struct work_struct *work);

The return value is nonzero if the entry was canceled before it began execution. The kernel guarantees that execution of the given entry will not be initiated after a call to cancel_delayed_work. If cancel_delayed_work returns 0, however, the entry may have already been running on a different processor, and might still be running after a call to cancel_delayed_work. To be absolutely sure that the work function is not running anywhere in the system after cancel_delayed_work returns 0, you must follow that call with a call to:

    void flush_workqueue(struct workqueue_struct *queue);

After flush_workqueue returns, no work function submitted prior to the call is running anywhere in the system. When you are done with a workqueue, you can get rid of it with:

    void destroy_workqueue(struct workqueue_struct *queue);

***
<h3 id="7.6.1">7.6.1 共享队列</h3>
***

A device driver, in many cases, does not need its own workqueue. If you only submit tasks to the queue occasionally, it may be more efficient to simply use the shared, default workqueue that is provided by the kernel. If you use this queue, however, you must be aware that you will be sharing it with others. Among other things, that means that you should not monopolize the queue for long periods of time (no long sleeps), and it may take longer for your tasks to get their turn in the processor. The jiq (“just in queue”) module exports two files that demonstrate the use of the shared workqueue. They use a single work_struct structure, which is set up this way:

    static struct work_struct jiq_work;
        /* this line is in jiq_init( ) */
        INIT_WORK(&jiq_work, jiq_print_wq, &jiq_data);

When a process reads /proc/jiqwq, the module initiates a series of trips through the shared workqueue with no delay. The function it uses is:

    int schedule_work(struct work_struct *work);

Note that a different function is used when working with the shared queue; it requires only the work_struct structure for an argument. The actual code in jiq looks like this:

    prepare_to_wait(&jiq_wait, &wait, TASK_INTERRUPTIBLE);
    schedule_work(&jiq_work);
    schedule( );
    finish_wait(&jiq_wait, &wait);

The actual work function prints out a line just like the jit module does, then, if need be, resubmits the work_struct structure into the workqueue. Here is jiq_print_wq in its entirety:

    static void jiq_print_wq(void *ptr)
    {
        struct clientdata *data = (struct clientdata *) ptr;

        if (! jiq_print (ptr))
            return;
        if (data->delay)
            schedule_delayed_work(&jiq_work, data->delay);
        else
            schedule_work(&jiq_work);
    }

If the user is reading the delayed device (/proc/jiqwqdelay), the work function resubmits itself in the delayed mode with schedule_delayed_work:

    int schedule_delayed_work(struct work_struct *work, unsigned long delay);

If you look at the output from these two devices, it looks something like:

    % cat /proc/jiqwq
     time delta preempt pid cpu command
     1113043 0 0 7 1 events/1
     1113043 0 0 7 1 events/1
     1113043 0 0 7 1 events/1
     1113043 0 0 7 1 events/1
     1113043 0 0 7 1 events/1
    % cat /proc/jiqwqdelay
     time delta preempt pid cpu command
     1122066 1 0 6 0 events/0
     1122067 1 0 6 0 events/0
     1122068 1 0 6 0 events/0
     1122069 1 0 6 0 events/0
     1122070 1 0 6 0 events/0

When /proc/jiqwq is read, there is no obvious delay between the printing of each line. When, instead, /proc/jiqwqdelay is read, there is a delay of exactly one jiffy between each line. In either case, we see the same process name printed; it is the name of the kernel thread that implements the shared workqueue. The CPU number is printed after the slash; we never know which CPU will be running when the /proc file is read, but the work function will always run on the same processor thereafter.

If you need to cancel a work entry submitted to the shared queue, you may use cancel_delayed_work, as described above. Flushing the shared workqueue requires a separate function, however:

    void flush_scheduled_work(void);

Since you do not know who else might be using this queue, you never really know how long it might take for flush_scheduled_work to return.