<h1 id="0">0 目录</h1>

* [5.1 scull的缺陷](#5.1)
* [5.2 并发及其管理](#5.2)
* [5.3 信号量和互斥](#5.3)
    - [5.3.1 linux信号量实现](#5.3.1)
    - [5.3.2 在scull中使用信号量](#5.3.2)
    - [5.3.3 读/写信号量](#5.3.3)
* [5.4 completion机制](#5.4)
* [5.5 自旋锁](#5.5)
    - [5.5.1 自旋锁API介绍](#5.5.1)
    - [5.5.2 自旋锁和原子上下文](#5.5.2)
    - [5.5.3 自旋锁函数](#5.5.3)
    - [5.5.4 读/写自旋锁](#5.5.4)
* [5.6 锁陷阱](#5.6)
    - [5.6.1 不明确的规则](#5.6.1)
    - [5.6.2 加锁的顺序规则](#5.6.2)
    - [5.6.3 细粒度锁和粗粒度锁的对比](#5.6.3)
* [5.7 除锁之外的选择](#5.7)
    - [5.7.1 免锁算法](#5.7.1)
    - [5.7.2 原子变量](#5.7.2)
    - [5.7.3 位操作](#5.7.3)
    - [5.7.4 seqlock锁](#5.7.4)
    - [5.7.5 读取-复制-更新](#5.7.5)

---

并发问题是操作系统编程中的核心问题之一。并发时相关bug易发生，难解决。所以，驱动程序开发者必须在开始就把并发问题考虑在内。现在让我们看一下，之前我们简单编写的scull驱动程序是否存在潜在的问题。如果有，想出解决办法。

<h2 id="5.1">5.1 scull的缺陷</h2>

让我们看一下scull模块中内存管理相关代码。下面这段代码是write函数实现中的一段代码。Scull代码需要判断它所申请的内存是否被分配。

    if (!dptr->data[s_pos]) {
        dptr->data[s_pos] = kmalloc(quantum, GFP_KERNEL);
        if (!dptr->data[s_pos])
            goto out;
    }

这段代码，咋看上没有什么问题。但是，假设我们的系统中存在2个彼此独立的进程（假设分别为进程A和B），在某一个时刻，同时访问scull设备中的同一偏移的区域，会发生什么呢？假设2个进程都同时访问到第一个if条件语句处，而此时判断的结果恰好是Null，那么它们都会调用kmalloc()函数，申请分配内存，然后将返回的内存指针赋给`dptr->data[s_pos]`，这时，如果A先赋值，那么B赋值时，就会覆盖掉A之前的赋值。那么A申请的内存，就会发生内存泄漏，系统无法找到了。

这就是竞态条件的一个例证。竞态条件就是对共享数据的访问不加控制的结果。竞态条件可能会造成系统崩溃，数据损坏，以及安全问题等。大家可能认为，竞态的发生是一个概率非常非常低的事情，但是，一旦发生，后果就是极其严重的。

让我们在消除scull中的竞态问题前，先全面地对并发做一下了解吧。

<h2 id="5.2">5.2 并发及其管理</h2>

在现代操作系统中，并发的来源有很多种。比如，多用户可能同时访问你的代码；SMP系统可以在不同的CPU上同时执行你的代码；内核代码是可抢占式的，你的驱动程序可能会在任何时候被打断，而替代的进程可能正在运行你的驱动程序；设备硬件中断是异步发生的，可能会造成你的代码同时执行。内核提供了多种延时代码执行的机制、诸如工作队列、tasklet、和定时器，它们可以让你的代码在任何时候运行，而不关注当前的进程正在做什么。另外，现在大多数系统都支持“热插拔”机制，也就是说，在你使用设备期间，它随时有可能消失。

避免竞态条件的出现是一个艰难的任务。实践证明，竞态条件可以通过多思考、使用内核并发控制原语、及采用一些基本原则去避免。接下来，我们首先介绍这些原则，而后再研究如何应用它们。

* **原则一：尽量避免使用共享资源。**

    竞态条件就是因对资源的共享访问而产生的。所以，第一条经验准则就是牢记避免在你的驱动程序中使用共享资源。没有并发访问，也就没有竞态条件。如果非得在程序中使用共享资源，必须有“不得不这样做”的理由。

    但是，实际情况就是，共享又经常需要。当遇上了，我们就得面对：

* **原则二：任何时间，发生对硬件或软件资源的访问，而有可能造成竞态条件时，我们必须显式地控制对这些资源的访问。**

    在scull的示例中，我们必须控制对scull的数据结构的访问。我们需要让代码知道，是否已经分配内存，还要让代码知道，分配的内存是“其它人”的。这种访问管理的常用方法就是加锁和互斥-保证同时只有一个线程在控制共享的资源。

    下面让我们专注于分析锁的使用。在此之前，还有一个重要的原则，我们必须作一简单的介绍：内核代码创建一个与其它代码共享对象，在对该对象所有的引用解除之前，其必须一直存在。这条规则带来了2个要求：内核的对象在内核没有处于可运行状态时，必须是不可用的；对该对象的引用必须可被追踪。在大部分时候，引用计数的处理都是由内核完成，但是，万事无绝对。所以，我们必须非常注重细节的实现。

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.3">5.3 信号量和互斥</h2>

所以，让我们看看如何给scull这个示例代码添加锁。保证对scull中的数据结构进行的操作是原子的，意味着如果有其它正在执行的线程也在对该数据结构做操作，当前线程的操作必须立马执行而不会被打断。在我们上面的示例中，我们需要保证如果一个线程发现需要分配一块内存，必须在其它线程也做相同操作之前，完成分配内存的所有操作。为此，我们必须建立临界代码段：保证代码段一段时间内只有一个线程在执行。

不同的需求可能需要不同的临界代码段。在本例中，对scull数据结构的访问，是用户直接请求的结果；没有来自中断服务程序或其它异步执行的进程。也没有特殊的响应时间要求；应用程序通常不需要I/O请求立即响应。进一步讲，scull也没有其它需要临界系统资源，它只访问自己的数据结构。所有的这些意味着，如果scull驱动程序没有取得访问其数据结构的权限就会进入休眠状态，而不用在意其它进程。

在本文中，进入休眠是很明确的。当Linux进程完成操作后，就会进入休眠（或者称为阻塞），将处理器交给其它程序，直到下一次执行。进程为了等待I/O执行完毕，经常需要休眠。但是，我们深入研究内核代码，就会发现很多不能休眠的情况。scull中的write方法是可以实现为阻塞的，因此，我们可以使用加锁机制，使进程在等待访问临界代码的时候，进入休眠状态。

正因如此，我们执行的操作（使用kmalloc分配内存）可能会休眠，在任何时候都有可能发生。如果想要我们的临界代码段正常工作，我们必须使用一个拥有锁的线程休眠的时候还能正常工作的锁原语（locking primitive）。因为并不是所有的锁原语都可以在会发生休眠的地方使用（在本章的后面，我们就会看到一些不能使用的例子）。但是，当前我们最合适的就是信号量。

信号量在计算机科学中是一个很容易理解的概念。本质上，信号量就是一个简单的整数，对其进行的操作称为PV操作。进入某段临界代码段就会调用相关信号量的P操作；如果信号量的值大于0，该值会减1，进程继续执行。相反，如果信号量的值等于0，该进程就会等待，直到有其它程序释放该信号量。解锁信号量的过程就称为V操作，增加信号量的值，并唤醒正在等待的进程。

> <font color="red">注：</font>
>
> 信号量，这一同步机制为什么称为PV操作。原来，这些术语都是来源于狄克斯特拉使用荷兰文定义的。因为在荷兰文中，通过叫`passeren`，释放叫`vrijgeven`，PV操作因此得名。这是在计算机术语中不是用英语表达的极少数的例子之一。

使用信号量保持几个进程保持互斥，信号量的值被设为1。这样的信号量，在某个时间内只能被一个进程拥有。值为1的信号量有时候也被称为mutex，它是`mutual exclusion`的缩略语。Linux内核中几乎所有的信号量都是用于互斥。

<h3 id="5.3.1">5.3.1 linux信号量实现</h3>

Linux内核提供了符合上述语义的信号量实现，尽管术语略有不同。为了使用信号量，必须包含头文件`<asm/semaphore.h>`。相关的数据结构是`struct semaphore`；实际的信号量可以通过几种方式进行声明和初始化。其中一种就是直接创建信号量，然后使用sema_init()函数进行设置：

    void sema_init(struct semaphore *sem, int val);

在这儿，val是sem的初始值。

但是，通常情况下，信号量都是以互斥的方式使用。为了方便，内核提供了一组辅助函数和宏。因此，可使用下面宏声明一个互斥量并初始化：

    DECLARE_MUTEX(name);
    DECLARE_MUTEX_LOCKED(name);

这儿，产生了一个称为name的信号量，其初始值为0（使用DECLARE_MUTEX_LOCKED）或1（使用DECLARE_MUTEX）。其值为0时，互斥量以一个被锁的状态开始；任何线程想要访问之前，必须被显式地解锁。

在运行时动态初始化互斥量时，调用下面的函数：

    void init_MUTEX(struct semaphore *sem);
    void init_MUTEX_LOCKED(struct semaphore *sem);

> <font color="red">注：</font>
>
> 在新版本的Linux内核（2.6.37之后）中，上面的函数已经不存在。
>

Linux中调用P函数-被称为down或者其它变体。在这儿，down指的是函数递减信号量，甚至将调用者休眠一会，直到信号量变得可用，并授予对受保护资源的访问权。这儿有3个版本的down函数：

    void down(struct semaphore *sem);
    int down_interruptible(struct semaphore *sem);
    int down_trylock(struct semaphore *sem);

* down

    减少信号量的值，必要时进入休眠状态。

* down_interruptible

    做相同工作，但是可被中断。我们大部分时候想要的都是可中断版本，它允许等待信号量的用户空间进程可被用户中断。通常不会使用非中断版本。不可中断进程是创建不可杀进程的一种好方法（可怕的“D状态”-ps命令的结果中可以看到），但是会令用户烦恼。特别值得注意的是，使用down_interruptible时，如果操作被中断，此时返回值为非零值，而调用者其实已经不再拥有信号量。所以调用down_interruptible时，必须检查返回值，作出相应的处理。

* down_trylock

    不会休眠；如果信号量不可用，down_trylock会立即返回，并返回一个非零值。

线程一旦调用了上面的某一个down函数，就会说它拥有信号量。该线程现在有权访问受保护的临界区代码。

Linux中的V函数就是up函数：

    void up(struct semaphore *sem);

一旦调用up，调用者将不再拥有该信号量。

> <font color="red">注：</font>
>
> 在使用的过程中，获取信号量和释放信号量应该是成对出现的。所以，当错误发生时，必须特别小心。如果在拥有信号量的同时，发生了错误，必须在返回错误状态给调用者之前，释放掉信号量。这是经常容易犯的错误，要格外小心。

<h3 id="5.3.2">5.3.2 在scull中使用信号量</h3>

信号量机制给了scull代码一种避免竞态出现的方法。但是，对于我们编程者来说，怎样掌握这门技巧，确定哪些资源需要被保护，如何使用正确的方式进行加锁访问资源，这些才是我们学习信号量的关键。

让我们再看一次scull_dev结构体：

    struct scull_dev {
        struct          scull_qset *data;   /* 指向第一个量子集的指针 */
        int             quantum;            /* 当前量子的大小 */
        int             qset;               /* 当前数组的大小 */
        unsigned long   size;               /* 数据的大小 */
        unsigned int    access_key;         /* 被sculluid和scullpriv使用 */
        struct          semaphore sem;      /* 互斥信号量 */
        struct          cdev cdev;          /* 字符设备结构 */
    };

在上面的代码片段中，我们需要关注倒数第2个成员，sem，互斥信号量。我们选择为每一个虚拟的scull设备提供一个独立的互斥信号量。

信号量在使用之前必须被初始化。看下面的代码：

    for (i = 0; i < scull_nr_devs; i++) {
        scull_devices[i].quantum = scull_quantum;
        scull_devices[i].qset = scull_qset;
        sema_init(&scull_devices[i].sem, 1);
        scull_setup_cdev(&scull_devices[i], i);
    }

在系统可以使用scull设备之前，互斥信号量sem必须被初始化。因此，sema_init必须在scull_setup_cdev之前进行调用。

接下来，获取互斥信号量以便访问scull_dev结构体。所以，scull_write开头部分的代码如下所示：

    if (down_interruptible(&dev->sem))
        return -ERESTARTSYS;

> <font color="red">注：</font>
>
> 注意检查down_interruptible的返回值，如果返回非0，说明操作被中断。在这种情况下，通常返回-ERESTARTSYS。基于这个返回码，内核上层代码决定重启调用还是将其错误返回给用户。如果返回-ERESTARTSYS，则必须首先撤消可能已进行的任何用户更改，以便在重试系统调用时操作正确。如果您无法以这种方式撤消操作，则应返回-EINTR。

不论scull_write中的其它代码能否正常执行，都必须释放其占用的信号量。如果执行正常，最后会执行下面的代码：

    out:
        up(&dev->sem);
        return retval;

<h3 id="5.3.3">5.3.3 读写信号量</h3>

信号量为每个调用者提供互斥操作，而不管线程想要做什么。但是，许多任务可以分为2类：一类是只读受保护的数据，而另一类就是改变受保护的数据。也就是说，可能同时很多个读任务，只要没有其它任务在尝试写操作。这样做可以显著优化性能：只读任务可以并行执行，而无需等待其它读任务退出临界代码段。

Linux内核针对这种情况提供了一种称为rwsem的特殊信号量（或读/写信号量）。rwsem在内核中使用较少，但是偶尔也会用。

要想使用rwsem就必须包含`<linux/rwsem.h>`头文件。与读写信号量有关的数据类型是`struct rw_semaphore`；运行时，rwsem必须被显示初始化。使用下面的函数：

    void init_rwsem(struct rw_semaphore *sem);

初始化后，就可以使用下面的这些函数给代码添加读信号量：

    void down_read(struct rw_semaphore *sem);
    int down_read_trylock(struct rw_semaphore *sem);
    void up_read(struct rw_semaphore *sem);

down_read 提供阻塞访问，也就是在访问受保护的资源的时候，如果没有获取权限就会进入不可中断的休眠状态。down_read_trylock提供非阻塞访问，如果获取权限，就返回非0；否则返回0。这儿值得注意的是，down_read_trylock的返回值与大部分的Linux内核函数不同，后者在成功时返回0。

处理写信号量的函数为:

    void down_write(struct rw_semaphore *sem);
    int down_write_trylock(struct rw_semaphore *sem);
    void up_write(struct rw_semaphore *sem);
    void downgrade_write(struct rw_semaphore *sem);

down_write、down_write_trylock、up_write与上面读信号量的处理函数类似，除了它们提供的是写操作权限外。有时候，在写操作后紧跟较长周期的只读操作时，可以使用downgrade_write将写信号量降级为读信号量，以便其它读操作在写保护之后立即响应。

一个rwsem可以允许一个写操作或者多个读操作拥有信号量。写操作拥有优先权：只要写操作尝试进入临界代码段，其它读操作直到写操作完成才能进入。如果有许多写操作在竞争信号量，因为读操作长时间获取不到访问权限而导致阻塞。基于这个原因，rwsem最好在写操作较少，且拥有锁的时间比较短的时候使用。

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.4">5.4 completion机制</h2>

内核编程中的一个常见模式就是在当前进程之外再启动某个活动，比如创建新的内核线程或用户空间进程，向已存在的进程发起请求，再或者一些基于硬件的操作。针对这些情况，内核可以尝试使用信号量同步两个任务，代码如下：

    struct semaphore sem;

    init_MUTEX_LOCKED(&sem);
    start_external_task(&sem);
    down(&sem);

当外部的任务完成操作后，调用up(&sem)释放信号量。

事实证明，在这些情况下信号量不是最好的工具。正常的情况下，代码尝试给信号量加锁时，几乎一直是可用的；但是，如果对信号量的竞争加剧的情况下，性能会变糟糕，加锁的机制需要被重新审视。所以，信号量针对“可用”情况进行了优化。但是，如果把上面的方法应用到通信任务时，调用down的线程几乎总是处于等待中，因此，性能将会变得糟糕。而且，如果将信号量声明为自动变量，按照上面的方法，这些信号量也会存在竞态条件。在某些情况下，在进程尝试调用up函数之前，这个信号量可能会消失。

基于上面提到的情况，内核版本2.4.7里添加了completion机制。Completion是任务间的轻量级同步机制：允许一个线程告知另一个线程工作已经完成。要想使用completion，需要包含头文件`<linux/completion.h>`，可以使用下面的声明语句进行声明：

    DECLARE_COMPLETION(my_completion);

也可以使用下面的代码动态声明：

    struct completion my_completion;
    /* ... */
    init_completion(&my_completion);

等待completion使用下面的方法：

    void wait_for_completion(struct completion *c);

> <font color="red">注：</font>
>
> <font color="red">wait_for_completion执行不可中断的等待。如果代码调用了该函数，而且被等待的任务没有完成，结果就是，等待的任务就是一个不可杀的进程。</font>

可以通过下面的函数，发出任务完成的事件：

    void complete(struct completion *c);
    void complete_all(struct completion *c);

上面两个函数的行为是不一样的。complete()函数仅唤醒一个等待的任务，而complete_all()函数唤醒所有正在等待该完成事件的任务。如果只有一个等待者，这两个函数将会产生相同的结果。

completion机制通常是一次性的，用过即抛弃。但是，如果处理得当，完全可以重用completion结构体:只要正在发送的事件没有歧义，且没有调用complete_all()函数，重用completion结构就没有问题；但是，如果调用了complete_all()函数，再次使用之前，必须使用下面的宏进行重新初始化：

    INIT_COMPLETION(struct completion c);

这个函数可以快速的完成重新初始化。

关于completion机制如何使用，请参考complete的模块示例。该模块定义了一个这样的模块：任何尝试读取设备的进程都会进入等待状态（通过调用wait_for_completion()函数实现），直到有其它进行尝试写该设备。代码类似于下面的代码：

    DECLARE_COMPLETION(comp);
    ssize_t complete_read (struct file *filp, char __user *buf, size_t count, loff_t
            *pos)
    {
        printk(KERN_DEBUG "process %i (%s) going to sleep\n",
                current->pid, current->comm);
        wait_for_completion(&comp);
        printk(KERN_DEBUG "awoken %i (%s)\n", current->pid, current->comm);
        return 0;
    }
    ssize_t complete_write (struct file *filp, const char __user *buf, size_t count,
            loff_t *pos)
    {
        printk(KERN_DEBUG "process %i (%s) awakening the readers...\n",
                current->pid, current->comm);
        complete(&comp);
        return count; /* 成功，避免重试 */
    }

在上面的示例中，可能存在多个进程同时读取设备。对设备的一次写操作只能试一个读操作完成，而无法通知其它正在读操作的进程。

completion机制的一个典型应用就是，在模块exit的时候，终止内核线程。在一些典型的例子中，驱动程序的内部工作是在内核线程中使用while(1)循环中实现的。当模块准备好清理时，exit函数就会告诉线程需要退出，然后等待线程的completion事件。基于这个目的，内核提供了一个特殊的函数供线程调用：

    void complete_and_exit(struct completion *c, long retval);

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.5">5.5 自旋锁</h2>

除了信号量之外，Linux内核还提供了一种加锁机制，`spinlock`，中文可以翻译为`自旋锁`。

* 概念

    何为自旋锁？它是为实现保护共享资源而提出的一种锁机制。其它，自旋锁和互斥锁比较类似，都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，最多都只能有一个保持者。也就是说，在任何时候最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态；但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，自锁一次由此而来。

* 实现原理

    在单处理机环境中可以使用特定的原子级汇编指令swap和test_and_set实现进程互斥，（Swap指令：交换两个内存单元的内容；test_and_set指令取出内存某一单元(位)的值，然后再给该单元(位)赋一个新值，关于为何这两条指令能实现互斥我们不在赘述，读者可以了解其算法） 这些指令涉及对同一存储单元的两次或两次以上操作，这些操作将在几个指令周期内完成，但由于中断只能发生在两条机器指令之间，而同一指令内的多个指令周期不可中断，从而保证swap指令或test_and_set指令的执行不会交叉进行.

    但在多处理机环境中情况有所不同，例如test_and_set指令包括“取”、“送”两个指令周期，两个CPU执行test_and_set(lock)可能发生指令周期上的交叉，假如lock初始为0, CPU1和CPU2可能分别执行完前一个指令周期并通过检测(均为0)，然后分别执行后一个指令周期将lock设置为1，结果都取回0作为判断临界区空闲的依据，从而不能实现互斥.

    为在多CPU环境中利用test_and_set指令实现进程互斥，硬件需要提供进一步的支持，以保证test_and_set指令执行的原子性. 这种支持多以“锁总线”(bus locking)的形式提供的，由于test_and_set指令对内存的两次操作都需要经过总线，在执行test_and_set指令之前锁住总线，在执行test_and_set指令后开放总线，即可保证test_and_set指令执行的原子性。

* 可能的问题

    * 死锁

        引发这个问题的最常见情况就是递归使用一个自旋锁，即如果一个已经拥有某个自旋锁的CPU想第二次获得这个自旋锁，则该CPU将会发生死锁。此外，如果进程获得自旋锁之后再阻塞，也有可能导致死锁的发生。copy_from_user()、copy_to_user()和kmalloc()等函数都有可能引起阻塞，因此在自旋锁的占用期间不能调用这些函数。所以，在使用自旋锁的时候必须小心。

    * 占用CPU资源

        自旋锁实际上就是忙等锁。当锁不可用时，CPU一直循环执行`test and set`操作，直到该锁可用，CPU在等待自旋锁的时候不作任何有用的工作，仅仅是等待。<font color="blue">因此，只有在占用锁的时间极短的情况下，使用自旋锁才是合理的。当临界代码段很大或共享设备的时候，需要较长时间占用锁，使用自旋锁会降低系统的性能。</font>

本质上说，自旋锁主要是为多处理器系统设计的，尽管就并发来说，运行抢占式内核的单核系统行为与SMP相像（通过超线程技术实现）。如果单核系统，运行的是非抢占式内核，占有一个自旋锁后，它将永远`自旋`，没有其它线程获取CPU来释放锁。因此，除了那些更改IRQ屏蔽状态的操作以外，运行非抢占式内核的单核系统上的自旋操作已被优化为不执行任何操作。（这句话就是说，这类自旋锁只是关闭中断，没有其它任何操作）。运行抢占式内核的处理器，不管是不是多核系统，都要实现合适的加锁机制。

> <font color="red">总结：</font>
>
> <font color="red">1. 因此我们需要慎重使用自旋锁，自旋锁只有在内核是可抢占式或SMP的情况下才真正需要，但单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁的时间比较短的情况。</font>
>
> <font color="red">2. 自旋锁不会引起调用者休眠，所以自旋锁的效率远高于互斥锁。</font>

> <font color="red">注：</font>
>
> <font color="red">超线程：超线程技术是由Intel公司提出的一项同时多线程（simultaneous multi-theading）技术，允许一个CPU执行多个控制流的技术。它的原理很简单，就是把一颗CPU虚拟成2颗，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU没有什么区别。因此，操作系统会把工作线程分派给这两颗逻辑CPU去执行，让应用程序的多个线程，能够同时在同一颗CPU上执行。注意：两颗逻辑CPU共享单颗物理CPU的所有执行资源。因此，可以简单地认为，超线程技术就是对CPU的虚拟化。</font>

<h3 id="5.5.1">5.5.1 自旋锁API</h3>

要想使用自旋锁，请包含头文件 `<linux/spinlock.h>`，数据类型为`spinlock_t`。

1. 与其他数据类型一样，使用之前也必须初始化。有2种方法：

    * 编译的时候，使用下面的指令进行初始化，

            spinlock_t my_lock = SPIN_LOCK_UNLOCKED;

    * 运行时，使用下面的函数进行初始化，

            void spin_lock_init(spinlock_t *lock);

2. 使用下面的函数获取自旋锁：

        void spin_lock(spinlock_t *lock);

    > <font color="red">注：</font>
    >
    > <font color="red">从本质上讲，所有的自旋锁都是不可中断的。一旦调用了spin_lock，会一直自旋，直到自旋锁可用为止。</font>


3. 释放自旋锁，使用下面的函数

        void spin_unlock(spinlock_t *lock);

还有许多其它的spinlock函数，后面我们会介绍。但是，它们的核心思想与上面的函数相同。很少会只加锁，而不释放锁。但是，再深入理解所有的spinlock函数之前，我们还需要花费一点时间了解一些使用spinlock的规则。

<h3 id="5.5.2">5.5.2 自旋锁和原子上下文</h3>

想象一下，某一时刻，你的驱动程序获取自旋锁并进入临界代码段；中间某个时刻点，驱动程序可能会丢失CPU的使用权。比如说，调用函数`copy_from_user`，该函数会使进程进入休眠状态；又或许，抢占式内核中，高优先级的任务抢占了CPU的使用权。而此时，你的驱动程序在可预见的时间内无法释放获取的自旋锁。如果其它线程尝试获取该锁，好的情况，一直自旋等待较长时间；坏的情况，系统会发生死锁。

这种情况最好能够避免。因此，自旋锁的主要应用规则就是持有自旋锁的代码必须是原子的。除非是响应中断，否则它不能休眠。（某些情况下，响应中断也不可以）

另外的情况就是内核抢占。spinlock的实现中必须关中断。即使是单处理器系统也必须禁止抢占以避免竞态发生。这就是为什么即使代码不运行在多核机器上，也要适当的加锁的原因。

避免休眠是很困难的；许多内核函数都能够导致休眠，而且这些行为并不总是被很好地说明。`copy_from_user`的调用就是一个很好的例子：在继续拷贝用户空间数据之前，可能需要从硬盘上交换所需的用户空间页，这个操作显然需要休眠。再比如内存分配操作也可能导致休眠；kmalloc函数可能会因为申请的内存空间不足，等待直到所需的空间可用，这也会发生休眠，除非显式地禁止这样做。休眠可能发生在许多意想不到的地方，所以在编写使用自旋锁的代码时必须小心每个调用的函数。

另一种使用场景：驱动刚获取一个自旋锁，控制对设备的访问。同时，设备发出中断，中断服务程序在访问设备之前，也必须获取该自旋锁。而在中断服务程序中获取自旋锁是合法的，这也是自旋锁不能休眠的一个原因。因为中断服务程序一直在自旋等待，而获取自旋锁的代码又不能运行而释放自旋锁。所以，CPU只能一直自旋等待中，这不是我们想要的。

可通过禁止中断，避免这种情况（同一CPU）。有许多与禁止中断相关的操作自旋锁的函数（在下面的一章[5.5.3 自旋锁函数](#5.5.3)中我们会介绍）。但是，完整的中断介绍需要等待第10章。

自旋锁另外一条重要的原则就是：保持自旋锁的时间必须尽可能短。保持自旋锁的时间越长，另一个处理器自旋等待的时间就越长，从而影响调度效率。在2.5内核版本中，内核开发人员为减少内核等待时间做了很多努力。

> <font color="red">总结：</font>
>
> <font color="red">1. 使用自旋锁保护的临界代码段必须是原子的；</font>
>
> <font color="red">2. 为避免内核抢占，关闭中断；</font>
>
> <font color="red">3. 避免被中断服务程序自旋等待，关闭中断；</font>
>
> <font color="red">4. 保持自旋锁的时间必须尽可能短。</font>

<h3 id="5.5.3">5.5.3 自旋锁函数</h3>

下面是4个对自旋锁进行加锁的函数：

    void spin_lock(spinlock_t *lock);
    void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
    void spin_lock_irq(spinlock_t *lock);
    void spin_lock_bh(spinlock_t *lock)

* spin_lock

    前面已经介绍。

* spin_lock_irqsave

    在对自旋锁进行加锁之前，禁用中断（上一次的中断状态存储在标志位中）。

* spin_lock_irq

    不需要保存之前的中断状态时，禁用中断并对自旋锁进行加锁。

* spin_lock_bh

    禁止软件中断，保留硬件中断使能，然后对其加锁。

如果确定自旋锁将在中断（硬件或软件）上下文中使用，应该调用上面禁用中断的加锁函数。否则，可能发生死锁。

对应的，有4种释放自旋锁的函数：

    void spin_unlock(spinlock_t *lock);
    void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
    void spin_unlock_irq(spinlock_t *lock);
    void spin_unlock_bh(spinlock_t *lock);

每个函数与上面spin_lock的函数相对应，功能也与其相反。`spin_lock_irqsave`和`spin_unlock_irqrestore`必须在同一函数中调用，否则，在某些架构上可能会被打断。

另外，也有一个非阻塞的自旋锁操作函数：

    int spin_trylock(spinlock_t *lock);
    int spin_trylock_bh(spinlock_t *lock);

如果成功返回非0（获得锁），否则返回0。try相关的函数没有禁止中断的版本。

<h3 id="5.5.4">5.5.4 读/写自旋锁</h3>

同读/写信号量一样，内核也提供了读/写自旋锁。其允许任意数量的读进程同时访问临界代码段，但是写进程实行独占访问。头文件是`<linux/spinlock.h>`，类型为`rwlock_t`。声明和初始化有2种方式，如下面的代码片段所示：

    rwlock_t my_rwlock = RW_LOCK_UNLOCKED;  /* 静态方式 */

    rwlock_t my_rwlock;
    rwlock_init(&my_rwlock);                /* 动态方式 */

对于读进程而言，下面的锁操作函数可用：

    void read_lock(rwlock_t *lock);
    void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void read_lock_irq(rwlock_t *lock);
    void read_lock_bh(rwlock_t *lock);
    void read_unlock(rwlock_t *lock);
    void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void read_unlock_irq(rwlock_t *lock);
    void read_unlock_bh(rwlock_t *lock);

这儿没有`read_trylock`类似的函数。

写访问可以使用的锁函数，如下所示：

    void write_lock(rwlock_t *lock);
    void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void write_lock_irq(rwlock_t *lock);
    void write_lock_bh(rwlock_t *lock);
    int write_trylock(rwlock_t *lock);
    void write_unlock(rwlock_t *lock);
    void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void write_unlock_irq(rwlock_t *lock);
    void write_unlock_bh(rwlock_t *lock);

读/写自旋锁同读/写信号量一样，读进程也存在`饥饿`问题。这个行为很少，但是，一旦锁竞争加剧，就会产生这个问题，导致性能变差。

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.6">5.6 锁陷阱</h2>

多年使用锁的经验(早于linux)表明，加锁是很难正确实现的。管理并发本质上是一项棘手的工作，出错的方式有很多。在本节中，我们将快速查看可能出错的事情。

<h3 id="5.6.1">5.6.1 不明确的规则</h3>

如上所述，恰当的加锁机制需要清晰明确的规则。当你创建并发访问的资源时，应该决定使用哪种锁控制对其的访问。加锁机制应该在开始就设计好，后面再想重新设计会非常麻烦。俗话说，"磨刀不误砍柴工"。

编写代码时，肯定会遇到几个函数，它们需要访问被锁保护的数据结构。此时，必须小心调用函数，如果一个请求锁的函数尝试调用另一个请求锁的函数，可能会发生死锁。不论是信号量还是自旋锁都不允许这样。

为了使代码正常工作，有时候必须假设外部的调用者已经加锁成功。通常，在模块内部的静态函数中实现。当写这样的代码时，请用文档注明，这对自己，对使用代码的人都是很好的帮助。

`scull`案例中，采取的设计思想是，由系统调用直接调用的函数去获取保护设备数据访问的信号量。这样，`scull`模块内部的其它函数，都假定信号量已经正确地获取了。

<h3 id="5.6.2">5.6.2 加锁的顺序规则</h3>

In systems with a large number of locks (and the kernel is becoming such a system), it is not unusual for code to need to hold more than one lock at once. If some sort of computation must be performed using two different resources, each of which has its own lock, there is often no alternative to acquiring both locks.

Taking multiple locks can be dangerous, however. If you have two locks, called Lock1 and Lock2, and code needs to acquire both at the same time, you have a potential deadlock. Just imagine one thread locking Lock1 while another simultaneously takes Lock2. Then each thread tries to get the one it doesn’t have. Both threads will deadlock.

The solution to this problem is usually simple: when multiple locks must be acquired, they should always be acquired in the same order. As long as this convention is followed, simple deadlocks like the one described above can be avoided. However, following lock ordering rules can be easier said than done. It is very rare that such rules are actually written down anywhere. Often the best you can do is to see what other code does.

A couple of rules of thumb can help. If you must obtain a lock that is local to your code (a device lock, say) along with a lock belonging to a more central part of the kernel, take your lock first. If you have a combination of semaphores and spinlocks, you must, of course, obtain the semaphore(s) first; calling `down` (which can sleep) while holding a spinlock is a serious error. But most of all, try to avoid situations where you need more than one lock.

> <font color="blue">总结：</font>
>
> <font color="blue">1. 加锁的顺序规则就是，如果使用多个锁，请按照固定的顺序访问各个锁；</font>
>
> <font color="blue">2. 如果信号量和自旋锁同时使用，请先获取信号量；</font>
>
> <font color="blue">3. 尽量避免使用多个锁的情况；</font>


<h3 id="5.6.3">5.6.3 细粒度锁和粗粒度锁的对比</h3>

The first Linux kernel that supported multiprocessor systems was 2.0; it contained exactly one spinlock. The big kernel lock turned the entire kernel into one large critical section; only one CPU could be executing kernel code at any given time. This lock solved the concurrency problem well enough to allow the kernel developers to address all of the other issues involved in supporting SMP. But it did not scale very well. Even a two-processor system could spend a significant amount of time simply waiting for the big kernel lock. The performance of a four-processor system was not even close to that of four independent machines.

So, subsequent kernel releases have included finer-grained locking. In 2.2, one spinlock controlled access to the block I/O subsystem; another worked for networking, and so on. A modern kernel can contain thousands of locks, each protecting one small resource. This sort of fine-grained locking can be good for scalability; it allows each processor to work on its specific task without contending for locks used by other processors. Very few people miss the big kernel lock.

Fine-grained locking comes at a cost, however. In a kernel with thousands of locks, it can be very hard to know which locks you need—and in which order you should acquire them—to perform a specific operation. Remember that locking bugs can be very difficult to find; more locks provide more opportunities for truly nasty locking bugs to creep into the kernel. Fine-grained locking can bring a level of complexity that, over the long term, can have a large, adverse effect on the maintainability of the kernel.

Locking in a device driver is usually relatively straightforward; you can have a single lock that covers everything you do, or you can create one lock for every device you manage. As a general rule, you should start with relatively coarse locking unless you have a real reason to believe that contention could be a problem. Resist the urge to optimize prematurely; the real performance constraints often show up in unexpected places.

If you do suspect that lock contention is hurting performance, you may find the lockmeter tool useful. This patch (available at `[http://oss.sgi.com/projects/lockmeter/](http://oss.sgi.com/projects/lockmeter/)`) instruments the kernel to measure time spent waiting in locks. By looking at the report, you are able to determine quickly whether lock contention is truly the problem or not.

> <font color="blue">总结：</font>
>
> <font color="blue">1. 内核添加自旋锁的过程；</font>
>
> <font color="blue">2. 粗粒度锁降低系统的性能，细粒度锁增加了锁的使用难度；</font>
>
> <font color="blue">3. 驱动编写时，尽量使用粗粒度锁，除非有必须使用细粒度锁的理由；</font>
>
> <font color="blue">4. 检测锁的工具-lockmeter</font>

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.7">5.7 除锁之外的选择</h2>

Linux 内核提供了许多锁原语。但是，如我们已经看到的，锁的设计和实现并非没有缺陷。虽然，信号量和自旋锁不可替代；但是，在某些不需要完全锁定的情况下，也可以通过其他方式设置原子访问。

<h3 id="5.7.1">5.7.1 免锁算法</h3>

Sometimes, you can recast your algorithms to avoid the need for locking altogether. A number of reader/writer situations—if there is only one writer—can often work in this manner. If the writer takes care that the view of the data structure, as seen by the reader, is always consistent, it may be possible to create a lock-free data structure.

A data structure that can often be useful for lockless producer/consumer tasks is the circular buffer. This algorithm involves a producer placing data into one end of an array, while the consumer removes data from the other. When the end of the array is reached, the producer wraps back around to the beginning. So a circular buffer requires an array and two index values to track where the next new value goes and which value should be removed from the buffer next.

When carefully implemented, a circular buffer requires no locking in the absence of multiple producers or consumers. The producer is the only thread that is allowed to modify the write index and the array location it points to. As long as the writer stores a new value into the buffer before updating the write index, the reader will always see a consistent view. The reader, in turn, is the only thread that can access the read index and the value it points to. With a bit of care to ensure that the two pointers do not overrun each other, the producer and the consumer can access the buffer concurrently with no race conditions.

Figure 5-1 shows circular buffer in several states of fill. This buffer has been defined such that an empty condition is indicated by the read and write pointers being equal, while a full condition happens whenever the write pointer is immediately behind the read pointer (being careful to account for a wrap!). When carefully programmed, this
buffer can be used without locks.

![图 5-1](https://raw.githubusercontent.com/tupelo-shen/my_test/master/doc/linux/qemu/Linux_device_drivers_3_images/5-1.PNG)

Circular buffers show up reasonably often in device drivers. Networking adaptors, in particular, often use `circular buffers` to exchange data (packets) with the processor. Note that, as of 2.6.10, there is a generic circular buffer implementation available in the kernel; see `<linux/kfifo.h>` for information on how to use it.

> <font color="blue">总结：</font>
>
> <font color="blue">1. 尽量使用不用锁就可以的算法</font>

<h3 id="5.7.2">5.7.2 原子变量</h3>

Sometimes, a shared resource is a simple integer value. Suppose your driver maintains a shared variable `n_op` that tells how many device operations are currently outstanding. Normally, even a simple operation such as:

    n_op++;

would require locking. Some processors might perform that sort of increment in an atomic manner, but you can’t count on it. But a full locking regime seems like overhead for a simple integer value. For cases like this, the kernel provides an atomic integer type called atomic_t, defined in `<asm/atomic.h>`.

An atomic_t holds an int value on all supported architectures. Because of the way this type works on some processors, however, the full integer range may not be available; thus, you should not count on an atomic_t holding more than 24 bits. The following operations are defined for the type and are guaranteed to be atomic with respect to all processors of an SMP computer. The operations are very fast, because they compile to a single machine instruction whenever possible.

    void atomic_set(atomic_t *v, int i);
    atomic_t v = ATOMIC_INIT(0);

Set the atomic variable v to the integer value i. You can also initialize atomic values at compile time with the ATOMIC_INIT macro.

    int atomic_read(atomic_t *v);

Return the current value of v.

    void atomic_add(int i, atomic_t *v);

Add i to the atomic variable pointed to by v. The return value is void, because there is an extra cost to returning the new value, and most of the time there’s no need to know it.

    void atomic_sub(int i, atomic_t *v);

Subtract i from *v.

    void atomic_inc(atomic_t *v);
    void atomic_dec(atomic_t *v);

Increment or decrement an atomic variable.

    int atomic_inc_and_test(atomic_t *v);
    int atomic_dec_and_test(atomic_t *v);
    int atomic_sub_and_test(int i, atomic_t *v);

Perform the specified operation and test the result; if, after the operation, the atomic value is 0, then the return value is true; otherwise, it is false. Note that there is no atomic_add_and_test.

    int atomic_add_negative(int i, atomic_t *v);

Add the integer variable i to v. The return value is true if the result is negative, false otherwise.

    int atomic_add_return(int i, atomic_t *v);
    int atomic_sub_return(int i, atomic_t *v);
    int atomic_inc_return(atomic_t *v);
    int atomic_dec_return(atomic_t *v);

Behave just like atomic_add and friends, with the exception that they return the new value of the atomic variable to the caller.

As stated earlier, `atomic_t` data items must be accessed only through these functions. If you pass an atomic item to a function that expects an integer argument, you’ll get a compiler error.

You should also bear in mind[牢记在心] that atomic_t values work only when the quantity in question is truly atomic. Operations requiring multiple atomic_t variables still require some other sort of locking. Consider the following code:

    atomic_sub(amount, &first_atomic);
    atomic_add(amount, &second_atomic);

There is a period of time where the amount has been subtracted from the first atomic value but not yet added to the second. If that state of affairs could create trouble for code that might run between the two operations, some form of locking must be employed.

<h3 id="5.7.3">5.7.3 位操作</h3>

The atomic_t type is good for performing integer arithmetic. It doesn’t work as well, however, when you need to manipulate individual bits in an atomic manner. For that purpose, instead, the kernel offers a set of functions that modify or test single bits atomically. Because the whole operation happens in a single step, no interrupt (or other processor) can interfere.

Atomic bit operations are very fast, since they perform the operation using a single machine instruction without disabling interrupts whenever the underlying platform can do that. The functions are architecture dependent and are declared in `<asm/bitops.h>`. They are guaranteed to be atomic even on SMP computers and are useful to keep coherence across processors.

Unfortunately, data typing in these functions is architecture dependent as well. The nr argument (describing which bit to manipulate) is usually defined as int but is unsigned long for a few architectures. The address to be modified is usually a pointer to unsigned long, but a few architectures use void * instead.

The available bit operations are:

    void set_bit(nr, void *addr);

Sets bit number nr in the data item pointed to by addr.

    void clear_bit(nr, void *addr);

Clears the specified bit in the unsigned long datum that lives at addr. Its semantics are otherwise the same as set_bit.

    void change_bit(nr, void *addr);

Toggles the bit.

    test_bit(nr, void *addr);

This function is the only bit operation that doesn’t need to be atomic; it simply returns the current value of the bit.

    int test_and_set_bit(nr, void *addr);
    int test_and_clear_bit(nr, void *addr);
    int test_and_change_bit(nr, void *addr);

Behave atomically like those listed previously, except that they  also return the previous value of the bi t.

When these functions are used to access and modify a shared flag, you don’t have to do anything except call them; they perform their operations in an atomic manner. Using bit operations to manage a lockvariable that controls access to a shared variable, on the other hand, is a little more complicated and deserves an example. Most modern code does not use bit operations in this way, but code like the following still exists in the kernel.

A code segment that needs to access a shared data item tries to atomically acquire a lockusing either test_and_set_bit or test_and_clear_bit. The usual implementation is shown here; it assumes that the locklives at bit nr of address addr. It also assumes that the bit is 0 when the lock is free or nonzero when the lock is busy.

    /* try to set lock */
    while (test_and_set_bit (nr, addr) != 0)
    wait_for_a_while( );
    /* do your work */
    /* release lock, and check... */
    if (test_and_clear_bit(nr, addr) = = 0)
    something_went_wrong( ); /* already released: error */

If you read through the kernel source, you find code that works like this example. It is, however, far better to use spinlocks in new code; spinlocks are well debugged, they handle issues like interrupts and kernel preemption, and others reading your code do not have to work to understand what you are doing.

<h3 id="5.7.4">5.7.4 seqlock锁</h3>

The 2.6 kernel contains a couple of new mechanisms that are intended to provide fast, lockless access to a shared resource. Seqlocks work in situations where the resource to be protected is small, simple, and frequently accessed, and where write access is rare but must be fast. Essentially, they work by allowing readers free access to the resource but requiring those readers to check for collisions with writers and, when such a collision happens, retry their access. Seqlocks generally cannot be used to protect data structures involving pointers, because the reader may be following a pointer that is invalid while the writer is changing the data structure.

Seqlocks are defined in `<linux/seqlock.h>`. There are the two usual methods for initializing a seqlock (which has type seqlock_t):

    seqlock_t lock1 = SEQLOCK_UNLOCKED;
    seqlock_t lock2;
    seqlock_init(&lock2);

Read access works by obtaining an (unsigned) integer sequence value on entry into the critical section. On exit, that sequence value is compared with the current value; if there is a mismatch, the read access must be retried. As a result, reader code has a form like the following:

    unsigned int seq;
    do {
    seq = read_seqbegin(&the_lock);
    /* Do what you need to do */
    } while read_seqretry(&the_lock, seq);

This sort of lockis usually used to protect some sort of simple computation that requires multiple, consistent values. If the test at the end of the computation shows that a concurrent write occurred, the results can be simply discarded and recomputed.

If your seqlockmight be accessed from an interrupt handler, you should use the IRQ-safe versions instead:

    unsigned int read_seqbegin_irqsave(seqlock_t *lock, unsigned long flags);
    int read_seqretry_irqrestore(seqlock_t *lock, unsigned int seq, unsigned long flags);

Writers must obtain an exclusive lockto enter the critical section protected by a seqlock. To do so, call:

    void write_seqlock(seqlock_t *lock);

The write lockis implemented with a spinlock, so all the usual constraints apply. Make a call to:

    void write_sequnlock(seqlock_t *lock);

to release the lock. Since spinlocks are used to control write access, all of the usual variants are available:

    void write_seqlock_irqsave(seqlock_t *lock, unsigned long flags);
    void write_seqlock_irq(seqlock_t *lock);
    void write_seqlock_bh(seqlock_t *lock);
    void write_sequnlock_irqrestore(seqlock_t *lock, unsigned long flags);
    void write_sequnlock_irq(seqlock_t *lock);
    void write_sequnlock_bh(seqlock_t *lock);

There is also a `write_tryseqlock` that returns nonzero if it was able to obtain the lock.

<h3 id="5.7.5">5.7.5 读取-复制-更新</h3>

Read-copy-update (RCU) is an advanced mutual exclusion scheme that can yield high performance in the right conditions. Its use in drivers is rare but not unknown, so it is worth a quick overview here. Those who are interested in the full details of the RCU algorithm can find them in the white paper published by its creator (http://
www.rdrop.com/users/paulmck/rclock/intro/rclock_intro.html).

RCU places a number of constraints on the sort of data structure that it can protect. It is optimized for situations where reads are common and writes are rare. The resources being protected should be accessed via pointers, and all references to those resources must be held only by atomic code. When the data structure needs to be changed, the writing thread makes a copy, changes the copy, then aims the relevant pointer at the new version—thus, the name of the algorithm. When the kernel is sure that no references to the old version remain, it can be freed.

As an example of real-world use of RCU, consider the network routing tables. Every outgoing packet requires a check of the routing tables to determine which interface should be used. The check is fast, and, once the kernel has found the target interface, it no longer needs the routing table entry. RCU allows route lookups to be performed without locking, with significant performance benefits. The Star mode radio IP driver in the kernel also uses RCU to keep track of its list of devices.

Code using RCU should include `<linux/rcupdate.h>`.

On the read side, code using an RCU-protected data structure should bracket its references with calls to rcu_read_lock and rcu_read_unlock. As a result, RCU code tends to look like:

    struct my_stuff *stuff;
    rcu_read_lock( );
    stuff = find_the_stuff(args...);
    do_something_with(stuff);
    rcu_read_unlock( );

The rcu_read_lock call is fast; it disables kernel preemption but does not wait for anything. The code that executes while the read “lock” is held must be atomic. No reference to the protected resource may be used after the call to rcu_read_unlock.

Code that needs to change the protected structure has to carry out a few steps. The first part is easy; it allocates a new structure, copies data from the old one if need be, then replaces the pointer that is seen by the read code. At this point, for the purposes of the read side, the change is complete; any code entering the critical section sees the new version of the data.

All that remains is to free the old version. The problem, of course, is that code running on other processors may still have a reference to the older data, so it cannot be freed immediately. Instead, the write code must wait until it knows that no such reference can exist. Since all code holding references to this data structure must (by the rules) be atomic, we know that once every processor on the system has been scheduled at least once, all references must be gone. So that is what RCU does; it sets aside a callback that waits until all processors have scheduled; that callbackis then run to perform the cleanup work.

Code that changes an RCU-protected data structure must get its cleanup callback by allocating a struct rcu_head, although it doesn’t need to initialize that structure in any way. Often, that structure is simply embedded within the larger resource that is protected by RCU. After the change to that resource is complete, a call should be made to:

    void call_rcu(struct rcu_head *head, void (*func)(void *arg), void *arg);

The given func is called when it is safe to free the resource; it is passed to the same arg that was passed to call_rcu. Usually, the only thing func needs to do is to call `kfree`.

The full RCU interface is more complex than we have seen here; it includes, for example, utility functions for working with protected linked lists. See the relevant header files for the full story.

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>
