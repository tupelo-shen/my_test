<h1 id="0">0 目录</h1>

* [5.1 scull的缺陷](#5.1)
* [5.2 并发及其管理](#5.2)
* [5.3 信号量和互斥](#5.3)
    - [5.3.1 linux信号量实现](#5.3.1)
    - [5.3.2 在scull中使用信号量](#5.3.2)
    - [5.3.3 读/写信号量](#5.3.3)
* [5.4 completion机制](#5.4)
* [5.5 自旋锁](#5.5)
    - [5.5.1 自旋锁API介绍](#5.5.1)
    - [5.5.2 自旋锁和原子上下文](#5.5.2)
    - [5.5.3 自旋锁函数](#5.5.3)
    - [5.5.4 读/写自旋锁](#5.5.4)
* [5.6 锁陷阱](#5.6)
    - [5.6.1 不明确的规则](#5.6.1)
    - [5.6.2 加锁的顺序规则](#5.6.2)
    - [5.6.3 细粒度锁和粗粒度锁的对比](#5.6.3)
* [5.7 除锁之外的选择](#5.7)
    - [5.7.1 免锁算法](#5.7.1)
    - [5.7.2 原子变量](#5.7.2)
    - [5.7.3 位操作](#5.7.3)
    - [5.7.4 seqlock锁](#5.7.4)
    - [5.7.5 读取-复制-更新](#5.7.5)

---

并发问题是操作系统编程中的核心问题之一。并发时相关bug易发生，难解决。所以，驱动程序开发者必须在开始就把并发问题考虑在内。现在让我们看一下，之前我们简单编写的scull驱动程序是否存在潜在的问题。如果有，想出解决办法。

<h2 id="5.1">5.1 scull的缺陷</h2>

让我们看一下scull模块中内存管理相关代码。下面这段代码是write函数实现中的一段代码。Scull代码需要判断它所申请的内存是否被分配。

    if (!dptr->data[s_pos]) {
        dptr->data[s_pos] = kmalloc(quantum, GFP_KERNEL);
        if (!dptr->data[s_pos])
            goto out;
    }

这段代码，咋看上没有什么问题。但是，假设我们的系统中存在2个彼此独立的进程（假设分别为进程A和B），在某一个时刻，同时访问scull设备中的同一偏移的区域，会发生什么呢？假设2个进程都同时访问到第一个if条件语句处，而此时判断的结果恰好是Null，那么它们都会调用kmalloc()函数，申请分配内存，然后将返回的内存指针赋给`dptr->data[s_pos]`，这时，如果A先赋值，那么B赋值时，就会覆盖掉A之前的赋值。那么A申请的内存，就会发生内存泄漏，系统无法找到了。

这就是竞态条件的一个例证。竞态条件就是对共享数据的访问不加控制的结果。竞态条件可能会造成系统崩溃，数据损坏，以及安全问题等。大家可能认为，竞态的发生是一个概率非常非常低的事情，但是，一旦发生，后果就是极其严重的。

让我们在消除scull中的竞态问题前，让我们更全面地对并发做一下了解吧。

<h2 id="5.2">5.2 并发及其管理</h2>

在现代操作系统中，并发的来源有很多种。比如，多用户可能同时访问你的代码；SMP系统可以在不同的CPU上同时执行你的代码；内核代码是可抢占式的，你的驱动程序可能会在任何时候被打断，而替代的进程可能正在运行你的驱动程序；设备硬件中断是异步发生的，可能会造成你的代码同时执行。内核提供了多种延时代码执行的机制、诸如工作队列、tasklet、和定时器，它们可以让你的代码在任何时候运行，而不关注当前的进程正在做什么。另外，现在大多数系统都支持“热插拔”机制，也就是说，在你使用设备期间，它随时有可能消失。

避免竞态条件的出现是一个艰难的任务。实践证明，竞态条件可以通过多思考、使用内核并发控制原语、及采用一些基本原则去避免。接下来，我们首先介绍这些原则，而后再研究如何应用它们。

* **原则一：尽量避免使用共享资源。**

    竞态条件就是因对资源的共享访问而产生的。所以，第一条经验准则就是牢记避免在你的驱动程序中使用共享资源。没有并发访问，也就没有竞态条件。如果非得在程序中使用共享资源，必须有“不得不这样做”的理由。

    但是，实际情况就是，共享又经常需要。当遇上了，我们就得面对：

* **原则二：任何时间，发生对硬件或软件资源的访问，而有可能造成竞态条件时，我们必须显式地控制对这些资源的访问。**

    在scull的示例中，我们必须控制对scull的数据结构的访问。我们需要让代码知道，是否已经分配内存，还要让代码知道，分配的内存是“其它人”的。这种访问管理的常用方法就是加锁和互斥-保证同时只有一个线程在控制共享的资源。

    下面让我们专注于分析锁的使用。在此之前，还有一个重要的原则，我们必须作一简单的介绍：内核代码创建一个与其它代码共享对象，在对该对象所有的引用解除之前，其必须一直存在。这条规则带来了2个要求：内核的对象在内核没有处于可运行状态时，必须是不可用的；对该对象的引用必须可被追踪。在大部分时候，引用计数的处理都是由内核完成，但是，万事无绝对。所以，我们必须非常注重细节的实现。

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.3">5.3 信号量和互斥</h2>

所以，让我们看看如何给scull这个示例代码添加锁。保证对scull中的数据结构进行的操作是原子的，意味着如果有其它正在执行的线程也在对该数据结构做操作，当前线程的操作必须立马执行而不会被打断。在我们上面的示例中，我们需要保证如果一个线程发现需要分配一块内存，必须在其它线程也做相同操作之前，完成分配内存的所有操作。为此，我们必须建立临界代码段：保证代码段一段时间内只有一个线程在执行。

不同的需求可能需要不同的临界代码段。在本例中，对scull数据结构的访问，是用户直接请求的结果；没有来自中断服务程序或其它异步执行的进程。也没有特殊的响应时间要求；应用程序通常不需要I/O请求立即响应。进一步讲，scull也没有其它需要临界系统资源，它只访问自己的数据结构。所有的这些意味着，如果scull驱动程序没有取得访问其数据结构的权限就会进入休眠状态，而不用在意其它进程。

在本文中，进入休眠是很明确的。当Linux进程完成操作后，就会进入休眠（或者称为阻塞），将处理器交给其它程序，直到下一次执行。进程为了等待I/O执行完毕，经常需要休眠。但是，我们深入研究内核代码，就会发现很多不能休眠的情况。scull中的write方法是可以实现为阻塞的，因此，我们可以使用加锁机制，使进程在等待访问临界代码的时候，进入休眠状态。

正因如此，我们执行的操作（使用kmalloc分配内存）可能会休眠，在任何时候都有可能发生。如果想要我们的临界代码段正常工作，我们必须使用一个拥有锁的线程休眠的时候还能正常工作的锁原语（locking primitive）。因为并不是所有的锁原语都可以在会发生休眠的地方使用（在本章的后面，我们就会看到一些不能使用的例子）。但是，当前我们最合适的就是信号量。

信号量在计算机科学中是一个很容易理解的概念。本质上，信号量就是一个简单的整数，对其进行的操作称为PV操作。进入某段临界代码段就会调用相关信号量的P操作；如果信号量的值大于0，该值会减1，进程继续执行。相反，如果信号量的值等于0，该进程就会等待，直到有其它程序释放该信号量。解锁信号量的过程就称为V操作，增加信号量的值，并唤醒正在等待的进程。

> <font color="red">注：</font>
> 
> 信号量，这一同步机制为什么称为PV操作。原来，这些术语都是来源于狄克斯特拉使用荷兰文定义的。因为在荷兰文中，通过叫`passeren`，释放叫`vrijgeven`，PV操作因此得名。这是在计算机术语中不是用英语表达的极少数的例子之一。

使用信号量保持几个进程保持互斥，信号量的值被设为1。这样的信号量，在某个时间内只能被一个进程拥有。值为1的信号量有时候也被称为mutex，它是`mutual exclusion`的缩略语。Linux内核中几乎所有的信号量都是用于互斥。

<h3 id="5.3.1">5.3.1 linux信号量实现</h3>

Linux内核提供了符合上述语义的信号量实现，尽管术语略有不同。为了使用信号量，必须包含头文件`<asm/semaphore.h>`。相关的数据结构是`struct semaphore`；实际的信号量可以通过几种方式进行声明和初始化。其中一种就是直接创建信号量，然后使用sema_init()函数进行设置：

    void sema_init(struct semaphore *sem, int val);

在这儿，val是sem的初始值。

但是，通常情况下，信号量都是以互斥的方式使用。为了方便，内核提供了一组辅助函数和宏。因此，可使用下面宏声明一个互斥量并初始化：

    DECLARE_MUTEX(name);
    DECLARE_MUTEX_LOCKED(name);

这儿，产生了一个称为name的信号量，其初始值为0（使用DECLARE_MUTEX_LOCKED）或1（使用DECLARE_MUTEX）。其值为0时，互斥量以一个被锁的状态开始；任何线程想要访问之前，必须被显式地解锁。

在运行时动态初始化互斥量时，调用下面的函数：

    void init_MUTEX(struct semaphore *sem);
    void init_MUTEX_LOCKED(struct semaphore *sem);

> <font color="red">注：</font>
> 
> 在新版本的Linux内核（2.6.37之后）中，上面的函数已经不存在。
> 

Linux中调用P函数-被称为down或者其它变体。在这儿，down指的是函数递减信号量，甚至将调用者休眠一会，直到信号量变得可用，并授予对受保护资源的访问权。这儿有3个版本的down函数：

    void down(struct semaphore *sem);
    int down_interruptible(struct semaphore *sem);
    int down_trylock(struct semaphore *sem);

* down
    
    减少信号量的值，必要时进入休眠状态。

* down_interruptible 
    
    做相同工作，但是可被中断。我们大部分时候想要的都是可中断版本，它允许等待信号量的用户空间进程可被用户中断。作为通用规则，你不想使用非中断版本，除非没有其它选择。不可中断进程是创建不可杀进程的一种好方法（可怕的“D状态”-ps命令的结果中可以看到），但是会令用户烦恼。特别值得注意的是，使用down_interruptible时，如果操作被中断，此时返回值为非零值，而调用者其实已经不再拥有信号量。所以调用down_interruptible时，必须检查返回值，作出相应的处理。

* down_trylock
    
    不会休眠；如果信号量不可用，down_trylock会立即返回，并返回一个非零值。

线程一旦调用了上面的某一个down函数，就会说它拥有信号量。该线程现在有权访问受保护的临界区代码。

Linux中的V函数就是up函数：

    void up(struct semaphore *sem);

一旦调用up，调用者将不再拥有该信号量。

> <font color="red">注：</font>
> 
> 在使用的过程中，获取信号量和释放信号量应该是成对出现的。所以，当错误发生时，必须特别小心。如果在拥有信号量的同时，发生了错误，必须在返回错误状态给调用者之前，释放掉信号量。这是经常容易犯的错误，要格外小心。

<h3 id="5.3.2">5.3.2 在scull中使用信号量</h3>

信号量机制给了scull代码一种避免竞态出现的方法。但是，对于我们编程者来说，怎样掌握这门技巧，确定哪些资源需要被保护，如何使用正确的方式进行加锁访问资源，这些才是我们学习信号量的关键。

让我们再看一次scull_dev结构体：

    struct scull_dev {
        struct          scull_qset *data;   /* 指向第一个量子集的指针 */
        int             quantum;            /* 当前量子的大小 */
        int             qset;               /* 当前数组的大小 */
        unsigned long   size;               /* 数据的大小 */
        unsigned int    access_key;         /* 被sculluid和scullpriv使用 */
        struct          semaphore sem;      /* 互斥信号量 */
        struct          cdev cdev;          /* 字符设备结构 */
    };

在上面的代码片段中，我们需要关注倒数第2个成员，sem，互斥信号量。我们选择为每一个虚拟的scull设备提供一个独立的互斥信号量。

信号量在使用之前必须被初始化。看下面的代码：

    for (i = 0; i < scull_nr_devs; i++) {
        scull_devices[i].quantum = scull_quantum;
        scull_devices[i].qset = scull_qset;
        sema_init(&scull_devices[i].sem, 1);
        scull_setup_cdev(&scull_devices[i], i);
    }

在系统可以使用scull设备之前，互斥信号量sem必须被初始化。因此，sema_init必须在scull_setup_cdev之前进行调用。

接下来，获取互斥信号量以便访问scull_dev结构体。所以，scull_write开头部分的代码如下所示：

    if (down_interruptible(&dev->sem))
        return -ERESTARTSYS;

> <font color="red">注：</font>
> 
> 注意检查down_interruptible的返回值，如果返回非0，说明操作被中断。在这种情况下，通常返回-ERESTARTSYS。基于这个返回码，内核上层代码决定重启调用还是将其错误返回给用户。如果返回-ERESTARTSYS，则必须首先撤消可能已进行的任何用户更改，以便在重试系统调用时操作正确。如果您无法以这种方式撤消操作，则应返回-EINTR。

不论scull_write中的其它代码能否正常执行，都必须释放其占用的信号量。如果执行正常，最后会执行下面的代码：

    out:
        up(&dev->sem);
        return retval;

<h3 id="5.3.3">5.3.3 读写信号量</h3>

信号量为每个调用者提供互斥操作，而不管线程想要做什么。但是，许多任务可以分为2类：一类是只读受保护的数据，而另一类就是改变受保护的数据。也就是说，可能同时很多个读任务，只要没有其它任务在尝试写操作。这样做可以显著优化性能：只读任务可以并行执行，而无需等待其它读任务退出临界代码段。

Linux内核针对这种情况提供了一种称为rwsem的特殊信号量（或读/写信号量）。rwsem在内核中使用较少，但是偶尔也会用。

要想使用rwsem就必须包含`<linux/rwsem.h>`头文件。与读写信号量有关的数据类型是`struct rw_semaphore`；运行时，rwsem必须被显示初始化。使用下面的函数：

    void init_rwsem(struct rw_semaphore *sem);

初始化后，就可以使用下面的这些函数给代码添加读信号量：

    void down_read(struct rw_semaphore *sem);
    int down_read_trylock(struct rw_semaphore *sem);
    void up_read(struct rw_semaphore *sem);

down_read 提供阻塞访问，也就是在访问受保护的资源的时候，如果没有获取权限就会进入不可中断的休眠状态。down_read_trylock提供非阻塞访问，如果获取权限，就返回非0；否则返回0。这儿值得注意的是，down_read_trylock的返回值与大部分的Linux内核函数不同，后者在成功时返回0。

处理写信号量的函数为:

    void down_write(struct rw_semaphore *sem);
    int down_write_trylock(struct rw_semaphore *sem);
    void up_write(struct rw_semaphore *sem);
    void downgrade_write(struct rw_semaphore *sem);

down_write、down_write_trylock、up_write与上面读信号量的处理函数类似，除了它们提供的是写操作权限外。有时候，在写操作后紧跟较长周期的只读操作时，可以使用downgrade_write将写信号量降级为读信号量，以便其它读操作在写保护之后立即响应。

一个rwsem可以允许一个写操作或者多个读操作拥有信号量。写操作拥有优先权：只要写操作尝试进入临界代码段，其它读操作直到写操作完成才能进入。如果有许多写操作在竞争信号量，因为读操作长时间获取不到访问权限而导致阻塞。基于这个原因，rwsem最好在写操作较少，且拥有锁的时间比较短的时候使用。

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.4">5.4 completion机制</h2>

内核编程中的一个常见模式就是在当前进程之外再启动某个活动，比如创建新的内核线程或用户空间进程，向已存在的进程发起请求，再或者一些基于硬件的操作。针对这些情况，内核可以尝试使用信号量同步两个任务，代码如下：

    struct semaphore sem;

    init_MUTEX_LOCKED(&sem);
    start_external_task(&sem);
    down(&sem);

当外部的任务完成操作后，调用up(&sem)释放信号量。

事实证明，在这些情况下信号量不是最好的工具。正常的情况下，代码尝试给信号量加锁时，几乎一直是可用的；但是，如果对信号量的竞争加剧的情况下，性能会变糟糕，加锁的机制需要被重新审视。所以，信号量针对“可用”情况进行了优化。但是，如果把上面的方法应用到通信任务时，调用down的线程几乎总是处于等待中，因此，性能将会变得糟糕。而且，如果将信号量声明为自动变量，按照上面的方法，这些信号量也会存在竞态条件。在某些情况下，在进程尝试调用up函数之前，这个信号量可能会消失。

基于上面提到的情况，内核版本2.4.7里添加了completion机制。Completion是任务间的轻量级同步机制：允许一个线程告知另一个线程工作已经完成。要想使用completion，需要包含头文件`<linux/completion.h>`，可以使用下面的声明语句进行声明：

    DECLARE_COMPLETION(my_completion);

也可以使用下面的代码动态声明：

    struct completion my_completion;
    /* ... */
    init_completion(&my_completion);

等待completion使用下面的方法：

    void wait_for_completion(struct completion *c);

> <font color="red">注：</font>
> 
> <font color="red">wait_for_completion执行不可中断的等待。如果代码调用了该函数，而且被等待的任务没有完成，结果就是，等待的任务就是一个不可杀的进程。</font>

可以通过下面的函数，发出任务完成的事件：

    void complete(struct completion *c);
    void complete_all(struct completion *c);

上面两个函数的行为是不一样的。complete()函数仅唤醒一个等待的任务，而complete_all()函数唤醒所有正在等待该完成事件的任务。如果只有一个等待者，这两个函数将会产生相同的结果。

completion机制通常是一次性的，用过即抛弃。但是，如果处理得当，完全可以重用completion结构体:只要正在发送的事件没有歧义，且没有调用complete_all()函数，重用completion结构就没有问题；但是，如果调用了complete_all()函数，再次使用之前，必须使用下面的宏进行重新初始化：

    INIT_COMPLETION(struct completion c);

这个函数可以快速的完成重新初始化。

关于completion机制如何使用，请参考complete的模块示例。该模块定义了一个这样的模块：任何尝试读取设备的进程都会进入等待状态（通过调用wait_for_completion()函数实现），直到有其它进行尝试写该设备。代码类似于下面的代码：

    DECLARE_COMPLETION(comp);
    ssize_t complete_read (struct file *filp, char __user *buf, size_t count, loff_t
            *pos)
    {
        printk(KERN_DEBUG "process %i (%s) going to sleep\n",
                current->pid, current->comm);
        wait_for_completion(&comp);
        printk(KERN_DEBUG "awoken %i (%s)\n", current->pid, current->comm);
        return 0;
    }
    ssize_t complete_write (struct file *filp, const char __user *buf, size_t count,
            loff_t *pos)
    {
        printk(KERN_DEBUG "process %i (%s) awakening the readers...\n",
                current->pid, current->comm);
        complete(&comp);
        return count; /* 成功，避免重试 */
    }

在上面的示例中，可能存在多个进程同时读取设备。对设备的一次写操作只能试一个读操作完成，而无法通知其它正在读操作的进程。

completion机制的一个典型应用就是，在模块exit的时候，终止内核线程。在一些典型的例子中，驱动程序的内部工作是在内核线程中使用while(1)循环中实现的。当模块准备好清理时，exit函数就会告诉线程需要退出，然后等待线程的completion事件。基于这个目的，内核提供了一个特殊的函数供线程调用：

    void complete_and_exit(struct completion *c, long retval);

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.5">5.5 自旋锁</h2>

除了信号量之外，Linux内核还提供了一种加锁机制，`spinlock`，中文可以翻译为`自旋锁`。

* 概念
    
    何为自旋锁？它是为实现保护共享资源而提出的一种锁机制。其它，自旋锁和互斥锁比较类似，都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，最多都只能有一个保持者。也就是说，在任何时候最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态；但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，自锁一次由此而来。

* 实现原理
    
    在单处理机环境中可以使用特定的原子级汇编指令swap和test_and_set实现进程互斥，（Swap指令：交换两个内存单元的内容；test_and_set指令取出内存某一单元(位)的值，然后再给该单元(位)赋一个新值，关于为何这两条指令能实现互斥我们不在赘述，读者可以了解其算法） 这些指令涉及对同一存储单元的两次或两次以上操作，这些操作将在几个指令周期内完成，但由于中断只能发生在两条机器指令之间，而同一指令内的多个指令周期不可中断，从而保证swap指令或test_and_set指令的执行不会交叉进行.

    但在多处理机环境中情况有所不同，例如test_and_set指令包括“取”、“送”两个指令周期，两个CPU执行test_and_set(lock)可能发生指令周期上的交叉，假如lock初始为0, CPU1和CPU2可能分别执行完前一个指令周期并通过检测(均为0)，然后分别执行后一个指令周期将lock设置为1，结果都取回0作为判断临界区空闲的依据，从而不能实现互斥. 

    为在多CPU环境中利用test_and_set指令实现进程互斥，硬件需要提供进一步的支持，以保证test_and_set指令执行的原子性. 这种支持多以“锁总线”(bus locking)的形式提供的，由于test_and_set指令对内存的两次操作都需要经过总线，在执行test_and_set指令之前锁住总线，在执行test_and_set指令后开放总线，即可保证test_and_set指令执行的原子性。

* 可能的问题

    * 死锁

        引发这个问题的最常见情况就是递归使用一个自旋锁，即如果一个已经拥有某个自旋锁的CPU想第二次获得这个自旋锁，则该CPU将会发生死锁。此外，如果进程获得自旋锁之后再阻塞，也有可能导致死锁的发生。copy_from_user()、copy_to_user()和kmalloc()等函数都有可能引起阻塞，因此在自旋锁的占用期间不能调用这些函数。所以，在使用自旋锁的时候必须小心。

    * 占用CPU资源
        
        自旋锁实际上就是忙等锁。当锁不可用时，CPU一直循环执行`test and set`操作，直到该锁可用，CPU在等待自旋锁的时候不作任何有用的工作，仅仅是等待。因此，只有在占用锁的时间极短的情况下，使用自旋锁才是合理的。当临界代码段很大或共享设备的时候，需要较长时间占用锁，使用自旋锁会降低系统的性能。

本质上说，自旋锁主要是为多处理器系统设计的，尽管就并发来说，运行抢占式内核的单核系统行为与SMP相像（通过超线程技术实现）。如果单核系统，运行的是非抢占式内核，占有一个自旋锁后，它将永远`自旋`，没有其它线程获取CPU来释放锁。因此，除了那些更改IRQ屏蔽状态的操作以外，运行非抢占式内核的单核系统上的自旋操作已被优化为不执行任何操作。（这句话就是说，这类自旋锁只是关闭中断，没有其它任何操作）。运行抢占式内核的处理器，不管是不是多核系统，都要实现合适的加锁机制。

> <font color="red">注：</font>
> 
> <font color="red">超线程：超线程技术是由Intel公司提出的一项同时多线程（simultaneous multi-theading）技术，允许一个CPU执行多个控制流的技术。它的原理很简单，就是把一颗CPU虚拟成2颗，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU没有什么区别。因此，操作系统会把工作线程分派给这两颗逻辑CPU去执行，让应用程序的多个线程，能够同时在同一颗CPU上执行。注意：两颗逻辑CPU共享单颗物理CPU的所有执行资源。因此，可以简单地认为，超线程技术就是对CPU的虚拟化。</font>

<h3 id="5.5.1">5.5.1 自旋锁API</h3>

The required include file for the spinlock primitives is <linux/spinlock.h>. An actual lock has the type spinlock_t. Like any other data structure, a spinlock must be initialized. This initialization may be done at compile time as follows:

    spinlock_t my_lock = SPIN_LOCK_UNLOCKED;

or at runtime with:

    void spin_lock_init(spinlock_t *lock);

Before entering a critical section, your code must obtain the requisite lock with:

    void spin_lock(spinlock_t *lock);

Note that all spinlockwaits are, by their nature, uninterruptible. Once you call spin_lock, you will spin until the lock becomes available.

To release a lock that you have obtained, pass it to:

    void spin_unlock(spinlock_t *lock);

There are many other spinlockfunctions, and we will lookat them all shortly. But none of them depart from the core idea shown by the functions listed above. There is very little that one can do with a lock, other than lock and release it. However, there are a few rules about how you must work with spinlocks. We will take a moment to look at those before getting into the full spinlock interface.

<h3 id="5.5.2">5.5.2 自旋锁和原子上下文</h3>

Imagine for a moment that your driver acquires a spinlock and goes about its business within its critical section. Somewhere in the middle, your driver loses the processor. Perhaps it has called a function (copy_from_user, say) that puts the process to sleep. Or, perhaps, kernel preemption kicks in, and a higher-priority process pushes your code aside. Your code is now holding a lock that it will not release any time in the foreseeable future. If some other thread tries to obtain the same lock, it will, in the best case, wait (spinning in the processor) for a very long time. In the worst case, the system could deadlock entirely.

Most readers would agree that this scenario is best avoided. Therefore, the core rule that applies to spinlocks is that any code must, while holding a spinlock, be atomic. It cannot sleep; in fact, it cannot relinquish the processor for any reason except to service interrupts (and sometimes not even then).

The kernel preemption case is handled by the spinlock code itself. Any time kernel code holds a spinlock, preemption is disabled on the relevant processor. Even uniprocessor systems must disable preemption in this way to avoid race conditions. That is why proper locking is required even if you never expect your code to run on a multiprocessor machine.

Avoiding sleep while holding a lock can be more difficult; many kernel functions can sleep, and this behavior is not always well documented. Copying data to or from user
space is an obvious example: the required user-space page may need to be swapped
in from the diskbefore the copy can proceed, and that operation clearly requires a
sleep. Just about any operation that must allocate memory can sleep; kmalloc can
decide to give up the processor, and wait for more memory to become available
unless it is explicitly told not to. Sleeps can happen in surprising places; writing code
that will execute under a spinlockrequires paying attention to every function that
you call.

Here’s another scenario: your driver is executing and has just taken out a lock that
controls access to its device. While the lockis held, the device issues an interrupt,
which causes your interrupt handler to run. The interrupt handler, before accessing
the device, must also obtain the lock. Taking out a spinlock in an interrupt handler is
a legitimate thing to do; that is one of the reasons that spinlockoperations do not
sleep. But what happens if the interrupt routine executes in the same processor as the
code that tookout the lockoriginally? While the interrupt handler is spinning, the
noninterrupt code will not be able to run to release the lock. That processor will spin
forever.

Avoiding this trap requires disabling interrupts (on the local CPU only) while the
spinlockis held. There are variants of the spinlockfunctions that will disable interrupts
for you (we’ll see them in the next section). However, a complete discussion of
interrupts must wait until Chapter 10.

The last important rule for spinlockusage is that spinlocks must always be held for
the minimum time possible. The longer you hold a lock, the longer another processor
may have to spin waiting for you to release it, and the chance of it having to spin
at all is greater. Long lockhold times also keep the current processor from scheduling,
meaning that a higher priority process—which really should be able to get the
CPU—may have to wait. The kernel developers put a great deal of effort into reducing
kernel latency (the time a process may have to wait to be scheduled) in the 2.5
development series. A poorly written driver can wipe out all that progress just by
holding a lockfor too long. To avoid creating this sort of problem, make a point of
keeping your lock-hold times short.

<h3 id="5.5.3">5.5.3 自旋锁函数</h3>

We have already seen two functions, spin_lock and spin_unlock, that manipulate spinlocks.
There are several other functions, however, with similar names and purposes.
We will now present the full set. This discussion will take us into ground we will not
be able to cover properly for a few chapters yet; a complete understanding of the spinlock
API requires an understanding of interrupt handling and related concepts.

There are actually four functions that can lock a spinlock:

    void spin_lock(spinlock_t *lock);
    void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
    void spin_lock_irq(spinlock_t *lock);
    void spin_lock_bh(spinlock_t *lock)

We have already seen how spin_lock works. spin_lock_irqsave disables interrupts (on
the local processor only) before taking the spinlock; the previous interrupt state is
stored in flags. If you are absolutely sure nothing else might have already disabled
interrupts on your processor (or, in other words, you are sure that you should enable
interrupts when you release your spinlock), you can use spin_lock_irq instead and
not have to keep track of the flags. Finally, spin_lock_bh disables software interrupts
before taking the lock, but leaves hardware interrupts enabled.

If you have a spinlockthat can be taken by code that runs in (hardware or software)
interrupt context, you must use one of the forms of spin_lock that disables interrupts.
Doing otherwise can deadlockthe system, sooner or later. If you do not access
your lockin a hardware interrupt handler, but you do via software interrupts (in
code that runs out of a tasklet, for example, a topic covered in Chapter 7), you can
use spin_lock_bh to safely avoid deadlocks while still allowing hardware interrupts to
be serviced.

There are also four ways to release a spinlock; the one you use must correspond to
the function you used to take the lock:

    void spin_unlock(spinlock_t *lock);
    void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
    void spin_unlock_irq(spinlock_t *lock);
    void spin_unlock_bh(spinlock_t *lock);

Each spin_unlock variant undoes the workperformed by the corresponding spin_lock
function. The flags argument passed to spin_unlock_irqrestore must be the same
variable passed to spin_lock_irqsave. You must also call spin_lock_irqsave and spin_
unlock_irqrestore in the same function; otherwise, your code may breakon some
architectures.

There is also a set of nonblocking spinlock operations:

    int spin_trylock(spinlock_t *lock);
    int spin_trylock_bh(spinlock_t *lock);

These functions return nonzero on success (the lockwas obtained), 0 otherwise.
There is no “try” version that disables interrupts.

<h3 id="5.5.4">5.5.4 读/写自旋锁</h3>

The kernel provides a reader/writer form of spinlocks that is directly analogous to
the reader/writer semaphores we saw earlier in this chapter. These locks allow any
number of readers into a critical section simultaneously, but writers must have exclusive
access. Reader/writer locks have a type of rwlock_t, defined in <linux/spinlock.h>.
They can be declared and initialized in two ways:

    rwlock_t my_rwlock = RW_LOCK_UNLOCKED; /* Static way */

    rwlock_t my_rwlock;
    rwlock_init(&my_rwlock); /* Dynamic way */

The list of functions available should lookreasonably familiar by now. For readers,
the following functions are available:

    void read_lock(rwlock_t *lock);
    void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void read_lock_irq(rwlock_t *lock);
    void read_lock_bh(rwlock_t *lock);
    void read_unlock(rwlock_t *lock);
    void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void read_unlock_irq(rwlock_t *lock);
    void read_unlock_bh(rwlock_t *lock);

Interestingly, there is no read_trylock.

The functions for write access are similar:

    void write_lock(rwlock_t *lock);
    void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void write_lock_irq(rwlock_t *lock);
    void write_lock_bh(rwlock_t *lock);
    int write_trylock(rwlock_t *lock);
    void write_unlock(rwlock_t *lock);
    void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void write_unlock_irq(rwlock_t *lock);
    void write_unlock_bh(rwlock_t *lock);


Reader/writer locks can starve readers just as rwsems can. This behavior is rarely a
problem; however, if there is enough lockcontention to bring about starvation, performance
is poor anyway.

<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.6">5.6 锁陷阱</h2>

Many years of experience with locks—experience that predates Linux—have shown
that locking can be very hard to get right. Managing concurrency is an inherently
tricky undertaking, and there are many ways of making mistakes. In this section, we
take a quick look at things that can go wrong.


<h3 id="5.6.1">5.6.1 不明确的规则</h3>

<h3 id="5.6.2">5.6.2 加锁的顺序规则</h3>

<h3 id="5.6.3">5.6.3 细粒度锁和粗粒度锁的对比</h3>


<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>

<h2 id="5.7">5.7 除锁之外的选择</h2>

<h3 id="5.7.1">5.7.1 免锁算法</h3>

<h3 id="5.7.2">5.7.2 原子变量</h3>


<h3 id="5.7.3">5.7.3 位操作</h3>

<h3 id="5.7.4">5.7.4 seqlock锁</h3>

<h3 id="5.7.5">5.7.5 读取-复制-更新</h3>


<div style="text-align: right"><a href="#0">回到顶部</a><a name="_label0"></a></div>
