* [8.1 kmalloc](#8.1)
    * [8.1.1 参数-flags](#8.1.1)
    * [8.1.2 参数-size](#8.1.2)
* [8.2 后备高速缓存](#8.2)
    - [8.2.1 一个基于Slab缓存的scull：scullc](8.2.1)
    - [8.2.2 内存池](8.2.2)
* [8.3 get_free_page及其辅助函数](#8.3)
    - [8.3.1 一个使用整页的scull设备：scullp](#8.3.1)
    - [8.3.2 alloc_pages接口](#8.3.2)
    - [8.3.3 vmalloc及其辅助函数](#8.3.3)
    - [8.3.4 一个使用虚拟地址的scull设备：scullv](#8.3.4)
* [8.4 Per-CPU Variables](#8.4)
* [8.5 Obtaining Large Buffers](#8.5)

***

到目前为止，我们已经使用过kmalloc和kfree两个函数分配和释放内存。但是，Linux内核还提供了丰富的内存分配函数。本章，我们将学习在驱动程序中使用其它内存方法，以及如何去优化系统内存资源。我们不会关注不同体系架构管理内存的方法的不同。驱动模块不会涉及分段，分页等，因为内核为驱动程序提供了统一的内存分配函数接口。另外，也不会讨论内存管理实现的细节，推迟到第15章。

***
<h2 id="8.1">8.1 kmalloc </h2>

`kmalloc`与`malloc`有一定的相似性。该函数速度非常快（除非它阻塞），它不会清除获取的内存；所以获取内存后，需要用户手动清除。分配的内存是一段连续的物理内存。

<h3 id="8.1.1">8.1.1 参数-flags </h3>
***

`kmalloc` 的原型是：

    #include <linux/slab.h>
    void *kmalloc(size_t size, int flags);

`size`是分配内存块的大小。`flags`是分配标志，控制`kmalloc`的几种不同行为。

给运行在内核空间的进程分配内存（内部最终调用`__get_free_pages`， 这也是`GFP_`前缀的由来）。换句话说，调用最终执行系统调用。使用`GFP_KERNEL`意味着，当在低内存的情况下调用时，`kmalloc`函数可以使当前进程休眠，等待有足够的内存分配。因此，使用`GFP_KERNEL`分配内存的函数必须是可重入的，且不能在原子上下文中运行。当前进程休眠时，内核会采取恰当的手段查找空闲内存，方法就是将缓冲区刷新到磁盘或从用户空间交换内存。

有时候，使用`GFP_KERNEL`标志不合适，比如在中断服务程序，`tasklet`，和内核定时器等中发生内存分配时，我们是不希望进程休眠的。所以，驱动程序可以使用`GFP_ATOMIC`代替。内核经常保留一些空间内存页以满足原子分配。使用`GFP_ATOMIC`时，`kmalloc`甚至可以使用最后一个空闲内存页。但是如果一个空闲内存页也没有，则分配失败。

虽然`GFP_KERNEL`和`GFP_ATOMIC`能够满足大部分设备驱动程序的需求，但除此之外，还有一些其它的标志。它们都定义在`<linux/gfp.h>`头文件中。有一些标志，使用双下划綫作为前缀，比如，`__GFP_DMA`。

* GFP_ATOMIC

    为中断服务程序或其它进程之外的代码分配内存。不会休眠。

* GFP_KERNEL

    内核内存的正常分配函数。可以休眠。

* GFP_USER

    为用户空间页面分配内存。可以休眠。

* GFP_HIGHUSER

    同`GFP_USER`，但是从高内存分配。

* GFP_NOIO
* GFP_NOFS

    这两个标志很像`GFP_KERNEL`，但是对于内核可以做什么作了限制。`GFP_NOFS`不允许执行文件系统调用，而`GFP_NOIO`不允许任何I/O初始化。它们主要用在文件系统和虚拟内存代码中，允许休眠，但是递归文件系统调用是个坏主意。

上面列出的分配标志可以和下面的标志进行`或`操作，组合使用，以改变分配方式：

* __GFP_DMA

    请求在具有DMA功能的内存区域进行分配。具体依赖于平台。

* __GFP_HIGHMEM

    从高内存区域分配内存。关于高内存看下面的介绍。

* __GFP_COLD

    通常情况下，内存分配器尽可能分配“高速缓存”。相反，该标志就是请求一段时间内没有使用的内存页。对于DMA读请求非常有用，但是对高速缓存就没有啥用了。

* __GFP_NOWARN

    阻止请求失败时内核发出的警告信息。几乎不用。

* __GFP_HIGH

    高优先级请求，即使内核为紧急事件准备的备用内存它也可以使用。

* __GFP_REPEAT

    重复尝试分配，但仍然有可能会失败。

* __GFP_NOFAIL

    告诉内核分配内存不能失败，不建议使用。

* __GFP_NORETRY

    告诉分配器，如果请求内存不可用立即放弃。

组合使用方法举例：

1. 用于DMA的内存，可以休眠：   GFP_DMA | GFP_KERNEL

2. 用于DMA的内存，不可以休眠：  GFP_DMA |GFP_ATOMIC


####内存区域
***

`__GFP_DMA`和`__GFP_HIGHMEM`是依赖于平台的，尽管在所有的平台上都可以指定。

Linux 内核至少应该可以访问三种内存区域： DMA内存， 普通内存， 高内存。设置不同的标志位，可以访问不同的内存区域。

DMA内存是外设可以执行DMA访问的优先内存地址。在x86系统上，DMA内存区域使用RAM起始的16MB空间，`legacy ISA`设备可以执行DMA访问；PCI设备则没有这个限制。

高内存是在32位系统上访问大容量内存的一种机制。如果没有建立特殊的内存映射，内核无法直接访问高地址内存。

三种内存区域的比较：

| 区 | 描述 | 物理内存 |
| ------ | ------ | ------ |
| DMA内存 | 可以DMA访问的内存 | <16MB |
| 普通内存 | 正常可寻址的内存 | 16~896MB |
| 高内存 | 动态映射的内存 | >896MB |

每当要分配内存时，内核先确定指定区域内是否有可用的内存页。如果`__GFP_DMA`被指定，仅在DMA区域内搜索：如果没有地址可用，则分配失败。如果没有指定分配标志，则普通内存和DMA内存都会被搜索。如果设置了`__GFP_HIGHMEM`，则上面提到的三个区域都会被搜索。（但是，请注意，`kmalloc`不能分配高内存。

<h3 id="8.1.2">8.1.2 参数-size </h3>
***

内核管理的系统物理内存必须是页面化的块。结果就是，`kmalloc`与典型的用户空间的`malloc`实现相当不同。简单的面向堆分配技术在内存页边界处会很难处理。因此，内核使用了特殊的面向页分配技术，从而更好地使用系统的RAM。

Linux 通过创建一组固定大小的内存池对象来处理内存分配。从内存池中选取一整个内存块返回给请求者。内存管理的原理相当复杂，对于设备驱动程序开发来说，不必关心其实现细节。

但是，对于驱动开发者来说，最应该记住的就是，内核只能分配某些预定义的固定大小的字节数组。如果动态请求内存的话，可能得到的比请求的多，最大可以是2倍。另外，请记住，`kmalloc`能够处理的最小分配单元就是32或64字节，依赖于系统体系架构使用的页大小。

`kmalloc`能够分配的内存块的大小是有上限的。这个限制根据体系架构和内核配置选项而不同。如果想要代码具有更好的可移植性，最好不要分配大于128KB的内存空间。如果需要几KB以上的空间，有比`kmalloc`更好的方法，后面会有讨论。

<h2 id="8.2">8.2 后备高速缓存 </h2>

既然，驱动程序需要反反复复地请求分配相同大小的内存对象。而内核已经维护了一组相同大小的内存池对象，那为什么不给这些大量的对象建立特别的内存池呢？事实上，内核有一个创立这类内存池的工具，称为后备高速缓存。设备驱动程序通常不会使用它，但是Linux 2.6以后版本的内核中，USB和SCSI使用了高速缓存。

在linux内核中，cache管理器又称为“slab分配器”。创建高速缓存的函数原型如下所示，声明位于`<linux/slab.h>`文件中。

    kmem_cache_t *kmem_cache_create(const char *name, size_t size, size_t offset, unsigned long flags,
        void (*constructor)(void *, kmem_cache_t *, unsigned long flags),
        void (*destructor)(void *, kmem_cache_t *, unsigned long flags));

该函数返回一块类型为`kmem_cache_t`的高速缓存，在其中包含许多相同大小的内存块，大小由参数`size`指定。`name`，就是作为追踪问题时的信息。通常被命名为要保存的结构体的类型。缓存只是包含了`name`的一个指针，并没有复制它的内容，所以，必须给该函数传递一个`static`存储空间中的字符串的指针。该字符串不能包含空格。`offset`是页内的第一个对象的偏移量；最好使用0作为默认值。`flags`控制分配方式，是以下标志的位掩码。

* SLAB_NO_REAP

    设置此标志可防止在系统查找内存时缓存减少。 设置此标志通常是个坏主意; 重要的是避免不必要地限制内存分配器的操作自由。

* SLAB_HWCACHE_ALIGN

    设置这个标志，每个数据对象与高速缓存行对齐；真实的对齐方式还依赖于主机平台的缓存布局。在SMP计算机上，对于经常访问的内容，此选项是一个不错的选择。但是，为了满足缓存行对齐，实施填充也浪费了大量的内存。

* SLAB_CACHE_DMA

    要求每个数据对象被分配到DMA内存中。

参数`constructor`和`destructor`是可选项，前者可以用来初始化分配的对象；后者可以用来在释放内存到系统中时清空内存。

虽然，参数`constructor`和`destructor`很有用，但是也有些限制。当为一组对象分配内存时就会调用`constructor`；因为该内存块存储了几个对象，`constructor`可能会被调用好几次。不能假设`constructor`再分配对象时会立即起作用。同理，`destructor`也是如此。`constructor`和`destructor`是否能休眠，取决于是否传递了`SLAB_CTOR_ATOMIC`标志（`CTOR`是`constructor`的缩写）。

为了方便，`constructor`和`destructor`可以使用相同的函数；当调用的是`constructor`时，`slab`分配器总是传递`SLAB_CTOR_CONSTRUCTOR`标志。

一旦缓存建立，就可以调用`kmem_cache_alloc`为对象分配高速缓存了:

    void *kmem_cache_alloc(kmem_cache_t *cache, int flags);

在这儿，`cache`是前面创建的高速缓存；`flags`和传递给`kmalloc`的一样，如果`kmem_cache_alloc`需要更多内存时，则需要调用这些标志。注意如果缓存目前为空，那么这个函数就会调用 `cache_alloc_refill` 向缓存中增加内存。

释放对象，使用`kmem_cache_free`:

    void kmem_cache_free(kmem_cache_t *cache, const void *obj);

当驱动程序使用完`cache`之后，比较典型的就是驱动模块被卸载时，应该调用下面的函数销毁该`cache`。

    int kmem_cache_destroy(kmem_cache_t *cache);

只有当从缓存分配的对象都已经释放掉缓存后，销毁操作才能成功。因此，应该检查函数`kmem_cache_destroy`的返回状态。失败的话，表示驱动模块内存在着内存泄漏（因为某些对象被漏掉了）。

使用备用缓存的一个附带好处就是内核维护着`cache`使用情况。可以从`/proc/slabinfo`中获取这些信息。

<h3 id="8.2.1">8.2.1 一个基于Slab缓存的scull：scullc </h3>
***

`scullc`与`scull`的不同就是：`scull`使用的连续内存，调用的分配内存函数是`kmalloc`，而`scullc`使用的是缓存。在`scull`中，量子的大小只能在编译或者加载的时候可以修改，不能在运行时修改。如果想要在运行时修改，就要使用新的缓存了。

`scullc`可以用来验证slab分配器。与`scull`的代码大部分相同。首先，看一下声明slab缓存的函数：

    /* 声明一个cache指针: 所有设备都用它 */
    kmem_cache_t *scullc_cache;

模块加载时，使用下面的方式创建slab cache：

    /* scullc_init: 创建cache */
    scullc_cache = kmem_cache_create("scullc", scullc_quantum, 0,
            SLAB_HWCACHE_ALIGN, NULL, NULL); /* no ctor/dtor */
    if (!scullc_cache) {
        scullc_cleanup( );
        return -ENOMEM;
    }

从cache中为量子分配存储空间:

    /* 使用cache分配量子 */
    if (!dptr->data[s_pos]) {
        dptr->data[s_pos] = kmem_cache_alloc(scullc_cache, GFP_KERNEL);
        if (!dptr->data[s_pos])
            goto nomem;
        memset(dptr->data[s_pos], 0, scullc_quantum);
    }

释放量子所占用的cache:

    for (i = 0; i < qset; i++)
    if (dptr->data[i])
        kmem_cache_free(scullc_cache, dptr->data[i]);

最后，在卸载模块的时候，销毁创建的cache：

    /* scullc_cleanup: 销毁创建的cache */
    if (scullc_cache)
        kmem_cache_destroy(scullc_cache);

`scullc`相比`scull`而言，速度略有提高，内存使用效果更好。由于quanta是从大小合适的内存片段中分配的，它们在内存中的位置尽可能密集，而scull quanta则会导致不可预测的内存碎片。

***
<h3 id="8.2.2">8.2.2 内存池 </h3>
***

内核中有些地方分配内存是不允许失败的。为了保证不失败，内核开发者创建了一个`内存池`的抽象概念（“mempool”）。内存池与备用缓存的形式类似，保存一个可用内存表，以便在紧急情况下使用。

内存池数据结构如下：

    typedef struct mempool_s {
           spinlock_t lock;
           int min_nr;              /* elements数组中的成员数量 */
           int curr_nr;             /* 当前elements数组中空闲的成员数量 */
           void **elements;         /* 用来存放内存成员的二维数组，其长度为min_nr，宽度是上述各个内存对象的长度，*/
                                    /* 因为对于不同的对象类型，我们会创建相应的内存池对象，*/
                                    /* 所以每个内存池对象实例的element宽度都是跟其内存对象相关的 */
           void *pool_data;         /* 内存池与内核缓冲区结合使用（上面的简介当中提到了，*/
                                    /* Linux采用slab技术预先为每一种内存对象分配了缓存区，*/
                                    /* 每当我们申请某个类型的内存对象时，实际是从这种缓存区获取内存），*/
                                    /* 这个指针一般是指向这种内存对象对应的缓存区的指针 */
           mempool_alloc_t *alloc;  /* 用户在创建一个内存池对象时提供的内存分配函数，*/
                                    /* 这个函数可以用户自行编写（因为对于某个内存对象如何获取内存，*/
                                    /* 其开发者完全可以自行控制），也可以采用内存池提供的分配函数 */
           mempool_free_t *free;    /* 内存释放函数，其它同上 */
           wait_queue_head_t wait;  /* 任务等待队列 */
    } mempool_t;

内存池的创建函数原型声明位于文件`<linux/mempool.h>`中，返回数据类型为`mempool_t`。

    mempool_t *mempool_create(int min_nr,
                            mempool_alloc_t *alloc_fn,
                            mempool_free_t *free_fn,
                            void *pool_data);

参数`min_nr`是内存池应始终保留的最小分配对象数。实际的分配和释放对象的工作由函数`alloc_fn`和`free_fn`实现。它们的原型如下：

    typedef void *(mempool_alloc_t)(int gfp_mask, void *pool_data);
    typedef void (mempool_free_t)(void *element, void *pool_data);

函数`mempool_create`的最后一个参数`pool_data`传递给函数`alloc_fn`和`free_fn`。

如果有必要的话，可以自己写特殊的函数去处理内存池的内存分配问题。但是，通常情况下，调用内核slab分配器就可以了。内核slab分配器有2个函数（`mempool_alloc_slab`和`mempool_free_slab`）与上面的2个函数原型匹配，它们使用`kmem_cache_alloc`和`kmem_cache_free`分配内存。因而，建立内存池的代码通常如下所示：

    cache = kmem_cache_create(. . .);
    pool = mempool_create(MY_POOL_MINIMUM,
                        mempool_alloc_slab, mempool_free_slab,
                        cache);

一旦内存池建立，为对象分配和释放内存的函数为：

    void *mempool_alloc(mempool_t *pool, int gfp_mask);
    void mempool_free(void *element, mempool_t *pool);

当内存池`mempool`被建立时，分配函数会在内存池中创建预分配对象。调用`mempool_alloc`时，先是调用传递给`mempool_create`函数的第二个参数，内存分配函数申请额外的内存对象；分配失败的话，才会从内存池的预分配对象中返回一个。但是，当预分配对象低于`minimum`规定的内存池最小预分配对象数时，额外申请的内存对象就会保留在内存池中，大于最小内存池分配对象的时候才会释放会系统。

内存池可以调整大小：

    int mempool_resize(mempool_t *pool, int new_min_nr, int gfp_mask);

如果成功，调整内存池的大小使其至少具有`new_min_nr`个对象：

销毁内存池的函数为：

    void mempool_destroy(mempool_t *pool);

在销毁内存池之前，必须释放所有已分配的对象，否则必须报内核故障`kernel oops`。

如果想要在驱动中使用内存池时，请注意：内存池申请了大量内存，且处于空闲，也没有什么实质用处。所以，首选的方案不是使用内存池，而是想办法解决内存失败的可能性。只要你的驱动中处理内存分配失败的方法不会危害系统的整体性就行。在驱动程序中使用内存池的时候应该比较少。

***
<h2 id="8.3">8.3 get_free_page及其辅助函数</h2>

如果模块需要申请大块内存，通常使用基于页的技术更好。并且，整页请求还有其它好处，这个会在第15章介绍。

按页分配的函数：

* get_zeroed_page(unsigned int flags);

    返回指向新页的指针，并用 `0` 填充页面。

* __get_free_page(unsigned int flags);

    与`get_zeroed_page`一样，但是不会清空页面。

* __get_free_pages(unsigned int flags, unsigned int order);

    分配一个可能是多个（物理上连续）内存页的内存区域，返回该内存区域的第一个字节的指针，但是不会清零。

参数`flags`和函数`kmalloc`一样；通常使用`GFP_KERNEL`和`GFP_ATOMIC`，有可能加上`__GFP_DMA`(可以用来进行ISA直接内存访问操作)使用，还有可能在使用高内存时，加上标志`__GFP_HIGHMEM`。参数`order`是2的指数。例如，如果你申请1页，则`order`是0；如果申请8页，则`order`是3。如果`order`太大（没有这么大的内存可以使用），页分配失败。`get_order`函数，用来从主机提供的大小中获取`order`的值，这里内存的大小必须是2的幂。`order`的最大允许值是10或11（对应于1024或2048页），具体取决于体系结构。然而，除了具有大量内存的新的引导系统之外，`order`为10时分配内存成功的可能性比较小。

如果好奇的话，读取`/proc/buddyinfo`，就能够知道每个内存区域内，每个`order`下有多少个可用的内存块。使用命令，`cat /proc/buddyinfo`打印下面的内容，

    Node 0, zone      DMA      8      8      2      3      1      3      2      2      2      0      0
    Node 0, zone   Normal     85    294    375    333    191     40     25      6      7      2      2
    Node 0, zone  HighMem     65     78    150     97     14      2      1      1      0      0      0

在linux中使用buddy算法解决物理内存的外碎片问题，其把所有空闲的内存，以2的幂次方的形式，分成11个块链表，分别对应为1、2、4、8、16、32、64、128、256、512、1024个页块。

而Linux支持NUMA技术，对于NUMA设备，NUMA系统的结点通常是由一组CPU和本地内存组成，每一个节点都有相应的本地内存，因此buddyinfo 中的Node0表示节点ID；而每一个节点下的内存设备，又可以划分为多个内存区域（zone），因此上面的显示中，对于Node 0的内存，又划分类DMA、Normal、HighMem区域。而后面则是表示空闲的区域。

此处以Normal区域进行分析，第二列值为294，表示当前系统第0片CPU上的内存的normal区域，可用的连续2页的内存大小为`294*2*PAGE_SIZE`；第三列值为375，表示当前系统中的normal区域中，可用的连续4页的内存大小为`375*2^2*PAGE_SIZE`。

当使用完这些内存页后，就可以使用下面的函数释放掉它们，第一个函数是在第二个函数的基础上实现的宏：

    void free_page(unsigned long addr);
    void free_pages(unsigned long addr, unsigned long order);

如果从分配的内存中释放不同数量的页，内存映射会被破坏，系统也会陷入麻烦中。

函数`__get_free_pages`和函数`kmalloc`一样遵循相同的规则。这些函数在某些情况下，分配内存会失败，尤其是使用`GFP_ATOMIC`标志时。因此，使用这些函数的代码必须对分配内存失败的情况做处理。

如果没有内存可用时，内存分配函数kmalloc(GFP_KERNEL)会失败，但是内核会想尽一切办法满足分配请求。因此，如果分配太多内存很容易就会降低系统的响应速度。例如，如果往scull设备里写入大量数据，就会降低计算机的性能；系统就会不停地搜索，置换出尽可能多的内存以满足kmalloc的分配请求。随着不断增大的设备，系统的资源都会被吸收，计算机就会无法使用；甚至，你都无法启动一个新的进程去解决这个问题。在scull设备中，我们没有解决这个问题，是因为这仅是的示例程序。作为驱动开发者，必须注意，驱动模块程序是一种特权代码，可能会给系统带来新的安全漏洞（最有可能的就是，像刚才介绍的那样，拒绝服务漏洞）。

<h3 id="8.3.1">8.3.1 一个使用整页的scull设备：scullp </h3>
***

我们可以使用scullp设备测试一下页分配机制，像scullc一样，这是一个精简过得scull设备。

scullp设备是按页分配整页或多页给量子：变量scullp_order默认是0，可以在编译或加载时更改。

下面是分配内存相关的代码：

    /* 单个量子的内存分配 */
    if (!dptr->data[s_pos]) {
        dptr->data[s_pos] = (void *)__get_free_pages(GFP_KERNEL, dptr->order);
        if (!dptr->data[s_pos])
            goto nomem;
        memset(dptr->data[s_pos], 0, PAGE_SIZE << dptr->order);
    }

释放内存相关的代码:

    /* 释放一整个量子集 */
    for (i = 0; i < qset; i++)
        if (dptr->data[i])
            free_pages((unsigned long)(dptr->data[i]), dptr->order);

在用户级别，没有内存碎片的话，能感觉到的差异主要就是速度的提升和更好的内存使用。我们分别从`scull0`、`scullp0`拷贝4MB数据到`scull1`、`scullp1`中，结果显示内核空间的CPU使用率有一个轻微的提升。

性能的提升不显著，是因为`kmalloc`本身速度就很快。页分配技术的优势不是速度，而是更有效的使用内存。按页分配不会浪费内存，而使用`kmalloc`会因为分配粒度的原因导致不可预知的内存浪费。

使用`__get_free_page`函数的最大优点就是所获取的内存页完全由你支配。理论上，可以通过对页表进行适当的调整，可以把分配的页组成一个线性区域。例如，你可以允许用户进程将获取的内存区域映射为单一的不相关的内存页。我们将在第15章讨论这种操作，在那章我们将会讨论scullp是怎样提供内存映射，而scull却不能提供。

***
<h3 id="8.3.2">8.3.2 alloc_pages接口 </h3>
***

For completeness, we introduce another interface for memory allocation, even though we will not be prepared to use it until after Chapter 15. For now, suffice it to say that struct page is an internal kernel structure that describes a page of memory. As we will see, there are many places in the kernel where it is necessary to work withpage structures; they are especially useful in any situation where you might be dealing with high memory, which does not have a constant address in kernel space.

Linux页分配器真正的核心是函数`alloc_pages_node`：

    struct page *alloc_pages_node(int nid, unsigned int flags, unsigned int order);

This function also has two variants (which are simply macros); these are the versions that you will most likely use:

    struct page *alloc_pages(unsigned int flags, unsigned int order);
    struct page *alloc_page(unsigned int flags);

The core function, alloc_pages_node, takes three arguments. nid is the NUMA node ID* whose memory should be allocated, flags is the usual GFP_ allocation flags, and order is the size of the allocation. The return value is a pointer to the first of (possibly many) page structures describing the allocated memory, or, as usual, NULL on failure.

alloc_pages simplifies the situation by allocating the memory on the current NUMA node (it calls alloc_pages_node with the return value from numa_node_id as the nid parameter). And, of course, alloc_page omits the order parameter and allocates a single page.

To release pages allocated in this manner, you should use one of the following:

    void __free_page(struct page *page);
    void __free_pages(struct page *page, unsigned int order);
    void free_hot_page(struct page *page);
    void free_cold_page(struct page *page);

If you have specific knowledge of whether a single page’s contents are likely to be resident in the processor cache, you should communicate that to the kernel with free_hot_page (for cache-resident pages) or free_cold_page. This information helps the memory allocator optimize its use of memory across the system.

<h3 id="8.3.3">8.3.3 vmalloc及其辅助函数</h3>
***

The next memory allocation function that we show you is vmalloc, which allocates a contiguous memory region in the virtual address space. Although the pages are not consecutive in physical memory (each page is retrieved with a separate call to alloc_page), the kernel sees them as a contiguous range of addresses. vmalloc returns 0 (the NULL address) if an error occurs, otherwise, it returns a pointer to a linear memory area of size at least size.

NUMA (nonuniform memory access) computers are multiprocessor systems where memory is “local” to specific groups of processors (“nodes”). Access to local memory is faster than access to nonlocal memory. On such systems, allocating memory on the correct node is important. Driver authors do not normally have to worry about NUMA issues, however.

We describe vmalloc here because it is one of the fundamental Linux memory allocation mechanisms. We should note, however, that use of vmalloc is discouraged in most situations. Memory obtained from vmalloc is slightly less efficient to work with, and, on some architectures, the amount of address space set aside for vmalloc is relatively small. Code that uses vmalloc is likely to get a chilly reception if submitted for inclusion in the kernel. If possible, you should work directly with individual pages rather than trying to smooth things over with vmalloc.

That said, let’s see how vmalloc works. The prototypes of the function and its relatives (ioremap, which is not strictly an allocation function, is discussed later in this section) are as follows:

    #include <linux/vmalloc.h>
    void *vmalloc(unsigned long size);
    void vfree(void * addr);
    void *ioremap(unsigned long offset, unsigned long size);
    void iounmap(void * addr);

It’s worth stressing that memory addresses returned by kmalloc and _get_free_pages are also virtual addresses. Their actual value is still massaged by the MMU (the memory management unit, usually part of the CPU) before it is used to address physical memory.* vmalloc is not different in how it uses the hardware, but rather in how the kernel performs the allocation task.

The (virtual) address range used by kmalloc and __get_free_pages features a one-toone mapping to physical memory, possibly shifted by a constant PAGE_OFFSET value; the functions don’t need to modify the page tables for that address range. The address range used by vmalloc and ioremap, on the other hand, is completely synthetic, and each allocation builds the (virtual) memory area by suitably setting up the page tables.

This difference can be perceived by comparing the pointers returned by the allocation functions. On some platforms (for example, the x86), addresses returned by vmalloc are just beyond the addresses that kmalloc uses. On other platforms (for example, MIPS, IA-64, and x86_64), they belong to a completely different address range. Addresses available for vmalloc are in the range from VMALLOC_START to VMALLOC_END. Both symbols are defined in <asm/pgtable.h>.

Addresses allocated by vmalloc can’t be used outside of the microprocessor, because they make sense only on top of the processor’s MMU. When a driver needs a real physical address (such as a DMA address, used by peripheral hardware to drive the system’s bus), you can’t easily use vmalloc. The right time to call vmalloc is when you are allocating memory for a large sequential buffer that exists only in software. It’s important to note that vmalloc has more overhead than __get_free_pages, because it must both retrieve the memory and build the page tables. Therefore, it doesn’t make sense to call vmalloc to allocate just one page.

Actually, some architectures define ranges of “virtual” addresses as reserved to address physical memory. When this happens, the Linux kernel takes advantage of the feature, and both the kernel and __get_free_pages addresses lie in one of those memory ranges. The difference is transparent to device drivers and other code that is not directly involved with the memory-management kernel subsystem.

An example of a function in the kernel that uses vmalloc is the create_module system call, which uses vmalloc to get space for the module being created. Code and data of the module are later copied to the allocated space using copy_from_user. In this way, the module appears to be loaded into contiguous memory. You can verify, by looking in /proc/kallsyms, that kernel symbols exported by modules lie in a different memory range from symbols exported by the kernel proper.

Memory allocated with vmalloc is released by vfree, in the same way that kfree releases memory allocated by kmalloc.

Like vmalloc, ioremap builds new page tables; unlike vmalloc, however, it doesn’t actually allocate any memory. The return value of ioremap is a special virtual address that can be used to access the specified physical address range; the virtual address obtained is eventually released by calling iounmap.

ioremap is most useful for mapping the (physical) address of a PCI buffer to (virtual) kernel space. For example, it can be used to access the frame buffer of a PCI video device; such buffers are usually mapped at high physical addresses, outside of the address range for which the kernel builds page tables at boot time. PCI issues are explained in more detail in Chapter 12.

It’s worth noting that for the sake of portability, you should not directly access addresses returned by ioremap as if they were pointers to memory. Rather, you should always use readb and the other I/O functions introduced in Chapter 9. This requirement applies because some platforms, such as the Alpha, are unable to directly map PCI memory regions to the processor address space because of differences between PCI specs and Alpha processors in how data is transferred.

Both ioremap and vmalloc are page oriented (they work by modifying the page tables); consequently, the relocated or allocated size is rounded up to the nearest page boundary. ioremap simulates an unaligned mapping by “rounding down” the address to be remapped and by returning an offset into the first remapped page. One minor drawback of vmalloc is that it can’t be used in atomic context because, internally, it uses kmalloc(GFP_KERNEL) to acquire storage for the page tables, and therefore could sleep. This shouldn’t be a problem—if the use of __get_free_page isn’t good enough for an interrupt handler, the software design needs some cleaning up.

<h3 id="8.3.4">8.3.4 一个使用虚拟地址的scull设备：scullv </h3>
***

Sample code using vmalloc is provided in the scullv module. Like scullp, this module is a stripped-down version of scull that uses a different allocation function to obtain space for the device to store data.

The module allocates memory 16 pages at a time. The allocation is done in large chunks to achieve better performance than scullp and to show something that takes too long with other allocation techniques to be feasible. Allocating more than one page with __get_free_pages is failure prone, and even when it succeeds, it can be slow. As we saw earlier, vmalloc is faster than other functions in allocating several pages, but somewhat slower when retrieving a single page, because of the overhead of page-table building. scullv is designed like scullp. order specifies the “order” of each allocation and defaults to 4. The only difference between scullv and scullp is in allocation management. These lines use vmalloc to obtain new memory:

    /* 使用虚地址分配量子 */
    if (!dptr->data[s_pos]) {
        dptr->data[s_pos] = (void *)vmalloc(PAGE_SIZE << dptr->order);
        if (!dptr->data[s_pos])
            goto nomem;
        memset(dptr->data[s_pos], 0, PAGE_SIZE << dptr->order);
    }

释放内存：

    /* 释放量子集 */
    for (i = 0; i < qset; i++)
        if (dptr->data[i])
            vfree(dptr->data[i]);

如果编译两个模块的时候，使能了debug功能，你可以通过读取它们在/proc文件系统下创建的文件来查看它们的数据分配。下面是在x86_64系统上打印出的信息：

    salma% cat /tmp/bigfile > /dev/scullp0; head -5 /proc/scullpmem
    Device 0: qset 500, order 0, sz 1535135
        item at 000001001847da58, qset at 000001001db4c000
            0:1001db56000
            1:1003d1c7000
    salma% cat /tmp/bigfile > /dev/scullv0; head -5 /proc/scullvmem
    Device 0: qset 500, order 4, sz 1535135
        item at 000001001847da58, qset at 0000010013dea000
            0:ffffff0001177000
            1:ffffff0001188000

下面的输出，是在x86系统上：

    sudo% cat /tmp/bigfile > /dev/scullp0; head -5 /proc/scullpmem

    Device 0: qset 500, order 0, sz 1535135
        item at ccf80e00, qset at cf7b9800
            0:ccc58000
            1:cccdd000
    rudo% cat /tmp/bigfile > /dev/scullv0; head -5 /proc/scullvmem
    Device 0: qset 500, order 4, sz 1535135
        item at cfab4800, qset at cf8e4000
            0:d087a000
            1:d08d2000

上面的结果显示出了两种不同的行为。在x86_64上，物理地址和虚拟地址被映射到不同的地址范围（0x100和0xffffff00），而在x86计算机上，vmalloc返回的虚拟地址恰好在映射物理地址之上。

***
<h2 id="8.4">8.4 Per-CPU Variables </h2>
***

Per-CPU variables are an interesting 2.6 kernel feature. When you create a per-CPU variable, each processor on the system gets its own copy of that variable. This may seem like a strange thing to want to do, but it has its advantages. Access to per-CPU variables requires (almost) no locking, because each processor works with its own copy. Per-CPU variables can also remain in their respective processors’caches, which leads to significantly better performance for frequently updated quantities.

A good example of per-CPU variable use can be found in the networking subsystem. The kernel maintains no end of counters tracking how many of each type of packet was received; these counters can be updated thousands of times per second. Rather than deal with the caching and locking issues, the networking developers put the statistics counters into per-CPU variables. Updates are now lockless and fast. On the rare occasion that user space requests to see the values of the counters, it is a simple matter to add up each processor’s version and return the total. The declarations for per-CPU variables can be found in <linux/percpu.h>. To create a per-CPU variable at compile time, use this macro:

    DEFINE_PER_CPU(type, name);

If the variable (to be called name) is an array, include the dimension information with
the type. Thus, a per-CPU array of three integers would be created with:

    DEFINE_PER_CPU(int[3], my_percpu_array);

Per-CPU variables can be manipulated without explicit locking—almost. Remember
that the 2.6 kernel is preemptible; it would not do for a processor to be preempted in the middle of a critical section that modifies a per-CPU variable. It also would not be
good if your process were to be moved to another processor in the middle of a perCPU variable access. For this reason, you must explicitly use the get_cpu_var macro
to access the current processor’s copy of a given variable, and call put_cpu_var when
you are done. The call to get_cpu_var returns an lvalue for the current processor’s
version of the variable and disables preemption. Since an lvalue is returned, it can be
assigned to or operated on directly. For example, one counter in the networking code
is incremented with these two statements:

    get_cpu_var(sockets_in_use)++;
    put_cpu_var(sockets_in_use);

You can access another processor’s copy of the variable with:

    per_cpu(variable, int cpu_id);

If you write code that involves processors reaching into each other’s per-CPU variables, you, of course, have to implement a locking scheme that makes that access
safe.
Dynamically allocated per-CPU variables are also possible. These variables can be
allocated with:

    void *alloc_percpu(type);
    void *__alloc_percpu(size_t size, size_t align);

In most cases, alloc_percpu does the job; you can call __alloc_percpu in cases where
a particular alignment is required. In either case, a per-CPU variable can be returned
to the system with free_percpu. Access to a dynamically allocated per-CPU variable is
done via per_cpu_ptr:

    per_cpu_ptr(void *per_cpu_var, int cpu_id);

This macro returns a pointer to the version of per_cpu_var corresponding to the given
cpu_id. If you are simply reading another CPU’s version of the variable, you can dereference that pointer and be done with it. If, however, you are manipulating the current
processor’s version, you probably need to ensure that you cannot be moved out of
that processor first. If the entirety of your access to the per-CPU variable happens
with a spinlock held, all is well. Usually, however, you need to use get_cpu to block
preemption while working with the variable. Thus, code using dynamic per-CPU variables tends to look like this:

    int cpu;
    cpu = get_cpu( )
    ptr = per_cpu_ptr(per_cpu_var, cpu);
    /* work with ptr */
    put_cpu( );

When using compile-time per-CPU variables, the get_cpu_var and put_cpu_var macros take care of these details. Dynamic per-CPU variables require more explicit protection. Per-CPU variables can be exported to modules, but you must use a special version of the macros:

    EXPORT_PER_CPU_SYMBOL(per_cpu_var);
    EXPORT_PER_CPU_SYMBOL_GPL(per_cpu_var);

To access such a variable within a module, declare it with:

    DECLARE_PER_CPU(type, name);

The use of DECLARE_PER_CPU (instead of DEFINE_PER_CPU) tells the compiler
that an external reference is being made.

If you want to use per-CPU variables to create a simple integer counter, take a look
at the canned implementation in <linux/percpu_counter.h>. Finally, note that some
architectures have a limited amount of address space available for per-CPU variables. If you create per-CPU variables in your code, you should try to keep them
small.

***
<h2 id="8.5">8.5 Obtaining Large Buffers </h2>
***

As we have noted in previous sections, allocations of large, contiguous memory buffers are prone to failure. System memory fragments over time, and chances are that a
truly large region of memory will simply not be available. Since there are usually
ways of getting the job done without huge buffers, the kernel developers have not
put a high priority on making large allocations work. Before you try to obtain a large
memory area, you should really consider the alternatives. By far the best way of performing large I/O operations is through scatter/gather operations, which we discuss
in the section “Scatter-gather mappings” in Chapter 1.

***
<h3 id="8.5.1">8.5.1 Acquiring a Dedicated Buffer at Boot Time </h3>
***

If you really need a huge buffer of physically contiguous memory, the best approach
is often to allocate it by requesting memory at boot time. Allocation at boot time is
the only way to retrieve consecutive memory pages while bypassing the limits
imposed by __get_free_pages on the buffer size, both in terms of maximum allowed
size and limited choice of sizes. Allocating memory at boot time is a “dirty” technique, because it bypasses all memory management policies by reserving a private
memory pool. This technique is inelegant and inflexible, but it is also the least prone
to failure. Needless to say, a module can’t allocate memory at boot time; only drivers directly linked to the kernel can do that.

One noticeable problem with boot-time allocation is that it is not a feasible option
for the average user, since this mechanism is available only for code linked in the kernel image. A device driver using this kind of allocation can be installed or replaced
only by rebuilding the kernel and rebooting the computer.

When the kernel is booted, it gains access to all the physical memory available in the
system. It then initializes each of its subsystems by calling that subsystem’s initialization function, allowing initialization code to allocate a memory buffer for private use
by reducing the amount of RAM left for normal system operation.

Boot-time memory allocation is performed by calling one of these functions:

    #include <linux/bootmem.h>
    void *alloc_bootmem(unsigned long size);
    void *alloc_bootmem_low(unsigned long size);
    void *alloc_bootmem_pages(unsigned long size);
    void *alloc_bootmem_low_pages(unsigned long size);

The functions allocate either whole pages (if they end with _pages) or non-pagealigned memory areas. The allocated memory may be high memory unless one of the _low versions is used. If you are allocating this buffer for a device driver, you probably want to use it for DMA operations, and that is not always possible with high memory; thus, you probably want to use one of the _low variants.

It is rare to free memory allocated at boot time; you will almost certainly be unable to get it back later if you want it. There is an interface to free this memory, however:

    void free_bootmem(unsigned long addr, unsigned long size);

Note that partial pages freed in this manner are not returned to the system—but, if you are using this technique, you have probably allocated a fair number of whole pages to begin with.

If you must use boot-time allocation, you need to link your driver directly into the kernel. See the files in the kernel source under Documentation/kbuild for more information on how this should be done.